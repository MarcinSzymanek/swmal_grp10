{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "In this exercise we aim to shed some light on the Convolution Neural Networks by explaining the primary concepts behind CNN such as convolution layers and feature mapping and implement a CNN model to solve the MNIST numbers problem of recognizing numbers from images of handdrawn numbers.\n",
    "\n",
    "### The basics\n",
    "\n",
    "We have previously worked with multilayer perceptron models - these operated by having one or more layers of neurons, and a good way to attempt to understand CNN is to compare them to MLP models. In MLP the input is connected to one or more 'hidden' layers with some weights, and each subsequent hidden is connected to a layer before it. MLP layer consists of a one dimensional array of neurons. CNN, much like multilayer perceptrons, operate on layers connected to each other. The primary difference is that CNN models utilize a 2x2 matrix of neurons instead of a 1d array. This makes them much more fitting for tasks such as image recognition, where the input image can easily be represented as a 2d array of pixels.\n",
    "\n",
    "Another major difference is that in CNN each neuron in a layer is connected to specific subset of last layer called its receptive field. A receptive field is a i x i matrix, and can be thought of as a neurons 'field of vision'. Each neuron performs a convolution operation on its input based on a kernel (filter matrix) of the same size as the receptive fied.\n",
    "\n",
    "<img align = \"middle\" src=\"convolution_layer_geron.png\" width=\"500\"/>\n",
    "  \n",
    "<figcaption align = \"center\"><b>Example of convolution layer. The \"cone\" coming from the top layer is the receptive field of a neuron of size (3x3). </b> <i>A. Geron, Hands on Machine Learning</i></figcaption>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CNN to predict MNIST numbers dataset.\n",
    "\n",
    "We will now try to create a new CNN model using Keras framework and tweak it to predict the numbers out of an image with high accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Methods for downloading and plotting the data\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "# mnist 784 dataset has id == 554: https://www.openml.org/search?type=data&status=active&id=554\n",
    "\n",
    "def MNIST_GetDataSet() -> tuple[pd.DataFrame, pd.Series]:\n",
    "    X, y = fetch_openml(version=\"active\", data_id=554, return_X_y=True)\n",
    "    return X, y\n",
    "\n",
    "%matplotlib inline\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "X, y_true = MNIST_GetDataSet()\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to feed the data into a cnn model, we have to reshape it into 28x28x1 shape, since each image consists of 28x28 pixels. This is because by default the data is flattened and instead of using 28x28 pixels it's shaped as an array with length of 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "# Reshape the data\n",
    "X_all = X.to_numpy()\n",
    "X_all = X_all.reshape(70000, 28, 28, 1)\n",
    "print(X_all.shape)\n",
    "X_train = X_all[0:60000, :, :, :]\n",
    "X_test = X_all[60000: 70000, :, :, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the model will have to be a classification of a number between 0 and 9. At this step it is necessary to convert the train/test predictions to one-hot encoded values instead of the strings they are now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    0\n",
      "2    4\n",
      "3    1\n",
      "4    9\n",
      "Name: class, dtype: category\n",
      "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# This performs 'one-hot encoding'\n",
    "from keras.utils import to_categorical\n",
    "# Right now y_true is a vector of string with '0' to '9' in them\n",
    "print(y_true[0:5])\n",
    "\n",
    "# Convert the string to an array of 0s and 1s, where the \"correct\" value is given a 1 and each other value is a 0\n",
    "y_train = to_categorical(y_true[0:60000])\n",
    "y_test = to_categorical(y_true[60000:70000])\n",
    "\n",
    "print(y_train[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets train some cnn models to try to categorize the numbers. Additionally, since some of the fitting will take a long time, let's measure how long they take to train as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.7689 - accuracy: 0.8940 - val_loss: 0.3130 - val_accuracy: 0.9094\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3237 - accuracy: 0.9100 - val_loss: 0.3390 - val_accuracy: 0.9128\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3111 - accuracy: 0.9136 - val_loss: 0.3126 - val_accuracy: 0.9138\n",
      "time to fit:  46.19392228126526 s\n",
      "count    3.000000\n",
      "mean     0.912000\n",
      "std      0.002307\n",
      "min      0.909400\n",
      "25%      0.911100\n",
      "50%      0.912800\n",
      "75%      0.913300\n",
      "max      0.913800\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from pandas import Series\n",
    "import time\n",
    "\n",
    "def printAccData(acc : dict[str, float]):\n",
    "    valid_acc = Series(fittingLogs.history[\"val_accuracy\"])\n",
    "    print(valid_acc.describe())\n",
    "    return valid_acc.mean()\n",
    "\n",
    "# Model 1: 3 layers, kernel size 1x1\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, kernel_size=1, activation='relu', input_shape=(28,28,1)),\n",
    "    Conv2D(16, kernel_size=1, activation='relu', input_shape=(28,28,1)),\n",
    "    Conv2D(16, kernel_size=1, activation='relu', input_shape=(28,28,1)),\n",
    "])\n",
    "\n",
    "model.add(Flatten())\n",
    "# Dense() creates connection to the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "start = time.time()\n",
    "fittingLogs = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n",
    "end = time.time()\n",
    "print(\"time to fit: \", end-start, \"s\")\n",
    "final = end-start\n",
    "mean1 = printAccData(fittingLogs)\n",
    "m1_res = Series([mean1, final])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try increasing the kernel size to 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.2496 - accuracy: 0.9512 - val_loss: 0.0785 - val_accuracy: 0.9775\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0642 - accuracy: 0.9810 - val_loss: 0.0641 - val_accuracy: 0.9791\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.0668 - val_accuracy: 0.9821\n",
      "time to fit:  86.1745834350586 s\n",
      "count    3.000000\n",
      "mean     0.979567\n",
      "std      0.002335\n",
      "min      0.977500\n",
      "25%      0.978300\n",
      "50%      0.979100\n",
      "75%      0.980600\n",
      "max      0.982100\n",
      "dtype: float64\n",
      "count    3.000000\n",
      "mean     0.979567\n",
      "std      0.002335\n",
      "min      0.977500\n",
      "25%      0.978300\n",
      "50%      0.979100\n",
      "75%      0.980600\n",
      "max      0.982100\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=3, activation='relu', input_shape=(28,28,1))),\n",
    "model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#train the model\n",
    "start = time.time()\n",
    "fittingLogs = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n",
    "end = time.time()\n",
    "print(\"time to fit: \", end-start, \"s\")\n",
    "mean2 = printAccData(fittingLogs)\n",
    "\n",
    "final = end-start\n",
    "mean2 = printAccData(fittingLogs)\n",
    "m2_res = Series([mean2, final])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a noticable improvement in accuracy! We went from 0.917267 average validation accuracy to 0.977233, although the computation time has rougly doubled. Let's try doubling the filter size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.1769 - accuracy: 0.9613 - val_loss: 0.0664 - val_accuracy: 0.9788\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0497 - accuracy: 0.9850 - val_loss: 0.0745 - val_accuracy: 0.9780\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 0.0370 - accuracy: 0.9879 - val_loss: 0.0784 - val_accuracy: 0.9771\n",
      "time to fit:  168.18496894836426 s\n",
      "count    3.000000\n",
      "mean     0.977967\n",
      "std      0.000850\n",
      "min      0.977100\n",
      "25%      0.977550\n",
      "50%      0.978000\n",
      "75%      0.978400\n",
      "max      0.978800\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(28,28,1))),\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#train the model\n",
    "start = time.time()\n",
    "fittingLogs = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n",
    "end = time.time()\n",
    "print(\"time to fit: \", end-start, \"s\")\n",
    "mean3 = printAccData(fittingLogs)\n",
    "final = end-start\n",
    "m3_res = Series([mean3, final])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! Our accuracy has barely improved while the computation time for fitting, has doubled. Clearly adding more filters did not yield a noticable improvement to our model. The average accuracy and time can be shown below.\n",
    "\n",
    "\n",
    "A useful article about improving the performance of a model can be found here: https://machinelearningmastery.com/improve-deep-learning-performance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Rectangle.set() got an unexpected keyword argument 'x_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\UNI_2023\\ml\\swmal_grp10\\O3\\cnn_ans.ipynb Cell 16\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/cnn_ans.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/cnn_ans.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x_labels \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m1x1 kernel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m3x3 kernel, 16\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m3x3 kernel, 32\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/cnn_ans.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m results_score\u001b[39m.\u001b[39mplot\u001b[39m.\u001b[39mbar(ax \u001b[39m=\u001b[39m axes[\u001b[39m0\u001b[39m], title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean accuracy\u001b[39m\u001b[39m\"\u001b[39m, x_labels\u001b[39m=\u001b[39mx_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/cnn_ans.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m results_time\u001b[39m.\u001b[39mplot\u001b[39m.\u001b[39mbar(ax \u001b[39m=\u001b[39m axes[\u001b[39m1\u001b[39m], color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexec time\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_core.py:1136\u001b[0m, in \u001b[0;36mPlotAccessor.bar\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[39m@Appender\u001b[39m(\n\u001b[0;32m   1047\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39m    See Also\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mself\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   1126\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PlotAccessor:\n\u001b[0;32m   1127\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39m    Vertical bar plot.\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m    other axis represents a measured value.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kind\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbar\u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m=\u001b[39mx, y\u001b[39m=\u001b[39my, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_core.py:975\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    972\u001b[0m             label_name \u001b[39m=\u001b[39m label_kw \u001b[39mor\u001b[39;00m data\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m    973\u001b[0m             data\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m label_name\n\u001b[1;32m--> 975\u001b[0m \u001b[39mreturn\u001b[39;00m plot_backend\u001b[39m.\u001b[39mplot(data, kind\u001b[39m=\u001b[39mkind, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39max\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(ax, \u001b[39m\"\u001b[39m\u001b[39mleft_ax\u001b[39m\u001b[39m\"\u001b[39m, ax)\n\u001b[0;32m     70\u001b[0m plot_obj \u001b[39m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 71\u001b[0m plot_obj\u001b[39m.\u001b[39mgenerate()\n\u001b[0;32m     72\u001b[0m plot_obj\u001b[39m.\u001b[39mdraw()\n\u001b[0;32m     73\u001b[0m \u001b[39mreturn\u001b[39;00m plot_obj\u001b[39m.\u001b[39mresult\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:448\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_plot_data()\n\u001b[0;32m    447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_subplots()\n\u001b[1;32m--> 448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_plot()\n\u001b[0;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_table()\n\u001b[0;32m    450\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_legend()\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:1732\u001b[0m, in \u001b[0;36mBarPlot._make_plot\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1731\u001b[0m     w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbar_width \u001b[39m/\u001b[39m K\n\u001b[1;32m-> 1732\u001b[0m     rect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_plot(\n\u001b[0;32m   1733\u001b[0m         ax,\n\u001b[0;32m   1734\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39max_pos \u001b[39m+\u001b[39m (i \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m) \u001b[39m*\u001b[39m w,\n\u001b[0;32m   1735\u001b[0m         y,\n\u001b[0;32m   1736\u001b[0m         w,\n\u001b[0;32m   1737\u001b[0m         start\u001b[39m=\u001b[39mstart,\n\u001b[0;32m   1738\u001b[0m         label\u001b[39m=\u001b[39mlabel,\n\u001b[0;32m   1739\u001b[0m         log\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog,\n\u001b[0;32m   1740\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1741\u001b[0m     )\n\u001b[0;32m   1742\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_legend_handles_labels(rect, label)\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:1664\u001b[0m, in \u001b[0;36mBarPlot._plot\u001b[1;34m(cls, ax, x, y, w, start, log, **kwds)\u001b[0m\n\u001b[0;32m   1653\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_plot\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1662\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1663\u001b[0m ):\n\u001b[1;32m-> 1664\u001b[0m     \u001b[39mreturn\u001b[39;00m ax\u001b[39m.\u001b[39mbar(x, y, w, bottom\u001b[39m=\u001b[39mstart, log\u001b[39m=\u001b[39mlog, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1446\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1443\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1445\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1446\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1448\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1449\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1450\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:2480\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2471\u001b[0m \u001b[39mfor\u001b[39;00m l, b, w, h, c, e, lw, htch, lbl \u001b[39min\u001b[39;00m args:\n\u001b[0;32m   2472\u001b[0m     r \u001b[39m=\u001b[39m mpatches\u001b[39m.\u001b[39mRectangle(\n\u001b[0;32m   2473\u001b[0m         xy\u001b[39m=\u001b[39m(l, b), width\u001b[39m=\u001b[39mw, height\u001b[39m=\u001b[39mh,\n\u001b[0;32m   2474\u001b[0m         facecolor\u001b[39m=\u001b[39mc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2478\u001b[0m         hatch\u001b[39m=\u001b[39mhtch,\n\u001b[0;32m   2479\u001b[0m         )\n\u001b[1;32m-> 2480\u001b[0m     r\u001b[39m.\u001b[39m_internal_update(kwargs)\n\u001b[0;32m   2481\u001b[0m     r\u001b[39m.\u001b[39mget_path()\u001b[39m.\u001b[39m_interpolation_steps \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m   2482\u001b[0m     \u001b[39mif\u001b[39;00m orientation \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\matplotlib\\artist.py:1223\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_update\u001b[39m(\u001b[39mself\u001b[39m, kwargs):\n\u001b[0;32m   1217\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[39m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m \u001b[39m    errors as if calling `set`.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_props(\n\u001b[0;32m   1224\u001b[0m         kwargs, \u001b[39m\"\u001b[39m\u001b[39m{cls.__name__}\u001b[39;00m\u001b[39m.set() got an unexpected keyword argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1225\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m{prop_name!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\Lib\\site-packages\\matplotlib\\artist.py:1197\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[1;34m(self, props, errfmt)\u001b[0m\n\u001b[0;32m   1195\u001b[0m             func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mset_\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   1196\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(func):\n\u001b[1;32m-> 1197\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m   1198\u001b[0m                     errfmt\u001b[39m.\u001b[39mformat(\u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m), prop_name\u001b[39m=\u001b[39mk))\n\u001b[0;32m   1199\u001b[0m             ret\u001b[39m.\u001b[39mappend(func(v))\n\u001b[0;32m   1200\u001b[0m \u001b[39mif\u001b[39;00m ret:\n",
      "\u001b[1;31mAttributeError\u001b[0m: Rectangle.set() got an unexpected keyword argument 'x_labels'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame as df\n",
    "from matplotlib import pyplot as plt\n",
    "results_score = Series([m1_res.iloc[0], m2_res.iloc[0], m3_res.iloc[0]])\n",
    "results_time = Series([m1_res.iloc[1],m2_res.iloc[1], m3_res.iloc[1]])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "x_labels = [\"1x1 kernel\", \"3x3 kernel, 16\", \"3x3 kernel, 32\"]\n",
    "results_score.plot.bar(ax = axes[0], title=\"mean accuracy\", )\n",
    "results_time.plot.bar(ax = axes[1], color=\"green\", title=\"exec time\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
