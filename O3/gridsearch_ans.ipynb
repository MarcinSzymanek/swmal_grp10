{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Hyperparameters and Gridsearch \n",
    "\n",
    "Machine learning models have certain global parameters which decide on the inner workings of the model. An example of this could be a degree of polynomial models, or number of neurons or hidden layers in neural network models. Choosing the optimal hyperparameters for machine learning models manually is extremely time consuming, since it would involve a silly amount of trial and error. In this exercise we will delve into optimizing the hyperparameters using GridSearch and RandomizedSearch.\n",
    "\n",
    "### Qa Explain GridSearchCV\n",
    "\n",
    "The following python code block sets up our functions to load and set up the data, as well as display results of a gridsearch. See detailed explanation in the comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK(function setup, hope MNIST loads works because it seems you miss the installation of Keras or Tensorflow!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: importing 'keras' failed\n",
      "WARNING: importing 'tensorflow.keras' failed\n"
     ]
    }
   ],
   "source": [
    "# Explanation:\n",
    "# This block of code loads the data and defines functions which will be used to present results of gridsearch\n",
    "# GetBestModelCTOR() returns a string with a constructor of the model with the best parameters in it\n",
    "# SearchReport() displays the best models name, its best parameters, score and index. It also asserts that the scoring system used is f1_micro.\n",
    "# ClassificationReport() uses the model to predict with the test data supplied in parameters. It then compares the prediction with true values.\n",
    "# TryKerasImport() asserts that keras module is loaded and ready to be used\n",
    "# LoadAndSetupData() loads the data and reshapes it if needed, chosen by the parameter 'mode' - either iris, mnist or moon dataset\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import datasets\n",
    "\n",
    "# Need this to import libitmal on MY Windows machine. Replace with your GITMAL directory or uncomment if you already have gitmal in pythonpath  - Marcin\n",
    "sys.path.append(\"C:\\\\UNI_2023\\\\ml\\\\gitmal\")\n",
    "\n",
    "from libitmal import dataloaders as itmaldataloaders # Needed for load of iris, moon and mnist\n",
    "\n",
    "currmode=\"N/A\" # GLOBAL var!\n",
    "\n",
    "def SearchReport(model):\n",
    "\n",
    "    # This method\n",
    "    def GetBestModelCTOR(model, best_params):\n",
    "        def GetParams(best_params):\n",
    "            ret_str=\"\"\n",
    "            for key in sorted(best_params):\n",
    "                value = best_params[key]\n",
    "                temp_str = \"'\" if str(type(value))==\"<class 'str'>\" else \"\"\n",
    "                if len(ret_str)>0:\n",
    "                    ret_str += ','\n",
    "                ret_str += f'{key}={temp_str}{value}{temp_str}'\n",
    "            return ret_str\n",
    "        try:\n",
    "            param_str = GetParams(best_params)\n",
    "            return type(model).__name__ + '(' + param_str + ')'\n",
    "        except:\n",
    "            return \"N/A(1)\"\n",
    "\n",
    "    print(\"\\nBest model set found on train set:\")\n",
    "    print()\n",
    "    print(f\"\\tbest parameters={model.best_params_}\")\n",
    "    print(f\"\\tbest '{model.scoring}' score={model.best_score_}\")\n",
    "    print(f\"\\tbest index={model.best_index_}\")\n",
    "    print()\n",
    "    print(f\"Best estimator CTOR:\")\n",
    "    print(f\"\\t{model.best_estimator_}\")\n",
    "    print()\n",
    "    try:\n",
    "        print(f\"Grid scores ('{model.scoring}') on development set:\")\n",
    "        means = model.cv_results_['mean_test_score']\n",
    "        stds  = model.cv_results_['std_test_score']\n",
    "        i=0\n",
    "        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "            print(\"\\t[%2d]: %0.3f (+/-%0.03f) for %r\" % (i, mean, std * 2, params))\n",
    "            i += 1\n",
    "    except:\n",
    "        print(\"WARNING: the random search do not provide means/stds\")\n",
    "\n",
    "    global currmode\n",
    "    assert \"f1_micro\"==str(model.scoring), f\"come on, we need to fix the scoring to be able to compare model-fits! Your scoreing={str(model.scoring)}...remember to add scoring='f1_micro' to the search\"\n",
    "    return f\"best: dat={currmode}, score={model.best_score_:0.5f}, model={GetBestModelCTOR(model.estimator,model.best_params_)}\", model.best_estimator_\n",
    "\n",
    "def ClassificationReport(model, X_test, y_test, target_names=None):\n",
    "    assert X_test.shape[0]==y_test.shape[0]\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(\"\\tThe model is trained on the full development set.\")\n",
    "    print(\"\\tThe scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    print()\n",
    "\n",
    "def FullReport(model, X_test, y_test, t):\n",
    "    print(f\"SEARCH TIME: {t:0.2f} sec\")\n",
    "    beststr, bestmodel = SearchReport(model)\n",
    "    ClassificationReport(model, X_test, y_test)\n",
    "    print(f\"CTOR for best model: {bestmodel}\\n\")\n",
    "    print(f\"{beststr}\\n\")\n",
    "    return beststr, bestmodel\n",
    "\n",
    "def LoadAndSetupData(mode, test_size=0.3):\n",
    "    assert test_size>=0.0 and test_size<=1.0\n",
    "\n",
    "    def ShapeToString(Z):\n",
    "        n = Z.ndim\n",
    "        s = \"(\"\n",
    "        for i in range(n):\n",
    "            s += f\"{Z.shape[i]:5d}\"\n",
    "            if i+1!=n:\n",
    "                s += \";\"\n",
    "        return s+\")\"\n",
    "\n",
    "    global currmode\n",
    "    currmode=mode\n",
    "    print(f\"DATA: {currmode}..\")\n",
    "\n",
    "    if mode=='moon':\n",
    "        X, y = itmaldataloaders.MOON_GetDataSet(n_samples=5000, noise=0.2)\n",
    "        itmaldataloaders.MOON_Plot(X, y)\n",
    "    elif mode=='mnist':\n",
    "        X, y = itmaldataloaders.MNIST_GetDataSet(load_mode=0)\n",
    "        if X.ndim==3:\n",
    "            X=np.reshape(X, (X.shape[0], -1))\n",
    "    elif mode=='iris':\n",
    "        X, y = itmaldataloaders.IRIS_GetDataSet()\n",
    "    else:\n",
    "        raise ValueError(f\"could not load data for that particular mode='{mode}', only 'moon'/'mnist'/'iris' supported\")\n",
    "\n",
    "    print(f'  org. data:  X.shape      ={ShapeToString(X)}, y.shape      ={ShapeToString(y)}')\n",
    "\n",
    "    assert X.ndim==2\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    assert y.ndim==1 or (y.ndim==2 and y.shape[1]==0)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0, shuffle=True\n",
    "    )\n",
    "\n",
    "    print(f'  train data: X_train.shape={ShapeToString(X_train)}, y_train.shape={ShapeToString(y_train)}')\n",
    "    print(f'  test data:  X_test.shape ={ShapeToString(X_test)}, y_test.shape ={ShapeToString(y_test)}')\n",
    "    print()\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def TryKerasImport(verbose=True):\n",
    "\n",
    "    kerasok = True\n",
    "    try:\n",
    "        import keras as keras_try\n",
    "    except:\n",
    "        kerasok = False\n",
    "\n",
    "    tensorflowkerasok = True\n",
    "    try:\n",
    "        import tensorflow.keras as tensorflowkeras_try\n",
    "    except:\n",
    "        tensorflowkerasok = False\n",
    "\n",
    "    ok = kerasok or tensorflowkerasok\n",
    "\n",
    "    if not ok and verbose:\n",
    "        if not kerasok:\n",
    "            print(\"WARNING: importing 'keras' failed\", file=sys.stderr)\n",
    "        if not tensorflowkerasok:\n",
    "            print(\"WARNING: importing 'tensorflow.keras' failed\", file=sys.stderr)\n",
    "\n",
    "    return ok\n",
    "\n",
    "print(f\"OK(function setup\" + (\"\" if TryKerasImport() else \", hope MNIST loads works because it seems you miss the installation of Keras or Tensorflow!\") + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch is a method for tuning the hyperparameters of a model automatically, and GridSearchCV is the scikit-learn class that provides this functionality. To use GridSearchCV you simply supply it with the parameters you want it to test, and with values that you want to check. After running GridSearchCV.fit() on a dataset, gridsearch will go through all the possible combination of hyperparameters with the values supplied to it and compare their scoring using a scoring method of your choice. When that is done, the best parameters and the scores will be available in the GridSearchCV object. \n",
    "\n",
    "The following code block performs the actual grid search and displays the results using the functions supplied in the previous block. See the code comments for detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n",
      "\n",
      "SEARCH TIME: 1.98 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'C': 1, 'kernel': 'linear'}\n",
      "\tbest 'f1_micro' score=0.9714285714285715\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.962 (+/-0.093) for {'C': 0.1, 'kernel': 'linear'}\n",
      "\t[ 1]: 0.371 (+/-0.038) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "\t[ 2]: 0.971 (+/-0.047) for {'C': 1, 'kernel': 'linear'}\n",
      "\t[ 3]: 0.695 (+/-0.047) for {'C': 1, 'kernel': 'rbf'}\n",
      "\t[ 4]: 0.952 (+/-0.085) for {'C': 10, 'kernel': 'linear'}\n",
      "\t[ 5]: 0.924 (+/-0.097) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "CTOR for best model: SVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "best: dat=iris, score=0.97143, model=SVC(C=1,kernel='linear')\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData('iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# This is the model type we will test\n",
    "model = svm.SVC(\n",
    "    gamma=0.001\n",
    ")\n",
    "\n",
    "# These are the parameters that we want gridsearch to evaluate\n",
    "# They are setup as a Dict[name, vals] with name always being a string and vals being whatever type the parameter values are\n",
    "# In this particular example we will compare kernels 'linear' and 'rbf' against each other with 'C' (the regularization parameter) values being 0.1, 1 and 10\n",
    "# This means the model will be fit 2*3 times\n",
    "tuning_parameters = {\n",
    "    'kernel': ('linear', 'rbf'),\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# This is the number of KFolds that gridsearch's cross-validation strategy will use\n",
    "CV = 5\n",
    "# Don't display any debug informations\n",
    "VERBOSE = 0\n",
    "\n",
    "# Create gridsearch model with hyperparameters tested specified above\n",
    "# n_jobs is number of jobs ran in parallel when fitting the model: -1 uses all available processors according to sklearn's documentation\n",
    "# job is a somewhat ambiguous term so what exactly this means depends on the backend implementation in sklearn\n",
    "\n",
    "# 'f1_micro' scoring method is defined as the micro-averaged harmonic mean of precision and recall.\n",
    "# According to https://www.visobyte.com/2023/05/precision-recall-and-f1-score-in-object-detection-how-are-they-calculated.html#:~:text=The%20F1%20Score%20is%20a%20harmonic%20mean%20of,%2A%20%28Precision%20%2A%20Recall%29%20%2F%20%28Precision%20%2B%20Recall%29\n",
    "# The precision score measures the rate of false positives and the recall score measures how accurately it predicts/detects\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "# Find the best parameters and measure the time to do so using X_train, y_train from the iris dataset\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result. Uses previously defined methods to print data about the model. Also runs the best model to predict (X_test, y_test) validating it.\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for our model are C=1 with linear kernel, having a score of 0.97143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Hyperparameter Grid Search using an SDG classifier\n",
    "\n",
    "We will now use grid search to tune parameters of a Stochastic Gradient Descent classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 120.97 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\tbest 'f1_micro' score=0.9904761904761905\n",
      "\tbest index=222\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.001, loss='modified_huber', max_iter=100000, penalty='l1',\n",
      "              tol=0.01)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.790 (+/-0.411) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[ 1]: 0.686 (+/-0.273) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[ 2]: 0.800 (+/-0.194) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[ 3]: 0.771 (+/-0.220) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[ 4]: 0.819 (+/-0.279) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[ 5]: 0.952 (+/-0.085) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[ 6]: 0.800 (+/-0.265) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[ 7]: 0.781 (+/-0.187) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[ 8]: 0.781 (+/-0.305) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[ 9]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[10]: 0.876 (+/-0.187) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[11]: 0.800 (+/-0.152) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[12]: 0.676 (+/-0.338) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[13]: 0.800 (+/-0.229) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[14]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[15]: 0.667 (+/-0.434) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[16]: 0.829 (+/-0.196) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[17]: 0.905 (+/-0.200) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[18]: 0.781 (+/-0.143) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[19]: 0.895 (+/-0.185) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[20]: 0.876 (+/-0.245) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[21]: 0.810 (+/-0.170) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[22]: 0.819 (+/-0.152) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[23]: 0.829 (+/-0.222) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[24]: 0.762 (+/-0.248) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[25]: 0.743 (+/-0.339) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[26]: 0.733 (+/-0.420) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[27]: 0.733 (+/-0.129) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[28]: 0.867 (+/-0.229) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[29]: 0.819 (+/-0.315) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[30]: 0.752 (+/-0.315) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[31]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[32]: 0.819 (+/-0.194) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[33]: 0.695 (+/-0.398) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[34]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[35]: 0.781 (+/-0.166) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[36]: 0.781 (+/-0.245) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[37]: 0.619 (+/-0.386) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[38]: 0.857 (+/-0.181) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[39]: 0.743 (+/-0.187) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[40]: 0.914 (+/-0.164) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[41]: 0.848 (+/-0.258) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[42]: 0.819 (+/-0.164) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[43]: 0.867 (+/-0.220) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[44]: 0.733 (+/-0.222) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[45]: 0.752 (+/-0.251) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[46]: 0.905 (+/-0.209) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[47]: 0.667 (+/-0.545) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[48]: 0.848 (+/-0.203) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[49]: 0.800 (+/-0.126) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[50]: 0.752 (+/-0.272) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[51]: 0.914 (+/-0.203) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[52]: 0.838 (+/-0.245) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[53]: 0.781 (+/-0.177) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[54]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[55]: 0.857 (+/-0.241) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[56]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[57]: 0.771 (+/-0.185) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[58]: 0.819 (+/-0.126) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[59]: 0.781 (+/-0.205) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[60]: 0.876 (+/-0.205) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[61]: 0.848 (+/-0.220) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[62]: 0.733 (+/-0.245) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[63]: 0.648 (+/-0.273) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[64]: 0.838 (+/-0.155) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[65]: 0.857 (+/-0.085) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[66]: 0.895 (+/-0.194) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[67]: 0.895 (+/-0.164) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[68]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[69]: 0.724 (+/-0.505) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[70]: 0.743 (+/-0.260) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[71]: 0.781 (+/-0.253) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[72]: 0.886 (+/-0.230) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[73]: 0.667 (+/-0.120) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[74]: 0.733 (+/-0.253) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[75]: 0.629 (+/-0.304) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[76]: 0.876 (+/-0.222) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[77]: 0.733 (+/-0.214) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[78]: 0.771 (+/-0.315) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[79]: 0.895 (+/-0.111) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[80]: 0.762 (+/-0.135) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[81]: 0.781 (+/-0.328) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[82]: 0.800 (+/-0.353) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[83]: 0.743 (+/-0.114) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[84]: 0.790 (+/-0.196) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[85]: 0.829 (+/-0.196) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[86]: 0.857 (+/-0.209) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[87]: 0.800 (+/-0.185) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[88]: 0.819 (+/-0.244) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[89]: 0.914 (+/-0.164) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[90]: 0.867 (+/-0.203) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[91]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[92]: 0.743 (+/-0.230) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[93]: 0.733 (+/-0.177) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[94]: 0.705 (+/-0.363) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[95]: 0.924 (+/-0.097) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[96]: 0.352 (+/-0.097) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[97]: 0.400 (+/-0.354) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[98]: 0.495 (+/-0.322) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[99]: 0.352 (+/-0.076) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[100]: 0.343 (+/-0.229) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[101]: 0.314 (+/-0.076) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[102]: 0.305 (+/-0.129) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[103]: 0.257 (+/-0.293) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[104]: 0.429 (+/-0.263) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[105]: 0.343 (+/-0.071) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[106]: 0.305 (+/-0.076) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[107]: 0.400 (+/-0.316) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[108]: 0.314 (+/-0.076) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[109]: 0.324 (+/-0.071) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[110]: 0.362 (+/-0.047) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[111]: 0.295 (+/-0.203) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[112]: 0.295 (+/-0.038) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[113]: 0.324 (+/-0.111) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[114]: 0.314 (+/-0.047) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[115]: 0.305 (+/-0.166) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[116]: 0.352 (+/-0.143) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[117]: 0.362 (+/-0.047) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[118]: 0.286 (+/-0.289) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[119]: 0.381 (+/-0.241) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[120]: 0.448 (+/-0.245) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[121]: 0.467 (+/-0.368) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[122]: 0.400 (+/-0.222) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[123]: 0.267 (+/-0.273) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[124]: 0.381 (+/-0.289) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[125]: 0.352 (+/-0.097) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[126]: 0.438 (+/-0.220) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[127]: 0.333 (+/-0.060) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[128]: 0.448 (+/-0.267) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[129]: 0.410 (+/-0.267) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[130]: 0.457 (+/-0.280) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[131]: 0.276 (+/-0.236) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[132]: 0.438 (+/-0.309) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[133]: 0.429 (+/-0.313) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[134]: 0.381 (+/-0.200) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[135]: 0.429 (+/-0.313) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[136]: 0.390 (+/-0.185) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[137]: 0.419 (+/-0.291) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[138]: 0.257 (+/-0.280) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[139]: 0.429 (+/-0.289) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[140]: 0.410 (+/-0.214) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[141]: 0.381 (+/-0.135) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[142]: 0.448 (+/-0.322) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[143]: 0.448 (+/-0.364) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[144]: 0.876 (+/-0.177) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[145]: 0.848 (+/-0.236) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[146]: 0.752 (+/-0.164) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[147]: 0.876 (+/-0.214) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[148]: 0.952 (+/-0.085) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[149]: 0.943 (+/-0.111) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[150]: 0.895 (+/-0.140) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[151]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[152]: 0.933 (+/-0.097) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[153]: 0.790 (+/-0.230) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[154]: 0.771 (+/-0.229) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[155]: 0.886 (+/-0.196) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[156]: 0.895 (+/-0.229) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[157]: 0.800 (+/-0.212) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[158]: 0.819 (+/-0.265) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[159]: 0.867 (+/-0.236) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[160]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[161]: 0.876 (+/-0.196) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[162]: 0.933 (+/-0.129) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[163]: 0.943 (+/-0.071) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[164]: 0.781 (+/-0.177) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[165]: 0.876 (+/-0.230) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[166]: 0.933 (+/-0.097) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[167]: 0.857 (+/-0.104) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[168]: 0.867 (+/-0.220) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[169]: 0.771 (+/-0.194) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[170]: 0.857 (+/-0.217) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[171]: 0.857 (+/-0.269) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[172]: 0.886 (+/-0.114) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[173]: 0.924 (+/-0.097) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[174]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[175]: 0.924 (+/-0.114) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[176]: 0.933 (+/-0.114) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[177]: 0.838 (+/-0.333) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[178]: 0.905 (+/-0.289) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[179]: 0.867 (+/-0.152) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[180]: 0.790 (+/-0.453) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[181]: 0.848 (+/-0.265) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[182]: 0.867 (+/-0.236) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[183]: 0.848 (+/-0.164) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[184]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[185]: 0.943 (+/-0.071) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[186]: 0.933 (+/-0.047) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[187]: 0.971 (+/-0.076) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[188]: 0.800 (+/-0.229) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[189]: 0.867 (+/-0.220) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[190]: 0.876 (+/-0.214) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[191]: 0.781 (+/-0.245) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[192]: 0.781 (+/-0.214) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[193]: 0.838 (+/-0.196) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[194]: 0.800 (+/-0.298) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[195]: 0.733 (+/-0.196) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[196]: 0.952 (+/-0.104) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[197]: 0.943 (+/-0.071) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[198]: 0.962 (+/-0.111) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[199]: 0.924 (+/-0.114) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[200]: 0.829 (+/-0.230) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[201]: 0.905 (+/-0.159) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[202]: 0.857 (+/-0.217) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[203]: 0.914 (+/-0.212) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[204]: 0.876 (+/-0.177) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[205]: 0.857 (+/-0.248) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[206]: 0.800 (+/-0.152) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[207]: 0.838 (+/-0.205) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[208]: 0.971 (+/-0.047) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[209]: 0.943 (+/-0.038) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[210]: 0.933 (+/-0.047) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[211]: 0.924 (+/-0.214) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[212]: 0.867 (+/-0.203) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[213]: 0.867 (+/-0.212) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[214]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[215]: 0.848 (+/-0.164) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[216]: 0.819 (+/-0.212) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[217]: 0.829 (+/-0.322) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[218]: 0.876 (+/-0.177) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[219]: 0.867 (+/-0.111) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[220]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[221]: 0.924 (+/-0.155) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[222]: 0.990 (+/-0.038) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[223]: 0.971 (+/-0.047) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[224]: 0.876 (+/-0.267) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[225]: 0.867 (+/-0.185) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[226]: 0.857 (+/-0.256) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[227]: 0.790 (+/-0.155) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[228]: 0.829 (+/-0.267) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[229]: 0.838 (+/-0.205) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[230]: 0.857 (+/-0.276) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[231]: 0.857 (+/-0.241) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[232]: 0.924 (+/-0.129) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[233]: 0.933 (+/-0.047) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[234]: 0.895 (+/-0.140) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[235]: 0.952 (+/-0.000) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[236]: 0.810 (+/-0.200) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[237]: 0.905 (+/-0.200) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[238]: 0.943 (+/-0.111) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[239]: 0.876 (+/-0.267) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[240]: 0.333 (+/-0.085) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[241]: 0.333 (+/-0.085) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[242]: 0.324 (+/-0.423) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[243]: 0.314 (+/-0.155) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[244]: 0.276 (+/-0.285) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[245]: 0.286 (+/-0.104) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[246]: 0.210 (+/-0.322) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[247]: 0.276 (+/-0.285) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[248]: 0.410 (+/-0.293) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[249]: 0.248 (+/-0.251) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[250]: 0.505 (+/-0.322) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[251]: 0.324 (+/-0.220) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[252]: 0.400 (+/-0.273) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[253]: 0.200 (+/-0.332) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[254]: 0.343 (+/-0.071) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[255]: 0.276 (+/-0.236) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[256]: 0.267 (+/-0.222) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[257]: 0.295 (+/-0.298) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[258]: 0.314 (+/-0.076) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[259]: 0.333 (+/-0.085) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[260]: 0.257 (+/-0.260) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[261]: 0.352 (+/-0.097) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[262]: 0.314 (+/-0.047) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[263]: 0.343 (+/-0.071) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[264]: 0.638 (+/-0.129) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[265]: 0.600 (+/-0.322) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[266]: 0.467 (+/-0.338) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[267]: 0.400 (+/-0.273) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[268]: 0.552 (+/-0.344) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[269]: 0.495 (+/-0.322) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[270]: 0.667 (+/-0.341) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[271]: 0.486 (+/-0.304) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[272]: 0.524 (+/-0.330) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[273]: 0.600 (+/-0.273) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[274]: 0.571 (+/-0.319) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[275]: 0.362 (+/-0.177) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[276]: 0.619 (+/-0.301) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[277]: 0.733 (+/-0.311) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[278]: 0.543 (+/-0.311) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[279]: 0.448 (+/-0.411) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[280]: 0.543 (+/-0.311) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[281]: 0.505 (+/-0.393) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[282]: 0.562 (+/-0.415) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[283]: 0.571 (+/-0.486) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[284]: 0.638 (+/-0.557) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[285]: 0.457 (+/-0.424) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[286]: 0.505 (+/-0.230) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[287]: 0.381 (+/-0.159) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[288]: 0.914 (+/-0.111) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[289]: 0.905 (+/-0.104) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[290]: 0.838 (+/-0.214) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[291]: 0.781 (+/-0.205) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[292]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[293]: 0.990 (+/-0.038) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[294]: 0.971 (+/-0.076) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[295]: 0.962 (+/-0.038) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[296]: 0.838 (+/-0.196) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[297]: 0.886 (+/-0.076) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[298]: 0.914 (+/-0.111) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[299]: 0.838 (+/-0.205) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[300]: 0.924 (+/-0.097) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[301]: 0.895 (+/-0.194) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[302]: 0.876 (+/-0.177) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[303]: 0.867 (+/-0.229) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[304]: 0.952 (+/-0.085) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[305]: 0.962 (+/-0.038) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[306]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[307]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[308]: 0.724 (+/-0.038) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[309]: 0.790 (+/-0.230) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[310]: 0.838 (+/-0.230) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[311]: 0.781 (+/-0.238) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[312]: 0.876 (+/-0.143) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[313]: 0.886 (+/-0.177) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[314]: 0.848 (+/-0.185) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[315]: 0.838 (+/-0.245) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[316]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[317]: 0.962 (+/-0.093) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[318]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[319]: 0.952 (+/-0.085) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[320]: 0.914 (+/-0.071) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[321]: 0.876 (+/-0.245) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[322]: 0.924 (+/-0.196) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[323]: 0.876 (+/-0.214) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[324]: 0.857 (+/-0.159) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[325]: 0.886 (+/-0.230) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[326]: 0.876 (+/-0.097) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[327]: 0.952 (+/-0.060) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[328]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[329]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[330]: 0.962 (+/-0.071) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[331]: 0.962 (+/-0.038) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[332]: 0.895 (+/-0.152) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[333]: 0.905 (+/-0.159) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[334]: 0.829 (+/-0.230) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[335]: 0.876 (+/-0.230) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[336]: 0.810 (+/-0.276) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[337]: 0.905 (+/-0.181) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[338]: 0.810 (+/-0.159) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[339]: 0.848 (+/-0.220) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[340]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[341]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[342]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[343]: 0.952 (+/-0.085) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[344]: 0.905 (+/-0.170) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[345]: 0.895 (+/-0.140) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[346]: 0.867 (+/-0.212) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[347]: 0.905 (+/-0.241) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[348]: 0.838 (+/-0.177) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[349]: 0.886 (+/-0.129) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[350]: 0.848 (+/-0.203) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[351]: 0.848 (+/-0.265) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[352]: 0.933 (+/-0.076) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[353]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[354]: 0.952 (+/-0.104) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[355]: 0.933 (+/-0.143) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[356]: 0.819 (+/-0.258) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[357]: 0.886 (+/-0.260) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[358]: 0.857 (+/-0.181) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[359]: 0.800 (+/-0.272) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[360]: 0.838 (+/-0.143) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[361]: 0.724 (+/-0.272) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[362]: 0.829 (+/-0.349) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[363]: 0.848 (+/-0.353) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[364]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[365]: 0.952 (+/-0.060) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[366]: 0.962 (+/-0.038) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[367]: 0.952 (+/-0.060) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[368]: 0.933 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[369]: 0.895 (+/-0.126) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[370]: 0.829 (+/-0.230) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[371]: 0.819 (+/-0.304) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[372]: 0.800 (+/-0.140) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[373]: 0.838 (+/-0.222) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[374]: 0.924 (+/-0.129) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[375]: 0.829 (+/-0.166) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[376]: 0.971 (+/-0.076) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[377]: 0.962 (+/-0.071) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[378]: 0.962 (+/-0.038) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[379]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[380]: 0.962 (+/-0.111) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[381]: 0.876 (+/-0.205) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[382]: 0.838 (+/-0.369) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[383]: 0.952 (+/-0.085) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[384]: 0.352 (+/-0.129) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[385]: 0.371 (+/-0.152) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[386]: 0.352 (+/-0.114) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[387]: 0.343 (+/-0.038) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[388]: 0.324 (+/-0.111) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[389]: 0.371 (+/-0.126) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[390]: 0.362 (+/-0.097) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[391]: 0.229 (+/-0.093) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[392]: 0.314 (+/-0.230) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[393]: 0.257 (+/-0.143) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[394]: 0.314 (+/-0.076) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[395]: 0.381 (+/-0.135) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[396]: 0.371 (+/-0.265) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[397]: 0.400 (+/-0.129) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[398]: 0.410 (+/-0.129) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[399]: 0.381 (+/-0.060) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[400]: 0.352 (+/-0.273) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[401]: 0.333 (+/-0.217) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[402]: 0.314 (+/-0.196) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[403]: 0.305 (+/-0.205) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[404]: 0.333 (+/-0.060) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[405]: 0.343 (+/-0.126) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[406]: 0.333 (+/-0.190) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[407]: 0.305 (+/-0.177) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[408]: 0.676 (+/-0.071) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[409]: 0.714 (+/-0.104) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[410]: 0.657 (+/-0.140) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[411]: 0.686 (+/-0.097) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[412]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[413]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[414]: 0.648 (+/-0.177) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[415]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[416]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[417]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[418]: 0.733 (+/-0.076) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[419]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[420]: 0.743 (+/-0.166) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[421]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[422]: 0.724 (+/-0.140) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[423]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[424]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[425]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[426]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[427]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[428]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[429]: 0.733 (+/-0.177) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[430]: 0.705 (+/-0.071) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[431]: 0.657 (+/-0.236) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[432]: 0.781 (+/-0.177) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[433]: 0.800 (+/-0.194) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[434]: 0.752 (+/-0.164) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[435]: 0.800 (+/-0.220) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[436]: 0.752 (+/-0.126) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[437]: 0.838 (+/-0.143) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[438]: 0.857 (+/-0.104) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[439]: 0.743 (+/-0.155) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[440]: 0.781 (+/-0.114) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[441]: 0.733 (+/-0.097) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[442]: 0.771 (+/-0.203) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[443]: 0.714 (+/-0.135) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[444]: 0.876 (+/-0.205) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[445]: 0.829 (+/-0.253) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[446]: 0.810 (+/-0.233) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[447]: 0.867 (+/-0.291) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[448]: 0.867 (+/-0.194) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[449]: 0.829 (+/-0.155) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[450]: 0.790 (+/-0.129) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[451]: 0.848 (+/-0.175) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[452]: 0.714 (+/-0.060) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[453]: 0.743 (+/-0.047) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[454]: 0.781 (+/-0.177) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[455]: 0.705 (+/-0.071) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[456]: 0.810 (+/-0.248) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[457]: 0.790 (+/-0.129) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[458]: 0.800 (+/-0.220) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[459]: 0.752 (+/-0.212) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[460]: 0.762 (+/-0.200) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[461]: 0.752 (+/-0.126) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[462]: 0.857 (+/-0.241) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[463]: 0.743 (+/-0.129) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[464]: 0.714 (+/-0.060) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[465]: 0.790 (+/-0.143) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[466]: 0.752 (+/-0.093) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[467]: 0.771 (+/-0.194) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[468]: 0.762 (+/-0.060) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[469]: 0.924 (+/-0.222) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[470]: 0.790 (+/-0.230) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[471]: 0.771 (+/-0.152) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[472]: 0.829 (+/-0.205) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[473]: 0.762 (+/-0.104) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[474]: 0.790 (+/-0.177) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[475]: 0.848 (+/-0.203) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[476]: 0.781 (+/-0.214) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[477]: 0.829 (+/-0.196) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[478]: 0.714 (+/-0.085) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[479]: 0.743 (+/-0.177) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[480]: 0.838 (+/-0.214) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[481]: 0.867 (+/-0.251) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[482]: 0.876 (+/-0.097) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[483]: 0.829 (+/-0.196) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[484]: 0.895 (+/-0.071) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[485]: 0.886 (+/-0.245) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[486]: 0.886 (+/-0.047) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[487]: 0.895 (+/-0.126) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[488]: 0.781 (+/-0.155) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[489]: 0.829 (+/-0.097) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[490]: 0.838 (+/-0.143) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[491]: 0.790 (+/-0.245) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[492]: 0.781 (+/-0.129) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[493]: 0.857 (+/-0.085) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[494]: 0.762 (+/-0.269) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[495]: 0.848 (+/-0.164) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[496]: 0.895 (+/-0.244) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[497]: 0.933 (+/-0.114) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[498]: 0.848 (+/-0.236) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[499]: 0.867 (+/-0.194) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[500]: 0.886 (+/-0.155) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[501]: 0.943 (+/-0.093) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[502]: 0.800 (+/-0.140) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[503]: 0.771 (+/-0.203) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[504]: 0.838 (+/-0.238) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[505]: 0.914 (+/-0.152) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[506]: 0.895 (+/-0.194) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[507]: 0.829 (+/-0.155) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[508]: 0.962 (+/-0.038) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[509]: 0.962 (+/-0.071) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[510]: 0.990 (+/-0.038) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[511]: 0.971 (+/-0.047) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[512]: 0.857 (+/-0.233) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[513]: 0.867 (+/-0.140) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[514]: 0.876 (+/-0.230) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[515]: 0.895 (+/-0.126) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[516]: 0.943 (+/-0.071) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[517]: 0.924 (+/-0.097) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[518]: 0.848 (+/-0.194) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[519]: 0.952 (+/-0.148) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[520]: 0.952 (+/-0.085) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[521]: 0.971 (+/-0.047) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[522]: 0.981 (+/-0.047) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[523]: 0.971 (+/-0.047) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[524]: 0.933 (+/-0.143) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[525]: 0.895 (+/-0.152) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[526]: 0.933 (+/-0.097) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[527]: 0.924 (+/-0.114) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[528]: 0.324 (+/-0.111) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[529]: 0.314 (+/-0.214) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[530]: 0.400 (+/-0.155) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[531]: 0.324 (+/-0.093) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[532]: 0.324 (+/-0.285) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[533]: 0.410 (+/-0.166) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[534]: 0.343 (+/-0.203) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[535]: 0.276 (+/-0.111) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[536]: 0.286 (+/-0.241) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[537]: 0.286 (+/-0.148) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[538]: 0.267 (+/-0.129) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[539]: 0.371 (+/-0.164) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[540]: 0.381 (+/-0.200) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[541]: 0.295 (+/-0.071) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[542]: 0.381 (+/-0.200) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[543]: 0.371 (+/-0.111) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[544]: 0.333 (+/-0.269) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[545]: 0.267 (+/-0.230) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[546]: 0.419 (+/-0.071) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[547]: 0.305 (+/-0.129) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[548]: 0.371 (+/-0.071) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[549]: 0.371 (+/-0.258) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[550]: 0.305 (+/-0.177) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[551]: 0.305 (+/-0.187) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[552]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[553]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[554]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[555]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[556]: 0.562 (+/-0.212) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[557]: 0.486 (+/-0.291) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[558]: 0.486 (+/-0.265) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[559]: 0.495 (+/-0.299) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[560]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[561]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[562]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[563]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[564]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[565]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[566]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[567]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[568]: 0.524 (+/-0.181) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[569]: 0.390 (+/-0.203) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[570]: 0.524 (+/-0.241) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[571]: 0.562 (+/-0.244) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[572]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[573]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[574]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[575]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[576]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[577]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[578]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[579]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[580]: 0.600 (+/-0.322) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[581]: 0.467 (+/-0.265) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[582]: 0.657 (+/-0.140) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[583]: 0.619 (+/-0.233) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[584]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[585]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[586]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[587]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[588]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[589]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[590]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[591]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[592]: 0.419 (+/-0.304) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[593]: 0.514 (+/-0.343) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[594]: 0.457 (+/-0.349) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[595]: 0.495 (+/-0.293) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[596]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[597]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[598]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[599]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[600]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[601]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[602]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[603]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[604]: 0.581 (+/-0.332) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[605]: 0.362 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[606]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[607]: 0.438 (+/-0.279) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[608]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[609]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[610]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[611]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[612]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[613]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[614]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[615]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[616]: 0.495 (+/-0.322) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[617]: 0.429 (+/-0.241) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[618]: 0.562 (+/-0.338) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[619]: 0.438 (+/-0.279) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[620]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[621]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[622]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[623]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[624]: 0.810 (+/-0.248) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[625]: 0.848 (+/-0.194) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[626]: 0.743 (+/-0.222) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[627]: 0.771 (+/-0.152) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[628]: 0.324 (+/-0.071) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[629]: 0.343 (+/-0.071) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[630]: 0.333 (+/-0.085) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[631]: 0.333 (+/-0.060) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[632]: 0.867 (+/-0.348) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[633]: 0.781 (+/-0.333) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[634]: 0.686 (+/-0.076) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[635]: 0.676 (+/-0.244) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[636]: 0.752 (+/-0.140) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[637]: 0.829 (+/-0.245) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[638]: 0.790 (+/-0.205) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[639]: 0.762 (+/-0.301) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[640]: 0.324 (+/-0.071) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[641]: 0.343 (+/-0.071) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[642]: 0.333 (+/-0.060) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[643]: 0.352 (+/-0.047) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[644]: 0.714 (+/-0.233) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[645]: 0.848 (+/-0.140) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[646]: 0.648 (+/-0.230) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[647]: 0.600 (+/-0.379) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[648]: 0.752 (+/-0.111) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[649]: 0.790 (+/-0.205) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[650]: 0.867 (+/-0.203) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[651]: 0.829 (+/-0.222) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[652]: 0.714 (+/-0.104) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[653]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[654]: 0.733 (+/-0.129) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[655]: 0.705 (+/-0.038) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[656]: 0.743 (+/-0.114) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[657]: 0.762 (+/-0.085) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[658]: 0.762 (+/-0.120) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[659]: 0.733 (+/-0.114) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[660]: 0.714 (+/-0.104) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[661]: 0.771 (+/-0.236) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[662]: 0.781 (+/-0.177) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[663]: 0.743 (+/-0.166) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[664]: 0.714 (+/-0.104) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[665]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[666]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[667]: 0.733 (+/-0.177) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[668]: 0.790 (+/-0.177) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[669]: 0.733 (+/-0.097) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[670]: 0.771 (+/-0.152) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[671]: 0.705 (+/-0.038) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[672]: 0.457 (+/-0.260) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[673]: 0.371 (+/-0.285) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[674]: 0.229 (+/-0.236) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[675]: 0.400 (+/-0.416) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[676]: 0.257 (+/-0.177) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[677]: 0.381 (+/-0.233) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[678]: 0.267 (+/-0.260) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[679]: 0.333 (+/-0.170) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[680]: 0.371 (+/-0.338) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[681]: 0.352 (+/-0.253) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[682]: 0.371 (+/-0.236) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[683]: 0.295 (+/-0.212) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[684]: 0.333 (+/-0.276) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[685]: 0.495 (+/-0.196) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[686]: 0.295 (+/-0.298) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[687]: 0.438 (+/-0.265) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[688]: 0.410 (+/-0.316) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[689]: 0.371 (+/-0.220) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[690]: 0.257 (+/-0.260) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[691]: 0.295 (+/-0.212) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[692]: 0.343 (+/-0.343) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[693]: 0.267 (+/-0.196) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[694]: 0.200 (+/-0.236) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[695]: 0.314 (+/-0.177) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[696]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[697]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[698]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[699]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[700]: 0.352 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[701]: 0.362 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[702]: 0.333 (+/-0.085) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[703]: 0.343 (+/-0.071) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[704]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[705]: 0.333 (+/-0.085) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[706]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[707]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[708]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[709]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[710]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[711]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[712]: 0.324 (+/-0.071) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[713]: 0.333 (+/-0.085) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[714]: 0.305 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[715]: 0.333 (+/-0.060) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[716]: 0.352 (+/-0.076) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[717]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[718]: 0.352 (+/-0.076) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[719]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[720]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[721]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[722]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[723]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[724]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[725]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[726]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[727]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[728]: 0.333 (+/-0.000) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[729]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[730]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[731]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[732]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[733]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[734]: 0.324 (+/-0.038) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[735]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[736]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[737]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[738]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[739]: 0.324 (+/-0.038) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[740]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[741]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[742]: 0.324 (+/-0.038) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[743]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[744]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[745]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[746]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[747]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[748]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[749]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[750]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[751]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[752]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[753]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[754]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[755]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[756]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[757]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[758]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[759]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[760]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[761]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[762]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[763]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[764]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[765]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[766]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[767]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[768]: 0.448 (+/-0.222) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[769]: 0.419 (+/-0.298) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[770]: 0.467 (+/-0.258) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[771]: 0.448 (+/-0.155) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[772]: 0.305 (+/-0.047) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[773]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[774]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[775]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[776]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[777]: 0.324 (+/-0.038) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[778]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[779]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[780]: 0.429 (+/-0.241) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[781]: 0.371 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[782]: 0.457 (+/-0.214) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[783]: 0.400 (+/-0.177) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[784]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[785]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[786]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[787]: 0.343 (+/-0.038) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[788]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[789]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[790]: 0.324 (+/-0.038) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[791]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[792]: 0.467 (+/-0.229) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[793]: 0.467 (+/-0.229) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[794]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[795]: 0.400 (+/-0.230) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[796]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[797]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[798]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[799]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[800]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[801]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[802]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[803]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[804]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[805]: 0.381 (+/-0.000) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[806]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[807]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[808]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[809]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[810]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[811]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[812]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[813]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[814]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[815]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[816]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[817]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[818]: 0.419 (+/-0.203) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[819]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[820]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[821]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[822]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[823]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[824]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[825]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[826]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[827]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[828]: 0.400 (+/-0.129) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[829]: 0.400 (+/-0.230) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[830]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[831]: 0.419 (+/-0.203) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[832]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[833]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[834]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[835]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[836]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[837]: 0.343 (+/-0.038) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[838]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[839]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[840]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[841]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[842]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[843]: 0.381 (+/-0.104) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[844]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[845]: 0.324 (+/-0.038) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[846]: 0.305 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[847]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[848]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[849]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[850]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[851]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[852]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[853]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[854]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[855]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[856]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[857]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[858]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[859]: 0.305 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[860]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[861]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[862]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[863]: 0.314 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.001, loss='modified_huber', max_iter=100000, penalty='l1',\n",
      "              tol=0.01)\n",
      "\n",
      "best: dat=iris, score=0.99048, model=SGDClassifier(alpha=0.001,loss='modified_huber',max_iter=100000,penalty='l1',tol=0.01)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "sgd = linear_model.SGDClassifier()\n",
    "\n",
    "# Notice different parameters, check sklearn documentation for SGDClassifier for description of these parameters\n",
    "tuning_parameters = {\n",
    "    'loss': ['hinge', 'log_loss', 'perceptron', 'modified_huber', 'squared_error', 'huber'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 100],\n",
    "    'tol' : [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter' : [int(1e+5), int(1e+6)]\n",
    "}\n",
    "\n",
    "# This part is almost the same as in previous code block, we just swap the model\n",
    "grid_tuned = GridSearchCV(sgd,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model has a staggering score of 0.99048, even better than the SVC model we used previously! It did take a few minutes though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc Hyperparameter Random  Search using an SDG classifier\n",
    "\n",
    "Another method of finding the optimal parameters is to uze RandomizedSearchCV. In contrast to GridSearchCV it only chooses a few randomly selected samples of each hyperparameter provided, controlled by its own parameter 'n_iter'. This makes it potentially faster then GridSearchCV, but the results might not give the best scores. \n",
    "\n",
    "Below is an implementation and a test run of a RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 0.12 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'tol': 0.01, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 0.001}\n",
      "\tbest 'f1_micro' score=0.9714285714285715\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.001, loss='perceptron', max_iter=100000, penalty='l1',\n",
      "              tol=0.01)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.971 (+/-0.114) for {'tol': 0.01, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 0.001}\n",
      "\t[ 1]: 0.352 (+/-0.076) for {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'hinge', 'alpha': 100}\n",
      "\t[ 2]: 0.743 (+/-0.129) for {'tol': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 1}\n",
      "\t[ 3]: 0.886 (+/-0.196) for {'tol': 0.001, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'hinge', 'alpha': 0.01}\n",
      "\t[ 4]: 0.686 (+/-0.322) for {'tol': 0.1, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\t[ 5]: 0.895 (+/-0.111) for {'tol': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'hinge', 'alpha': 0.01}\n",
      "\t[ 6]: 0.524 (+/-0.301) for {'tol': 0.001, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'hinge', 'alpha': 1}\n",
      "\t[ 7]: 0.924 (+/-0.097) for {'tol': 0.01, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'hinge', 'alpha': 0.01}\n",
      "\t[ 8]: 0.905 (+/-0.120) for {'tol': 0.001, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 0.1}\n",
      "\t[ 9]: 0.752 (+/-0.164) for {'tol': 0.001, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 1}\n",
      "\t[10]: 0.333 (+/-0.085) for {'tol': 0.001, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'squared_error', 'alpha': 0.01}\n",
      "\t[11]: 0.362 (+/-0.047) for {'tol': 0.01, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 100}\n",
      "\t[12]: 0.343 (+/-0.071) for {'tol': 0.1, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 1}\n",
      "\t[13]: 0.829 (+/-0.196) for {'tol': 0.0001, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'log_loss', 'alpha': 0.1}\n",
      "\t[14]: 0.286 (+/-0.319) for {'tol': 0.01, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'squared_error', 'alpha': 1}\n",
      "\t[15]: 0.362 (+/-0.047) for {'tol': 0.001, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'log_loss', 'alpha': 100}\n",
      "\t[16]: 0.838 (+/-0.177) for {'tol': 0.1, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'perceptron', 'alpha': 0.0001}\n",
      "\t[17]: 0.352 (+/-0.076) for {'tol': 0.001, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'huber', 'alpha': 100}\n",
      "\t[18]: 0.333 (+/-0.085) for {'tol': 0.0001, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'huber', 'alpha': 1}\n",
      "\t[19]: 0.371 (+/-0.164) for {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'squared_error', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.96      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.001, loss='perceptron', max_iter=100000, penalty='l1',\n",
      "              tol=0.01)\n",
      "\n",
      "best: dat=iris, score=0.97143, model=SGDClassifier(alpha=0.001,loss='perceptron',max_iter=100000,penalty='l1',tol=0.01)\n",
      "\n",
      "OK(random-search)\n"
     ]
    }
   ],
   "source": [
    "random_tuned = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    tuning_parameters,\n",
    "    # Pick up to 20 different samples\n",
    "    n_iter=20,\n",
    "    # same state should give same rng distribution\n",
    "    random_state=42,\n",
    "    cv=CV,\n",
    "    scoring='f1_micro',\n",
    "    verbose=VERBOSE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start = time()\n",
    "random_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(random_tuned, X_test, y_test, t)\n",
    "print('OK(random-search)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the output that only 20 different combinations of parameters were tested, and the best parameters were not the same as in GridSearchCV test. The f1_score is also lower at 0.914 instead of 0.990. This could potentially be improved by adding more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qd MNIST Search Quest II\n",
    "\n",
    "\n",
    "It's time to embark on an epic adventure of finding the best model for the MNIST dataset. Here we will use gridsearch on several models to attempt to find the best model according to the f1_micro scoring metric. The best scores across different groups will then be compared to each other. May the best man win!\n",
    "\n",
    "In our first try, we'd like to test how fast the gridsearch performs, so we're gonna use a GridSearchCV with our existing SGDClassifier. Since complete GridSearch would take forever, we will only select a few parameters from each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: mnist..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\UNI_2023\\ml\\gitmal\\libitmal\\dataloaders.py:65: UserWarning: MNIST_GetDataSet(): failed to import and load data in load_mode 'tensorflow.keras', proceding to next mode..\n",
      "  warnings.warn(\"MNIST_GetDataSet(): failed to import and load data in load_mode 'tensorflow.keras', proceding to next mode..\")\n",
      "C:\\UNI_2023\\ml\\gitmal\\libitmal\\dataloaders.py:77: UserWarning: MNIST_GetDataSet(): failed to import and load data in load_mode 'keras', proceding to next mode..\n",
      "  warnings.warn(\"MNIST_GetDataSet(): failed to import and load data in load_mode 'keras', proceding to next mode..\")\n",
      "c:\\Users\\nastr\\anaconda3\\envs\\swmal\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "C:\\UNI_2023\\ml\\gitmal\\libitmal\\dataloaders.py:88: UserWarning: MNIST_GetDataSet(): fetch openml mode is slow and uses 'float64' instead of 'uint8'\n",
      "  warnings.warn(\"MNIST_GetDataSet(): fetch openml mode is slow and uses 'float64' instead of 'uint8'\")\n",
      "C:\\UNI_2023\\ml\\gitmal\\libitmal\\dataloaders.py:92: UserWarning: MNIST_GetDataSet(): fetch openml mode converts y from '<class 'str'>' to 'uint8'\n",
      "  warnings.warn(f\"MNIST_GetDataSet(): fetch openml mode converts y from '{type(y[0])}' to 'uint8'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  org. data:  X.shape      =(70000;  784), y.shape      =(70000)\n",
      "  train data: X_train.shape=(49000;  784), y_train.shape=(49000)\n",
      "  test data:  X_test.shape =(21000;  784), y_test.shape =(21000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load mnist data separate block, since this can take extra time\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData('mnist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 17656.98 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\tbest 'f1_micro' score=0.8937959183673468\n",
      "\tbest index=17\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.001, loss='log_loss', max_iter=100, penalty='l1', tol=0.1)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.868 (+/-0.017) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[ 1]: 0.864 (+/-0.027) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[ 2]: 0.882 (+/-0.012) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[ 3]: 0.893 (+/-0.008) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[ 4]: 0.892 (+/-0.007) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[ 5]: 0.891 (+/-0.003) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[ 6]: 0.869 (+/-0.024) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[ 7]: 0.876 (+/-0.032) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[ 8]: 0.879 (+/-0.018) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[ 9]: 0.890 (+/-0.008) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[10]: 0.890 (+/-0.012) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[11]: 0.891 (+/-0.008) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[12]: 0.872 (+/-0.015) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[13]: 0.874 (+/-0.020) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[14]: 0.881 (+/-0.011) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[15]: 0.892 (+/-0.006) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[16]: 0.891 (+/-0.003) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[17]: 0.894 (+/-0.007) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[18]: 0.881 (+/-0.007) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[19]: 0.873 (+/-0.049) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[20]: 0.880 (+/-0.017) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[21]: 0.890 (+/-0.009) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[22]: 0.888 (+/-0.006) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[23]: 0.888 (+/-0.002) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[24]: 0.865 (+/-0.032) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[25]: 0.877 (+/-0.014) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[26]: 0.878 (+/-0.035) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[27]: 0.881 (+/-0.010) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[28]: 0.877 (+/-0.003) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[29]: 0.880 (+/-0.007) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[30]: 0.877 (+/-0.028) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[31]: 0.872 (+/-0.029) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[32]: 0.876 (+/-0.016) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[33]: 0.881 (+/-0.012) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[34]: 0.885 (+/-0.004) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[35]: 0.887 (+/-0.007) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[36]: 0.875 (+/-0.014) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[37]: 0.872 (+/-0.025) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[38]: 0.875 (+/-0.018) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[39]: 0.885 (+/-0.006) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[40]: 0.884 (+/-0.004) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[41]: 0.881 (+/-0.006) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[42]: 0.866 (+/-0.029) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[43]: 0.866 (+/-0.050) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[44]: 0.878 (+/-0.021) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[45]: 0.886 (+/-0.004) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[46]: 0.883 (+/-0.009) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[47]: 0.884 (+/-0.009) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[48]: 0.876 (+/-0.027) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[49]: 0.875 (+/-0.026) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[50]: 0.869 (+/-0.017) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[51]: 0.822 (+/-0.006) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[52]: 0.822 (+/-0.013) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[53]: 0.821 (+/-0.011) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[54]: 0.885 (+/-0.018) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[55]: 0.876 (+/-0.024) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[56]: 0.885 (+/-0.014) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[57]: 0.834 (+/-0.007) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[58]: 0.834 (+/-0.016) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[59]: 0.832 (+/-0.018) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[60]: 0.880 (+/-0.017) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[61]: 0.880 (+/-0.023) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[62]: 0.875 (+/-0.030) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[63]: 0.839 (+/-0.026) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[64]: 0.841 (+/-0.022) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[65]: 0.844 (+/-0.020) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[66]: 0.884 (+/-0.025) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[67]: 0.880 (+/-0.014) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[68]: 0.871 (+/-0.012) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[69]: 0.850 (+/-0.011) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[70]: 0.845 (+/-0.016) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[71]: 0.847 (+/-0.015) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      2077\n",
      "           1       0.96      0.96      0.96      2385\n",
      "           2       0.91      0.89      0.90      2115\n",
      "           3       0.90      0.85      0.87      2117\n",
      "           4       0.90      0.91      0.91      2004\n",
      "           5       0.85      0.81      0.83      1900\n",
      "           6       0.94      0.93      0.94      2045\n",
      "           7       0.94      0.90      0.92      2189\n",
      "           8       0.73      0.87      0.79      2042\n",
      "           9       0.88      0.85      0.86      2126\n",
      "\n",
      "    accuracy                           0.89     21000\n",
      "   macro avg       0.90      0.89      0.89     21000\n",
      "weighted avg       0.90      0.89      0.89     21000\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.001, loss='log_loss', max_iter=100, penalty='l1', tol=0.1)\n",
      "\n",
      "best: dat=mnist, score=0.89380, model=SGDClassifier(alpha=0.001,loss='log_loss',max_iter=100,penalty='l1',tol=0.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nastr\\anaconda3\\envs\\swmal\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Notice different parameters, check sklearn documentation for SGDClassifier for description of these parameters\n",
    "tuning_parameters = {\n",
    "    'loss': ['hinge', 'log_loss'],\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'alpha' : [0.001, 0.01, 0.1],\n",
    "    'tol' : [0.001, 0.01, 0.1],\n",
    "    'max_iter' : [int(1e+2), int(1e+3)]\n",
    "}\n",
    "\n",
    "# This part is almost the same as in previous code block, we just swap the model\n",
    "grid_tuned = GridSearchCV(sgd,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score of 0.8938 isn't terrible but it surely can be improved upon. Let's try a model which hasn't been explored during the lectures: RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nastr\\anaconda3\\envs\\swmal\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 36 is smaller than n_iter=50. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "SEARCH TIME: 5070.60 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\tbest 'f1_micro' score=0.8937959183673468\n",
      "\tbest index=17\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.001, loss='log_loss', max_iter=100, penalty='l1', tol=0.1)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.868 (+/-0.017) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[ 1]: 0.864 (+/-0.027) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[ 2]: 0.882 (+/-0.012) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[ 3]: 0.893 (+/-0.008) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[ 4]: 0.892 (+/-0.007) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[ 5]: 0.891 (+/-0.003) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[ 6]: 0.869 (+/-0.024) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[ 7]: 0.876 (+/-0.032) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[ 8]: 0.879 (+/-0.018) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[ 9]: 0.890 (+/-0.008) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[10]: 0.890 (+/-0.012) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[11]: 0.891 (+/-0.008) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[12]: 0.872 (+/-0.015) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[13]: 0.874 (+/-0.020) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[14]: 0.881 (+/-0.011) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[15]: 0.892 (+/-0.006) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[16]: 0.891 (+/-0.003) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[17]: 0.894 (+/-0.007) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[18]: 0.881 (+/-0.007) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[19]: 0.873 (+/-0.049) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[20]: 0.880 (+/-0.017) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[21]: 0.890 (+/-0.009) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[22]: 0.888 (+/-0.006) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[23]: 0.888 (+/-0.002) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[24]: 0.865 (+/-0.032) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[25]: 0.877 (+/-0.014) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[26]: 0.878 (+/-0.035) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[27]: 0.881 (+/-0.010) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[28]: 0.877 (+/-0.003) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[29]: 0.880 (+/-0.007) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[30]: 0.877 (+/-0.028) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[31]: 0.872 (+/-0.029) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[32]: 0.876 (+/-0.016) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[33]: 0.881 (+/-0.012) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[34]: 0.885 (+/-0.004) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[35]: 0.887 (+/-0.007) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[36]: 0.875 (+/-0.014) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[37]: 0.872 (+/-0.025) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[38]: 0.875 (+/-0.018) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[39]: 0.885 (+/-0.006) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[40]: 0.884 (+/-0.004) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[41]: 0.881 (+/-0.006) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[42]: 0.866 (+/-0.029) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[43]: 0.866 (+/-0.050) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[44]: 0.878 (+/-0.021) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[45]: 0.886 (+/-0.004) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[46]: 0.883 (+/-0.009) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[47]: 0.884 (+/-0.009) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[48]: 0.876 (+/-0.027) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[49]: 0.875 (+/-0.026) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[50]: 0.869 (+/-0.017) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[51]: 0.822 (+/-0.006) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[52]: 0.822 (+/-0.013) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[53]: 0.821 (+/-0.011) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[54]: 0.885 (+/-0.018) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[55]: 0.876 (+/-0.024) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[56]: 0.885 (+/-0.014) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[57]: 0.834 (+/-0.007) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[58]: 0.834 (+/-0.016) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[59]: 0.832 (+/-0.018) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[60]: 0.880 (+/-0.017) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[61]: 0.880 (+/-0.023) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[62]: 0.875 (+/-0.030) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[63]: 0.839 (+/-0.026) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[64]: 0.841 (+/-0.022) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[65]: 0.844 (+/-0.020) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[66]: 0.884 (+/-0.025) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[67]: 0.880 (+/-0.014) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[68]: 0.871 (+/-0.012) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[69]: 0.850 (+/-0.011) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[70]: 0.845 (+/-0.016) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[71]: 0.847 (+/-0.015) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      2077\n",
      "           1       0.96      0.96      0.96      2385\n",
      "           2       0.91      0.89      0.90      2115\n",
      "           3       0.90      0.85      0.87      2117\n",
      "           4       0.90      0.91      0.91      2004\n",
      "           5       0.85      0.81      0.83      1900\n",
      "           6       0.94      0.93      0.94      2045\n",
      "           7       0.94      0.90      0.92      2189\n",
      "           8       0.73      0.87      0.79      2042\n",
      "           9       0.88      0.85      0.86      2126\n",
      "\n",
      "    accuracy                           0.89     21000\n",
      "   macro avg       0.90      0.89      0.89     21000\n",
      "weighted avg       0.90      0.89      0.89     21000\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.001, loss='log_loss', max_iter=100, penalty='l1', tol=0.1)\n",
      "\n",
      "best: dat=mnist, score=0.89380, model=SGDClassifier(alpha=0.001,loss='log_loss',max_iter=100,penalty='l1',tol=0.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forest gridsearch!\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'n_estimators' : [50, 100, 1000],\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth' : [None, 2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_tuned = GridSearchCV(forest,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let this code run on the gpucluster server and got the following results:\n",
    "\n",
    "![random forest results](mnist_quest/RandomForest.png)\n",
    "\n",
    "  \n",
    "With a score of 0.96863 we feel this is a pretty good result! Nonetheless, we might be able to optimize it. The search above was done using RandomizedSearchCV. Let's try choosing a couple parameters close to our result and performing a GridSearch with them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "SEARCH TIME: 4508.03 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'min_samples_split': 2, 'n_estimators': 1500}\n",
      "\tbest 'f1_micro' score=0.9686530612244898\n",
      "\tbest index=1\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRandomForestClassifier(n_estimators=1500)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.968 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 1000}\n",
      "\t[ 1]: 0.969 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 1500}\n",
      "\t[ 2]: 0.968 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 2000}\n",
      "\t[ 3]: 0.968 (+/-0.003) for {'min_samples_split': 3, 'n_estimators': 1000}\n",
      "\t[ 4]: 0.968 (+/-0.003) for {'min_samples_split': 3, 'n_estimators': 1500}\n",
      "\t[ 5]: 0.968 (+/-0.003) for {'min_samples_split': 3, 'n_estimators': 2000}\n",
      "\t[ 6]: 0.968 (+/-0.003) for {'min_samples_split': 5, 'n_estimators': 1000}\n",
      "\t[ 7]: 0.968 (+/-0.002) for {'min_samples_split': 5, 'n_estimators': 1500}\n",
      "\t[ 8]: 0.967 (+/-0.003) for {'min_samples_split': 5, 'n_estimators': 2000}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2077\n",
      "           1       0.99      0.99      0.99      2385\n",
      "           2       0.96      0.98      0.97      2115\n",
      "           3       0.97      0.95      0.96      2117\n",
      "           4       0.97      0.97      0.97      2004\n",
      "           5       0.97      0.96      0.97      1900\n",
      "           6       0.97      0.98      0.98      2045\n",
      "           7       0.97      0.96      0.97      2189\n",
      "           8       0.96      0.96      0.96      2042\n",
      "           9       0.96      0.95      0.96      2126\n",
      "\n",
      "    accuracy                           0.97     21000\n",
      "   macro avg       0.97      0.97      0.97     21000\n",
      "weighted avg       0.97      0.97      0.97     21000\n",
      "\n",
      "\n",
      "CTOR for best model: RandomForestClassifier(n_estimators=1500)\n",
      "\n",
      "best: dat=mnist, score=0.96865, model=RandomForestClassifier(min_samples_split=2,n_estimators=1500)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'n_estimators' : [1000, 1500, 2000],\n",
    "    'min_samples_split' : [2, 3, 5]\n",
    "}\n",
    "\n",
    "grid_tuned = GridSearchCV(forest,\n",
    "                          tuning_parameters,\n",
    "                          cv=5,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=2,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not seem to improve our score by much. In our final test we will test the DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "SEARCH TIME: 40.16 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\tbest 'f1_micro' score=0.8317346938775512\n",
      "\tbest index=24\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tDecisionTreeClassifier(criterion='entropy', max_features='sqrt')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.819 (+/-0.005) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[ 1]: 0.821 (+/-0.015) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[ 2]: 0.824 (+/-0.014) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[ 3]: 0.815 (+/-0.010) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[ 4]: 0.823 (+/-0.013) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[ 5]: 0.819 (+/-0.006) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[ 6]: 0.819 (+/-0.006) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[ 7]: 0.821 (+/-0.007) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[ 8]: 0.818 (+/-0.013) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[ 9]: 0.817 (+/-0.009) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[10]: 0.821 (+/-0.010) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[11]: 0.822 (+/-0.014) for {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[12]: 0.778 (+/-0.007) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[13]: 0.777 (+/-0.010) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[14]: 0.773 (+/-0.011) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[15]: 0.769 (+/-0.009) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[16]: 0.776 (+/-0.006) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[17]: 0.772 (+/-0.014) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[18]: 0.779 (+/-0.008) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[19]: 0.773 (+/-0.015) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[20]: 0.770 (+/-0.006) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[21]: 0.780 (+/-0.011) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[22]: 0.778 (+/-0.019) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[23]: 0.773 (+/-0.013) for {'criterion': 'gini', 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[24]: 0.832 (+/-0.007) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[25]: 0.830 (+/-0.005) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[26]: 0.824 (+/-0.007) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[27]: 0.826 (+/-0.006) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[28]: 0.826 (+/-0.010) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[29]: 0.828 (+/-0.014) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[30]: 0.826 (+/-0.012) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[31]: 0.828 (+/-0.008) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[32]: 0.825 (+/-0.004) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[33]: 0.829 (+/-0.009) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[34]: 0.831 (+/-0.006) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[35]: 0.827 (+/-0.006) for {'criterion': 'entropy', 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[36]: 0.782 (+/-0.011) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[37]: 0.778 (+/-0.005) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[38]: 0.781 (+/-0.009) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[39]: 0.776 (+/-0.005) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[40]: 0.778 (+/-0.015) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[41]: 0.780 (+/-0.004) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[42]: 0.780 (+/-0.013) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[43]: 0.777 (+/-0.011) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[44]: 0.777 (+/-0.010) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\t[45]: 0.778 (+/-0.012) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "\t[46]: 0.776 (+/-0.017) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "\t[47]: 0.773 (+/-0.015) for {'criterion': 'entropy', 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'splitter': 'best'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92      2077\n",
      "           1       0.94      0.95      0.95      2385\n",
      "           2       0.84      0.83      0.84      2115\n",
      "           3       0.79      0.78      0.79      2117\n",
      "           4       0.81      0.84      0.83      2004\n",
      "           5       0.79      0.77      0.78      1900\n",
      "           6       0.88      0.89      0.88      2045\n",
      "           7       0.86      0.86      0.86      2189\n",
      "           8       0.80      0.79      0.80      2042\n",
      "           9       0.78      0.79      0.79      2126\n",
      "\n",
      "    accuracy                           0.85     21000\n",
      "   macro avg       0.84      0.84      0.84     21000\n",
      "weighted avg       0.84      0.85      0.85     21000\n",
      "\n",
      "\n",
      "CTOR for best model: DecisionTreeClassifier(criterion='entropy', max_features='sqrt')\n",
      "\n",
      "best: dat=mnist, score=0.83173, model=DecisionTreeClassifier(criterion='entropy',max_features='sqrt',min_samples_leaf=1,min_samples_split=2,splitter='best')\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'splitter' : ['best'],\n",
    "    'min_samples_split' : [2, 3, 5],\n",
    "    'min_samples_leaf' : [1, 2, 3, 4],\n",
    "    'max_features' : ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_tuned = GridSearchCV(tree,\n",
    "                          tuning_parameters,\n",
    "                          cv=5,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=2,\n",
    "                          n_jobs=6)\n",
    "\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, this score is even worse than the scores we had before. We'll have to stick with our RandomTreeClassifier, with a score of 0.986."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
