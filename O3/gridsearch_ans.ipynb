{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Hyperparameters and Gridsearch \n",
    "\n",
    "Machine learning models have certain global parameters which decide on the inner workings of the model. An example of this could be a degree of polynomial models, or number of neurons or hidden layers in neural network models. Choosing the optimal hyperparameters for machine learning models manually is extremely time consuming, since it would involve a silly amount of trial and error. In this exercise we will delve into optimizing the hyperparameters using GridSearch and RandomizedSearch.\n",
    "\n",
    "### Qa Explain GridSearchCV\n",
    "\n",
    "The following python code block sets up our functions to load and set up the data, as well as display results of a gridsearch. See detailed explanation in the comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK(function setup)\n"
     ]
    }
   ],
   "source": [
    "# Explanation:\n",
    "# This block of code loads the data and defines functions which will be used to present results of gridsearch\n",
    "# GetBestModelCTOR() returns a string with a constructor of the model with the best parameters in it\n",
    "# SearchReport() displays the best models name, its best parameters, score and index. It also asserts that the scoring system used is f1_micro.\n",
    "# ClassificationReport() uses the model to predict with the test data supplied in parameters. It then compares the prediction with true values.\n",
    "# TryKerasImport() asserts that keras module is loaded and ready to be used\n",
    "# LoadAndSetupData() loads the data and reshapes it if needed, chosen by the parameter 'mode' - either iris, mnist or moon dataset\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import datasets\n",
    "\n",
    "# Need this to import libitmal on MY Windows machine. Replace with your GITMAL directory or uncomment if you already have gitmal in pythonpath  - Marcin\n",
    "sys.path.append(\"C:\\\\UNI_2023\\\\ml\\\\gitmal\")\n",
    "\n",
    "from libitmal import dataloaders as itmaldataloaders # Needed for load of iris, moon and mnist\n",
    "\n",
    "currmode=\"N/A\" # GLOBAL var!\n",
    "\n",
    "def SearchReport(model): \n",
    "    \n",
    "    # This method \n",
    "    def GetBestModelCTOR(model, best_params):\n",
    "        def GetParams(best_params):\n",
    "            ret_str=\"\"          \n",
    "            for key in sorted(best_params):\n",
    "                value = best_params[key]\n",
    "                temp_str = \"'\" if str(type(value))==\"<class 'str'>\" else \"\"\n",
    "                if len(ret_str)>0:\n",
    "                    ret_str += ','\n",
    "                ret_str += f'{key}={temp_str}{value}{temp_str}'  \n",
    "            return ret_str          \n",
    "        try:\n",
    "            param_str = GetParams(best_params)\n",
    "            return type(model).__name__ + '(' + param_str + ')' \n",
    "        except:\n",
    "            return \"N/A(1)\"\n",
    "        \n",
    "    print(\"\\nBest model set found on train set:\")\n",
    "    print()\n",
    "    print(f\"\\tbest parameters={model.best_params_}\")\n",
    "    print(f\"\\tbest '{model.scoring}' score={model.best_score_}\")\n",
    "    print(f\"\\tbest index={model.best_index_}\")\n",
    "    print()\n",
    "    print(f\"Best estimator CTOR:\")\n",
    "    print(f\"\\t{model.best_estimator_}\")\n",
    "    print()\n",
    "    try:\n",
    "        print(f\"Grid scores ('{model.scoring}') on development set:\")\n",
    "        means = model.cv_results_['mean_test_score']\n",
    "        stds  = model.cv_results_['std_test_score']\n",
    "        i=0\n",
    "        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "            print(\"\\t[%2d]: %0.3f (+/-%0.03f) for %r\" % (i, mean, std * 2, params))\n",
    "            i += 1\n",
    "    except:\n",
    "        print(\"WARNING: the random search do not provide means/stds\")\n",
    "    \n",
    "    global currmode                \n",
    "    assert \"f1_micro\"==str(model.scoring), f\"come on, we need to fix the scoring to be able to compare model-fits! Your scoreing={str(model.scoring)}...remember to add scoring='f1_micro' to the search\"   \n",
    "    return f\"best: dat={currmode}, score={model.best_score_:0.5f}, model={GetBestModelCTOR(model.estimator,model.best_params_)}\", model.best_estimator_ \n",
    "\n",
    "def ClassificationReport(model, X_test, y_test, target_names=None):\n",
    "    assert X_test.shape[0]==y_test.shape[0]\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(\"\\tThe model is trained on the full development set.\")\n",
    "    print(\"\\tThe scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)                 \n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    print()\n",
    "    \n",
    "def FullReport(model, X_test, y_test, t):\n",
    "    print(f\"SEARCH TIME: {t:0.2f} sec\")\n",
    "    beststr, bestmodel = SearchReport(model)\n",
    "    ClassificationReport(model, X_test, y_test)    \n",
    "    print(f\"CTOR for best model: {bestmodel}\\n\")\n",
    "    print(f\"{beststr}\\n\")\n",
    "    return beststr, bestmodel\n",
    "    \n",
    "def LoadAndSetupData(mode, test_size=0.3):\n",
    "    assert test_size>=0.0 and test_size<=1.0\n",
    "    \n",
    "    def ShapeToString(Z):\n",
    "        n = Z.ndim\n",
    "        s = \"(\"\n",
    "        for i in range(n):\n",
    "            s += f\"{Z.shape[i]:5d}\"\n",
    "            if i+1!=n:\n",
    "                s += \";\"\n",
    "        return s+\")\"\n",
    "\n",
    "    global currmode\n",
    "    currmode=mode\n",
    "    print(f\"DATA: {currmode}..\")\n",
    "    \n",
    "    if mode=='moon':\n",
    "        X, y = itmaldataloaders.MOON_GetDataSet(n_samples=5000, noise=0.2)\n",
    "        itmaldataloaders.MOON_Plot(X, y)\n",
    "    elif mode=='mnist':\n",
    "        X, y = itmaldataloaders.MNIST_GetDataSet(load_mode=0)\n",
    "        if X.ndim==3:\n",
    "            X=np.reshape(X, (X.shape[0], -1))\n",
    "    elif mode=='iris':\n",
    "        X, y = itmaldataloaders.IRIS_GetDataSet()\n",
    "    else:\n",
    "        raise ValueError(f\"could not load data for that particular mode='{mode}', only 'moon'/'mnist'/'iris' supported\")\n",
    "        \n",
    "    print(f'  org. data:  X.shape      ={ShapeToString(X)}, y.shape      ={ShapeToString(y)}')\n",
    "\n",
    "    assert X.ndim==2\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    assert y.ndim==1 or (y.ndim==2 and y.shape[1]==0)    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f'  train data: X_train.shape={ShapeToString(X_train)}, y_train.shape={ShapeToString(y_train)}')\n",
    "    print(f'  test data:  X_test.shape ={ShapeToString(X_test)}, y_test.shape ={ShapeToString(y_test)}')\n",
    "    print()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def TryKerasImport(verbose=True):\n",
    "    \n",
    "    kerasok = True\n",
    "    try:\n",
    "        import keras as keras_try\n",
    "    except:\n",
    "        kerasok = False\n",
    "\n",
    "    tensorflowkerasok = True\n",
    "    try:\n",
    "        import tensorflow.keras as tensorflowkeras_try\n",
    "    except:\n",
    "        tensorflowkerasok = False\n",
    "        \n",
    "    ok = kerasok or tensorflowkerasok\n",
    "    \n",
    "    if not ok and verbose:\n",
    "        if not kerasok:\n",
    "            print(\"WARNING: importing 'keras' failed\", file=sys.stderr)\n",
    "        if not tensorflowkerasok:\n",
    "            print(\"WARNING: importing 'tensorflow.keras' failed\", file=sys.stderr)\n",
    "\n",
    "    return ok\n",
    "    \n",
    "print(f\"OK(function setup\" + (\"\" if TryKerasImport() else \", hope MNIST loads works because it seems you miss the installation of Keras or Tensorflow!\") + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch is a method for tuning the hyperparameters of a model automatically, and GridSearchCV is the scikit-learn class that provides this functionality. To use GridSearchCV you simply supply it with the parameters you want it to test, and with values that you want to check. After running GridSearchCV.fit() on a dataset, gridsearch will go through all the possible combination of hyperparameters with the values supplied to it and compare their scoring using a scoring method of your choice. When that is done, the best parameters and the scores will be available in the GridSearchCV object. \n",
    "\n",
    "The following code block performs the actual grid search and displays the results using the functions supplied in the previous block. See the code comments for detailed explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n",
      "\n",
      "SEARCH TIME: 2.09 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'C': 1, 'kernel': 'linear'}\n",
      "\tbest 'f1_micro' score=0.9714285714285715\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.962 (+/-0.093) for {'C': 0.1, 'kernel': 'linear'}\n",
      "\t[ 1]: 0.371 (+/-0.038) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "\t[ 2]: 0.971 (+/-0.047) for {'C': 1, 'kernel': 'linear'}\n",
      "\t[ 3]: 0.695 (+/-0.047) for {'C': 1, 'kernel': 'rbf'}\n",
      "\t[ 4]: 0.952 (+/-0.085) for {'C': 10, 'kernel': 'linear'}\n",
      "\t[ 5]: 0.924 (+/-0.097) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "CTOR for best model: SVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "best: dat=iris, score=0.97143, model=SVC(C=1,kernel='linear')\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData('iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# This is the model type we will test\n",
    "model = svm.SVC(\n",
    "    gamma=0.001\n",
    ")\n",
    "\n",
    "# These are the parameters that we want gridsearch to evaluate\n",
    "# They are setup as a Dict[name, vals] with name always being a string and vals being whatever type the parameter values are\n",
    "# In this particular example we will compare kernels 'linear' and 'rbf' against each other with 'C' (the regularization parameter) values being 0.1, 1 and 10\n",
    "# This means the model will be fit 2*3 times \n",
    "tuning_parameters = {\n",
    "    'kernel': ('linear', 'rbf'), \n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# This is the number of KFolds that gridsearch's cross-validation strategy will use\n",
    "CV = 5\n",
    "# Don't display any debug informations\n",
    "VERBOSE = 0\n",
    "\n",
    "# Create gridsearch model with hyperparameters tested specified above\n",
    "# n_jobs is number of jobs ran in parallel when fitting the model: -1 uses all available processors according to sklearn's documentation\n",
    "# job is a somewhat ambiguous term so what exactly this means depends on the backend implementation in sklearn\n",
    "\n",
    "# 'f1_micro' scoring method is defined as the micro-averaged harmonic mean of precision and recall.\n",
    "# According to https://www.visobyte.com/2023/05/precision-recall-and-f1-score-in-object-detection-how-are-they-calculated.html#:~:text=The%20F1%20Score%20is%20a%20harmonic%20mean%20of,%2A%20%28Precision%20%2A%20Recall%29%20%2F%20%28Precision%20%2B%20Recall%29\n",
    "# The precision score measures the rate of false positives and the recall score measures how accurately it predicts/detects \n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "# Find the best parameters and measure the time to do so using X_train, y_train from the iris dataset\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result. Uses previously defined methods to print data about the model. Also runs the best model to predict (X_test, y_test) validating it.\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for our model are C=1 with linear kernel, having a score of 0.97143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Hyperparameter Grid Search using an SDG classifier\n",
    "\n",
    "We will now use grid search to tune parameters of a Stochastic Gradient Descent classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 132.49 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\tbest 'f1_micro' score=0.9904761904761905\n",
      "\tbest index=305\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.01, max_iter=1000000, penalty='l1')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.771 (+/-0.236) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[ 1]: 0.743 (+/-0.328) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[ 2]: 0.819 (+/-0.251) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[ 3]: 0.838 (+/-0.097) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[ 4]: 0.924 (+/-0.076) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[ 5]: 0.819 (+/-0.140) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[ 6]: 0.848 (+/-0.220) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[ 7]: 0.810 (+/-0.269) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[ 8]: 0.819 (+/-0.212) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[ 9]: 0.752 (+/-0.229) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[10]: 0.743 (+/-0.245) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[11]: 0.714 (+/-0.200) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[12]: 0.771 (+/-0.304) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[13]: 0.924 (+/-0.047) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[14]: 0.714 (+/-0.248) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[15]: 0.762 (+/-0.276) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[16]: 0.790 (+/-0.196) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[17]: 0.829 (+/-0.245) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[18]: 0.876 (+/-0.166) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[19]: 0.838 (+/-0.245) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[20]: 0.819 (+/-0.220) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[21]: 0.762 (+/-0.346) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[22]: 0.733 (+/-0.187) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[23]: 0.848 (+/-0.258) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[24]: 0.771 (+/-0.152) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[25]: 0.781 (+/-0.166) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[26]: 0.705 (+/-0.071) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[27]: 0.686 (+/-0.076) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[28]: 0.838 (+/-0.238) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[29]: 0.848 (+/-0.279) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[30]: 0.905 (+/-0.159) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[31]: 0.810 (+/-0.200) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[32]: 0.724 (+/-0.194) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[33]: 0.867 (+/-0.203) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[34]: 0.781 (+/-0.214) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[35]: 0.752 (+/-0.353) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[36]: 0.733 (+/-0.155) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[37]: 0.810 (+/-0.283) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[38]: 0.676 (+/-0.244) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[39]: 0.771 (+/-0.185) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[40]: 0.848 (+/-0.220) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[41]: 0.867 (+/-0.236) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[42]: 0.848 (+/-0.229) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[43]: 0.886 (+/-0.177) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[44]: 0.733 (+/-0.286) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[45]: 0.771 (+/-0.229) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[46]: 0.819 (+/-0.185) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[47]: 0.790 (+/-0.196) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[48]: 0.848 (+/-0.236) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[49]: 0.800 (+/-0.244) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[50]: 0.924 (+/-0.129) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[51]: 0.771 (+/-0.164) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[52]: 0.838 (+/-0.143) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[53]: 0.857 (+/-0.159) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[54]: 0.886 (+/-0.230) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[55]: 0.848 (+/-0.194) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[56]: 0.676 (+/-0.220) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[57]: 0.848 (+/-0.229) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[58]: 0.829 (+/-0.230) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[59]: 0.714 (+/-0.000) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[60]: 0.695 (+/-0.280) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[61]: 0.810 (+/-0.301) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[62]: 0.752 (+/-0.440) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[63]: 0.686 (+/-0.379) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[64]: 0.876 (+/-0.230) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[65]: 0.867 (+/-0.164) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[66]: 0.905 (+/-0.135) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[67]: 0.905 (+/-0.135) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[68]: 0.829 (+/-0.177) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[69]: 0.800 (+/-0.194) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[70]: 0.829 (+/-0.214) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[71]: 0.848 (+/-0.220) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[72]: 0.857 (+/-0.170) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[73]: 0.810 (+/-0.276) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[74]: 0.752 (+/-0.212) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[75]: 0.790 (+/-0.230) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[76]: 0.819 (+/-0.194) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[77]: 0.810 (+/-0.170) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[78]: 0.829 (+/-0.214) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[79]: 0.867 (+/-0.164) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[80]: 0.762 (+/-0.159) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[81]: 0.724 (+/-0.353) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[82]: 0.838 (+/-0.273) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[83]: 0.771 (+/-0.348) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[84]: 0.724 (+/-0.111) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[85]: 0.752 (+/-0.343) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[86]: 0.657 (+/-0.111) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[87]: 0.781 (+/-0.114) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[88]: 0.752 (+/-0.378) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[89]: 0.781 (+/-0.299) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[90]: 0.838 (+/-0.196) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[91]: 0.886 (+/-0.222) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[92]: 0.762 (+/-0.200) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[93]: 0.829 (+/-0.230) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[94]: 0.724 (+/-0.244) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[95]: 0.819 (+/-0.285) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[96]: 0.200 (+/-0.327) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[97]: 0.352 (+/-0.047) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[98]: 0.295 (+/-0.251) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[99]: 0.276 (+/-0.285) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[100]: 0.333 (+/-0.000) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[101]: 0.333 (+/-0.060) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[102]: 0.352 (+/-0.354) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[103]: 0.352 (+/-0.129) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[104]: 0.305 (+/-0.047) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[105]: 0.267 (+/-0.503) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[106]: 0.352 (+/-0.047) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[107]: 0.257 (+/-0.267) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[108]: 0.400 (+/-0.177) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[109]: 0.343 (+/-0.071) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[110]: 0.333 (+/-0.060) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[111]: 0.305 (+/-0.339) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[112]: 0.276 (+/-0.203) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[113]: 0.305 (+/-0.114) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[114]: 0.343 (+/-0.406) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[115]: 0.295 (+/-0.164) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[116]: 0.352 (+/-0.076) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[117]: 0.219 (+/-0.260) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[118]: 0.419 (+/-0.304) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[119]: 0.362 (+/-0.097) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[120]: 0.438 (+/-0.279) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[121]: 0.476 (+/-0.356) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[122]: 0.390 (+/-0.236) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[123]: 0.352 (+/-0.076) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[124]: 0.381 (+/-0.248) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[125]: 0.400 (+/-0.322) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[126]: 0.410 (+/-0.311) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[127]: 0.419 (+/-0.304) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[128]: 0.343 (+/-0.071) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[129]: 0.333 (+/-0.060) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[130]: 0.429 (+/-0.276) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[131]: 0.448 (+/-0.205) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[132]: 0.371 (+/-0.111) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[133]: 0.352 (+/-0.047) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[134]: 0.371 (+/-0.071) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[135]: 0.295 (+/-0.038) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[136]: 0.352 (+/-0.196) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[137]: 0.324 (+/-0.038) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[138]: 0.467 (+/-0.338) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[139]: 0.343 (+/-0.071) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[140]: 0.343 (+/-0.111) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[141]: 0.324 (+/-0.071) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[142]: 0.486 (+/-0.343) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[143]: 0.352 (+/-0.222) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[144]: 0.790 (+/-0.187) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[145]: 0.876 (+/-0.177) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[146]: 0.924 (+/-0.076) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[147]: 0.790 (+/-0.196) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[148]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[149]: 0.924 (+/-0.214) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[150]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[151]: 0.943 (+/-0.093) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[152]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[153]: 0.857 (+/-0.209) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[154]: 0.781 (+/-0.166) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[155]: 0.933 (+/-0.076) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[156]: 0.848 (+/-0.194) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[157]: 0.876 (+/-0.177) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[158]: 0.838 (+/-0.177) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[159]: 0.800 (+/-0.126) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[160]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[161]: 0.905 (+/-0.159) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[162]: 0.962 (+/-0.038) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[163]: 0.914 (+/-0.126) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[164]: 0.905 (+/-0.190) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[165]: 0.819 (+/-0.194) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[166]: 0.876 (+/-0.230) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[167]: 0.876 (+/-0.177) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[168]: 0.762 (+/-0.085) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[169]: 0.848 (+/-0.279) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[170]: 0.781 (+/-0.354) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[171]: 0.762 (+/-0.467) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[172]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[173]: 0.981 (+/-0.047) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[174]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[175]: 0.933 (+/-0.047) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[176]: 0.819 (+/-0.212) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[177]: 0.762 (+/-0.159) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[178]: 0.848 (+/-0.220) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[179]: 0.790 (+/-0.177) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[180]: 0.876 (+/-0.245) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[181]: 0.714 (+/-0.390) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[182]: 0.714 (+/-0.060) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[183]: 0.829 (+/-0.238) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[184]: 0.924 (+/-0.076) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[185]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[186]: 0.924 (+/-0.129) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[187]: 0.952 (+/-0.085) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[188]: 0.857 (+/-0.263) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[189]: 0.867 (+/-0.140) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[190]: 0.848 (+/-0.185) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[191]: 0.810 (+/-0.248) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[192]: 0.810 (+/-0.283) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[193]: 0.819 (+/-0.093) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[194]: 0.800 (+/-0.220) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[195]: 0.781 (+/-0.253) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[196]: 0.886 (+/-0.187) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[197]: 0.981 (+/-0.047) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[198]: 0.848 (+/-0.152) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[199]: 0.933 (+/-0.076) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[200]: 0.867 (+/-0.285) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[201]: 0.810 (+/-0.301) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[202]: 0.829 (+/-0.238) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[203]: 0.819 (+/-0.175) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[204]: 0.895 (+/-0.203) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[205]: 0.810 (+/-0.209) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[206]: 0.800 (+/-0.185) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[207]: 0.905 (+/-0.209) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[208]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[209]: 0.962 (+/-0.071) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[210]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[211]: 0.933 (+/-0.129) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[212]: 0.924 (+/-0.097) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[213]: 0.924 (+/-0.222) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[214]: 0.886 (+/-0.187) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[215]: 0.743 (+/-0.416) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[216]: 0.838 (+/-0.333) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[217]: 0.695 (+/-0.273) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[218]: 0.857 (+/-0.241) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[219]: 0.790 (+/-0.245) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[220]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[221]: 0.962 (+/-0.038) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[222]: 0.933 (+/-0.076) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[223]: 0.867 (+/-0.164) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[224]: 0.829 (+/-0.245) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[225]: 0.848 (+/-0.203) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[226]: 0.819 (+/-0.194) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[227]: 0.867 (+/-0.185) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[228]: 0.810 (+/-0.135) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[229]: 0.867 (+/-0.220) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[230]: 0.886 (+/-0.230) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[231]: 0.848 (+/-0.152) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[232]: 0.848 (+/-0.229) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[233]: 0.924 (+/-0.114) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[234]: 0.876 (+/-0.196) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[235]: 0.952 (+/-0.060) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[236]: 0.905 (+/-0.159) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[237]: 0.829 (+/-0.222) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[238]: 0.819 (+/-0.304) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[239]: 0.886 (+/-0.196) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[240]: 0.248 (+/-0.251) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[241]: 0.362 (+/-0.047) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[242]: 0.305 (+/-0.299) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[243]: 0.333 (+/-0.085) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[244]: 0.314 (+/-0.393) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[245]: 0.267 (+/-0.273) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[246]: 0.352 (+/-0.047) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[247]: 0.333 (+/-0.395) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[248]: 0.362 (+/-0.129) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[249]: 0.314 (+/-0.047) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[250]: 0.324 (+/-0.038) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[251]: 0.257 (+/-0.260) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[252]: 0.352 (+/-0.076) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[253]: 0.343 (+/-0.071) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[254]: 0.324 (+/-0.071) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[255]: 0.171 (+/-0.273) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[256]: 0.305 (+/-0.129) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[257]: 0.324 (+/-0.397) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[258]: 0.362 (+/-0.453) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[259]: 0.314 (+/-0.047) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[260]: 0.352 (+/-0.047) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[261]: 0.333 (+/-0.060) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[262]: 0.410 (+/-0.311) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[263]: 0.295 (+/-0.038) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[264]: 0.676 (+/-0.071) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[265]: 0.695 (+/-0.143) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[266]: 0.676 (+/-0.071) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[267]: 0.371 (+/-0.251) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[268]: 0.638 (+/-0.344) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[269]: 0.695 (+/-0.214) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[270]: 0.590 (+/-0.230) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[271]: 0.524 (+/-0.313) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[272]: 0.638 (+/-0.322) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[273]: 0.705 (+/-0.229) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[274]: 0.486 (+/-0.304) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[275]: 0.486 (+/-0.327) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[276]: 0.562 (+/-0.304) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[277]: 0.524 (+/-0.263) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[278]: 0.676 (+/-0.093) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[279]: 0.429 (+/-0.289) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[280]: 0.657 (+/-0.236) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[281]: 0.648 (+/-0.143) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[282]: 0.686 (+/-0.322) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[283]: 0.571 (+/-0.467) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[284]: 0.667 (+/-0.120) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[285]: 0.619 (+/-0.335) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[286]: 0.610 (+/-0.348) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[287]: 0.476 (+/-0.439) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[288]: 0.819 (+/-0.236) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[289]: 0.781 (+/-0.205) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[290]: 0.933 (+/-0.143) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[291]: 0.876 (+/-0.177) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[292]: 0.952 (+/-0.085) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[293]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[294]: 0.952 (+/-0.060) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[295]: 0.952 (+/-0.085) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[296]: 0.819 (+/-0.265) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[297]: 0.838 (+/-0.238) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[298]: 0.933 (+/-0.129) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[299]: 0.924 (+/-0.222) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[300]: 0.867 (+/-0.203) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[301]: 0.867 (+/-0.236) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[302]: 0.886 (+/-0.196) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[303]: 0.695 (+/-0.305) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[304]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[305]: 0.990 (+/-0.038) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[306]: 0.962 (+/-0.071) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[307]: 0.943 (+/-0.093) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[308]: 0.876 (+/-0.230) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[309]: 0.810 (+/-0.135) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[310]: 0.876 (+/-0.166) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[311]: 0.905 (+/-0.060) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[312]: 0.905 (+/-0.135) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[313]: 0.857 (+/-0.135) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[314]: 0.895 (+/-0.236) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[315]: 0.886 (+/-0.143) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[316]: 0.990 (+/-0.038) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[317]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[318]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[319]: 0.971 (+/-0.076) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[320]: 0.943 (+/-0.071) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[321]: 0.943 (+/-0.111) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[322]: 0.886 (+/-0.280) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[323]: 0.895 (+/-0.126) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[324]: 0.952 (+/-0.104) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[325]: 0.952 (+/-0.085) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[326]: 0.895 (+/-0.152) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[327]: 0.886 (+/-0.230) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[328]: 0.981 (+/-0.076) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[329]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[330]: 0.962 (+/-0.071) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[331]: 0.962 (+/-0.071) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[332]: 0.829 (+/-0.177) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[333]: 0.905 (+/-0.217) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[334]: 0.895 (+/-0.194) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[335]: 0.962 (+/-0.071) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[336]: 0.943 (+/-0.093) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[337]: 0.905 (+/-0.170) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[338]: 0.829 (+/-0.129) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[339]: 0.876 (+/-0.155) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[340]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[341]: 0.943 (+/-0.140) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[342]: 0.981 (+/-0.076) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[343]: 0.971 (+/-0.076) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[344]: 0.943 (+/-0.140) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[345]: 0.952 (+/-0.104) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[346]: 0.867 (+/-0.111) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[347]: 0.724 (+/-0.071) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[348]: 0.810 (+/-0.104) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[349]: 0.810 (+/-0.241) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[350]: 0.819 (+/-0.258) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[351]: 0.857 (+/-0.241) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[352]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[353]: 0.990 (+/-0.038) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[354]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[355]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[356]: 0.867 (+/-0.203) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[357]: 0.895 (+/-0.194) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[358]: 0.838 (+/-0.187) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[359]: 0.886 (+/-0.280) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[360]: 0.895 (+/-0.203) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[361]: 0.838 (+/-0.260) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[362]: 0.829 (+/-0.155) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[363]: 0.943 (+/-0.071) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[364]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[365]: 0.962 (+/-0.071) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[366]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[367]: 0.981 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[368]: 0.895 (+/-0.164) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[369]: 0.914 (+/-0.175) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[370]: 0.943 (+/-0.111) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[371]: 0.829 (+/-0.129) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[372]: 0.924 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[373]: 0.810 (+/-0.269) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[374]: 0.810 (+/-0.269) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[375]: 0.876 (+/-0.230) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[376]: 0.952 (+/-0.104) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[377]: 0.990 (+/-0.038) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[378]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[379]: 0.971 (+/-0.047) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[380]: 0.952 (+/-0.085) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[381]: 0.838 (+/-0.299) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[382]: 0.905 (+/-0.135) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[383]: 0.829 (+/-0.076) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[384]: 0.371 (+/-0.140) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[385]: 0.305 (+/-0.129) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[386]: 0.295 (+/-0.071) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[387]: 0.219 (+/-0.114) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[388]: 0.286 (+/-0.181) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[389]: 0.267 (+/-0.129) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[390]: 0.248 (+/-0.164) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[391]: 0.381 (+/-0.209) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[392]: 0.324 (+/-0.220) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[393]: 0.324 (+/-0.111) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[394]: 0.286 (+/-0.209) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[395]: 0.324 (+/-0.279) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[396]: 0.333 (+/-0.104) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[397]: 0.419 (+/-0.126) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[398]: 0.390 (+/-0.093) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[399]: 0.305 (+/-0.196) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[400]: 0.343 (+/-0.111) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[401]: 0.305 (+/-0.205) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[402]: 0.295 (+/-0.229) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[403]: 0.305 (+/-0.097) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[404]: 0.314 (+/-0.097) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[405]: 0.410 (+/-0.166) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[406]: 0.343 (+/-0.093) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[407]: 0.352 (+/-0.222) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[408]: 0.714 (+/-0.060) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[409]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[410]: 0.676 (+/-0.071) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[411]: 0.657 (+/-0.348) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[412]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[413]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[414]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[415]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[416]: 0.714 (+/-0.060) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[417]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[418]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[419]: 0.619 (+/-0.324) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[420]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[421]: 0.733 (+/-0.177) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[422]: 0.714 (+/-0.060) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[423]: 0.514 (+/-0.338) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[424]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[425]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[426]: 0.648 (+/-0.129) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[427]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[428]: 0.695 (+/-0.047) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[429]: 0.705 (+/-0.071) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[430]: 0.705 (+/-0.164) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[431]: 0.600 (+/-0.273) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[432]: 0.771 (+/-0.185) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[433]: 0.838 (+/-0.196) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[434]: 0.848 (+/-0.265) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[435]: 0.714 (+/-0.104) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[436]: 0.705 (+/-0.038) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[437]: 0.810 (+/-0.120) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[438]: 0.838 (+/-0.076) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[439]: 0.943 (+/-0.093) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[440]: 0.829 (+/-0.166) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[441]: 0.771 (+/-0.164) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[442]: 0.743 (+/-0.076) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[443]: 0.790 (+/-0.205) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[444]: 0.829 (+/-0.230) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[445]: 0.752 (+/-0.111) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[446]: 0.819 (+/-0.220) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[447]: 0.752 (+/-0.251) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[448]: 0.819 (+/-0.220) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[449]: 0.829 (+/-0.129) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[450]: 0.752 (+/-0.152) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[451]: 0.762 (+/-0.200) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[452]: 0.838 (+/-0.205) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[453]: 0.724 (+/-0.038) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[454]: 0.810 (+/-0.104) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[455]: 0.819 (+/-0.298) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[456]: 0.800 (+/-0.251) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[457]: 0.743 (+/-0.129) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[458]: 0.857 (+/-0.283) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[459]: 0.781 (+/-0.238) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[460]: 0.810 (+/-0.209) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[461]: 0.800 (+/-0.175) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[462]: 0.781 (+/-0.076) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[463]: 0.829 (+/-0.177) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[464]: 0.800 (+/-0.220) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[465]: 0.810 (+/-0.120) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[466]: 0.771 (+/-0.140) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[467]: 0.781 (+/-0.155) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[468]: 0.819 (+/-0.220) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[469]: 0.790 (+/-0.177) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[470]: 0.819 (+/-0.212) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[471]: 0.914 (+/-0.071) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[472]: 0.810 (+/-0.159) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[473]: 0.733 (+/-0.047) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[474]: 0.733 (+/-0.097) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[475]: 0.790 (+/-0.155) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[476]: 0.781 (+/-0.143) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[477]: 0.762 (+/-0.060) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[478]: 0.733 (+/-0.076) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[479]: 0.829 (+/-0.245) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[480]: 0.886 (+/-0.196) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[481]: 0.848 (+/-0.244) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[482]: 0.800 (+/-0.229) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[483]: 0.695 (+/-0.328) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[484]: 0.886 (+/-0.114) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[485]: 0.933 (+/-0.076) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[486]: 0.914 (+/-0.071) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[487]: 0.876 (+/-0.177) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[488]: 0.857 (+/-0.170) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[489]: 0.867 (+/-0.152) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[490]: 0.743 (+/-0.222) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[491]: 0.705 (+/-0.348) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[492]: 0.857 (+/-0.269) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[493]: 0.810 (+/-0.209) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[494]: 0.810 (+/-0.135) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[495]: 0.810 (+/-0.209) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[496]: 0.962 (+/-0.038) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[497]: 0.914 (+/-0.071) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[498]: 0.867 (+/-0.126) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[499]: 0.848 (+/-0.212) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[500]: 0.848 (+/-0.236) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[501]: 0.876 (+/-0.230) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[502]: 0.829 (+/-0.166) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[503]: 0.790 (+/-0.155) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[504]: 0.933 (+/-0.114) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[505]: 0.876 (+/-0.222) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[506]: 0.914 (+/-0.126) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[507]: 0.867 (+/-0.203) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[508]: 0.990 (+/-0.038) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[509]: 0.971 (+/-0.047) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[510]: 0.962 (+/-0.071) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[511]: 0.952 (+/-0.060) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[512]: 0.838 (+/-0.214) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[513]: 0.924 (+/-0.260) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[514]: 0.905 (+/-0.120) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[515]: 0.914 (+/-0.093) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[516]: 0.933 (+/-0.097) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[517]: 0.943 (+/-0.071) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[518]: 0.848 (+/-0.111) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[519]: 0.895 (+/-0.203) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[520]: 0.971 (+/-0.076) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[521]: 0.971 (+/-0.047) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[522]: 0.962 (+/-0.071) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[523]: 0.981 (+/-0.076) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[524]: 0.943 (+/-0.071) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[525]: 0.905 (+/-0.159) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[526]: 0.924 (+/-0.097) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[527]: 0.914 (+/-0.212) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[528]: 0.276 (+/-0.185) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[529]: 0.286 (+/-0.085) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[530]: 0.305 (+/-0.129) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[531]: 0.390 (+/-0.244) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[532]: 0.267 (+/-0.196) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[533]: 0.286 (+/-0.248) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[534]: 0.352 (+/-0.238) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[535]: 0.276 (+/-0.140) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[536]: 0.343 (+/-0.152) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[537]: 0.352 (+/-0.177) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[538]: 0.352 (+/-0.166) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[539]: 0.352 (+/-0.097) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[540]: 0.390 (+/-0.140) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[541]: 0.286 (+/-0.159) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[542]: 0.267 (+/-0.076) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[543]: 0.352 (+/-0.196) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[544]: 0.267 (+/-0.177) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[545]: 0.371 (+/-0.220) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[546]: 0.343 (+/-0.140) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[547]: 0.333 (+/-0.085) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[548]: 0.362 (+/-0.129) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[549]: 0.305 (+/-0.097) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[550]: 0.324 (+/-0.152) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[551]: 0.352 (+/-0.155) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[552]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[553]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[554]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[555]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[556]: 0.581 (+/-0.140) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[557]: 0.438 (+/-0.304) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[558]: 0.467 (+/-0.251) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[559]: 0.524 (+/-0.248) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[560]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[561]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[562]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[563]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[564]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[565]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[566]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[567]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[568]: 0.581 (+/-0.194) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[569]: 0.467 (+/-0.279) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[570]: 0.514 (+/-0.321) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[571]: 0.476 (+/-0.248) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[572]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[573]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[574]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[575]: 0.695 (+/-0.047) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[576]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[577]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[578]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[579]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[580]: 0.590 (+/-0.273) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[581]: 0.648 (+/-0.177) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[582]: 0.457 (+/-0.222) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[583]: 0.552 (+/-0.214) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[584]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[585]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[586]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[587]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[588]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[589]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[590]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[591]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[592]: 0.543 (+/-0.354) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[593]: 0.543 (+/-0.384) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[594]: 0.676 (+/-0.093) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[595]: 0.514 (+/-0.304) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[596]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[597]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[598]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[599]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[600]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[601]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[602]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[603]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[604]: 0.419 (+/-0.304) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[605]: 0.571 (+/-0.319) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[606]: 0.533 (+/-0.304) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[607]: 0.438 (+/-0.279) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[608]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[609]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[610]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[611]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[612]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[613]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[614]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[615]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[616]: 0.505 (+/-0.305) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[617]: 0.438 (+/-0.279) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[618]: 0.438 (+/-0.279) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[619]: 0.419 (+/-0.304) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[620]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[621]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[622]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[623]: 0.686 (+/-0.076) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[624]: 0.838 (+/-0.238) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[625]: 0.762 (+/-0.301) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[626]: 0.790 (+/-0.305) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[627]: 0.752 (+/-0.236) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[628]: 0.314 (+/-0.076) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[629]: 0.305 (+/-0.047) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[630]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[631]: 0.343 (+/-0.071) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[632]: 0.705 (+/-0.378) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[633]: 0.733 (+/-0.097) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[634]: 0.667 (+/-0.371) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[635]: 0.590 (+/-0.230) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[636]: 0.790 (+/-0.328) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[637]: 0.762 (+/-0.217) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[638]: 0.790 (+/-0.322) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[639]: 0.714 (+/-0.060) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[640]: 0.343 (+/-0.071) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[641]: 0.324 (+/-0.038) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[642]: 0.314 (+/-0.076) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[643]: 0.333 (+/-0.000) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[644]: 0.743 (+/-0.253) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[645]: 0.590 (+/-0.143) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[646]: 0.705 (+/-0.236) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[647]: 0.705 (+/-0.279) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[648]: 0.771 (+/-0.212) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[649]: 0.771 (+/-0.236) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[650]: 0.762 (+/-0.104) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[651]: 0.790 (+/-0.245) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[652]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[653]: 0.705 (+/-0.071) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[654]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[655]: 0.724 (+/-0.140) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[656]: 0.743 (+/-0.166) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[657]: 0.771 (+/-0.194) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[658]: 0.771 (+/-0.111) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[659]: 0.743 (+/-0.214) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[660]: 0.733 (+/-0.143) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[661]: 0.705 (+/-0.038) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[662]: 0.781 (+/-0.129) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[663]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[664]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[665]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[666]: 0.724 (+/-0.140) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[667]: 0.705 (+/-0.038) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[668]: 0.714 (+/-0.060) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[669]: 0.781 (+/-0.143) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[670]: 0.771 (+/-0.175) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[671]: 0.705 (+/-0.071) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[672]: 0.219 (+/-0.273) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[673]: 0.190 (+/-0.148) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[674]: 0.390 (+/-0.272) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[675]: 0.324 (+/-0.152) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[676]: 0.410 (+/-0.196) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[677]: 0.352 (+/-0.230) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[678]: 0.390 (+/-0.152) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[679]: 0.324 (+/-0.203) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[680]: 0.324 (+/-0.279) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[681]: 0.400 (+/-0.339) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[682]: 0.305 (+/-0.393) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[683]: 0.343 (+/-0.315) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[684]: 0.371 (+/-0.236) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[685]: 0.219 (+/-0.364) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[686]: 0.400 (+/-0.420) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[687]: 0.324 (+/-0.315) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[688]: 0.400 (+/-0.177) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[689]: 0.352 (+/-0.196) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[690]: 0.257 (+/-0.187) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[691]: 0.295 (+/-0.315) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[692]: 0.410 (+/-0.311) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[693]: 0.314 (+/-0.177) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[694]: 0.352 (+/-0.339) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[695]: 0.410 (+/-0.293) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[696]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[697]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[698]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[699]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[700]: 0.343 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[701]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[702]: 0.343 (+/-0.071) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[703]: 0.362 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[704]: 0.352 (+/-0.076) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[705]: 0.352 (+/-0.076) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[706]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[707]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[708]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[709]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[710]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[711]: 0.695 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[712]: 0.362 (+/-0.047) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[713]: 0.352 (+/-0.076) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[714]: 0.343 (+/-0.071) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[715]: 0.333 (+/-0.085) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[716]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[717]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[718]: 0.352 (+/-0.076) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[719]: 0.371 (+/-0.038) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[720]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[721]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[722]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[723]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[724]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[725]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[726]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[727]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[728]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[729]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[730]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[731]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[732]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[733]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[734]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[735]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[736]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[737]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[738]: 0.343 (+/-0.038) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[739]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[740]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[741]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[742]: 0.343 (+/-0.038) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[743]: 0.343 (+/-0.038) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[744]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[745]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[746]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[747]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[748]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[749]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[750]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[751]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[752]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[753]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[754]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[755]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[756]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[757]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[758]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[759]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[760]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[761]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[762]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[763]: 0.324 (+/-0.038) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[764]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[765]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[766]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[767]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[768]: 0.457 (+/-0.273) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[769]: 0.495 (+/-0.286) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[770]: 0.543 (+/-0.238) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[771]: 0.438 (+/-0.185) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[772]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[773]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[774]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[775]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[776]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[777]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[778]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[779]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[780]: 0.381 (+/-0.085) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[781]: 0.429 (+/-0.241) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[782]: 0.438 (+/-0.185) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[783]: 0.390 (+/-0.185) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[784]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[785]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[786]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[787]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[788]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[789]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[790]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[791]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[792]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[793]: 0.419 (+/-0.203) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[794]: 0.390 (+/-0.194) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[795]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[796]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[797]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[798]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[799]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[800]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[801]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[802]: 0.324 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[803]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[804]: 0.390 (+/-0.140) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[805]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[806]: 0.438 (+/-0.203) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[807]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[808]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[809]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[810]: 0.343 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[811]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[812]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[813]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[814]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[815]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[816]: 0.333 (+/-0.120) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[817]: 0.381 (+/-0.200) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[818]: 0.438 (+/-0.185) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[819]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[820]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[821]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[822]: 0.352 (+/-0.047) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[823]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[824]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[825]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[826]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[827]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[828]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[829]: 0.410 (+/-0.129) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[830]: 0.371 (+/-0.093) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[831]: 0.448 (+/-0.267) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[832]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[833]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[834]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[835]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[836]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[837]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[838]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[839]: 0.305 (+/-0.047) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[840]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[841]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[842]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[843]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[844]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[845]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[846]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[847]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[848]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[849]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[850]: 0.343 (+/-0.038) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[851]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[852]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[853]: 0.333 (+/-0.085) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[854]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[855]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[856]: 0.333 (+/-0.060) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[857]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[858]: 0.314 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[859]: 0.362 (+/-0.047) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[860]: 0.371 (+/-0.038) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[861]: 0.352 (+/-0.076) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[862]: 0.343 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[863]: 0.324 (+/-0.071) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.01, max_iter=1000000, penalty='l1')\n",
      "\n",
      "best: dat=iris, score=0.99048, model=SGDClassifier(alpha=0.01,loss='hinge',max_iter=1000000,penalty='l1',tol=0.001)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "sgd = linear_model.SGDClassifier()\n",
    "\n",
    "# Notice different parameters, check sklearn documentation for SGDClassifier for description of these parameters\n",
    "tuning_parameters = {\n",
    "    'loss': ['hinge', 'log_loss', 'perceptron', 'modified_huber', 'squared_error', 'huber'], \n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 100],\n",
    "    'tol' : [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter' : [int(1e+5), int(1e+6)]\n",
    "}\n",
    "\n",
    "# This part is almost the same as in previous code block, we just swap the model\n",
    "grid_tuned = GridSearchCV(sgd,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model has a staggering score of 0.99048, even better than the SVC model we used previously! It did take a few minutes though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc Hyperparameter Random  Search using an SDG classifier\n",
    "\n",
    "Another method of finding the optimal parameters is to uze RandomizedSearchCV. In contrast to GridSearchCV it only chooses a few randomly selected samples of each hyperparameter provided, controlled by its own parameter 'n_iter'. This makes it potentially faster then GridSearchCV, but the results might not give the best scores. \n",
    "\n",
    "Below is an implementation and a test run of a RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 0.13 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'tol': 0.01, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 0.001}\n",
      "\tbest 'f1_micro' score=0.9714285714285715\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=0.001, loss='perceptron', max_iter=100000, penalty='l1',\n",
      "              tol=0.01)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.971 (+/-0.047) for {'tol': 0.01, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 0.001}\n",
      "\t[ 1]: 0.438 (+/-0.229) for {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'hinge', 'alpha': 100}\n",
      "\t[ 2]: 0.762 (+/-0.233) for {'tol': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 1}\n",
      "\t[ 3]: 0.914 (+/-0.126) for {'tol': 0.001, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'hinge', 'alpha': 0.01}\n",
      "\t[ 4]: 0.867 (+/-0.203) for {'tol': 0.1, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'hinge', 'alpha': 0.0001}\n",
      "\t[ 5]: 0.886 (+/-0.129) for {'tol': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'hinge', 'alpha': 0.01}\n",
      "\t[ 6]: 0.533 (+/-0.265) for {'tol': 0.001, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'hinge', 'alpha': 1}\n",
      "\t[ 7]: 0.857 (+/-0.248) for {'tol': 0.01, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'hinge', 'alpha': 0.01}\n",
      "\t[ 8]: 0.886 (+/-0.097) for {'tol': 0.001, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 0.1}\n",
      "\t[ 9]: 0.810 (+/-0.248) for {'tol': 0.001, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 1}\n",
      "\t[10]: 0.352 (+/-0.238) for {'tol': 0.001, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'squared_error', 'alpha': 0.01}\n",
      "\t[11]: 0.343 (+/-0.071) for {'tol': 0.01, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 100}\n",
      "\t[12]: 0.352 (+/-0.047) for {'tol': 0.1, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'alpha': 1}\n",
      "\t[13]: 0.743 (+/-0.076) for {'tol': 0.0001, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'log_loss', 'alpha': 0.1}\n",
      "\t[14]: 0.352 (+/-0.344) for {'tol': 0.01, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'squared_error', 'alpha': 1}\n",
      "\t[15]: 0.352 (+/-0.076) for {'tol': 0.001, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'log_loss', 'alpha': 100}\n",
      "\t[16]: 0.838 (+/-0.205) for {'tol': 0.1, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'perceptron', 'alpha': 0.0001}\n",
      "\t[17]: 0.324 (+/-0.071) for {'tol': 0.001, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'huber', 'alpha': 100}\n",
      "\t[18]: 0.371 (+/-0.038) for {'tol': 0.0001, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'huber', 'alpha': 1}\n",
      "\t[19]: 0.286 (+/-0.148) for {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'squared_error', 'alpha': 0.0001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.85      0.94      0.89        18\n",
      "           2       0.89      0.73      0.80        11\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.91      0.89      0.90        45\n",
      "weighted avg       0.91      0.91      0.91        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=0.001, loss='perceptron', max_iter=100000, penalty='l1',\n",
      "              tol=0.01)\n",
      "\n",
      "best: dat=iris, score=0.97143, model=SGDClassifier(alpha=0.001,loss='perceptron',max_iter=100000,penalty='l1',tol=0.01)\n",
      "\n",
      "OK(random-search)\n"
     ]
    }
   ],
   "source": [
    "random_tuned = RandomizedSearchCV(\n",
    "    sgd, \n",
    "    tuning_parameters, \n",
    "    # Pick up to 20 different samples\n",
    "    n_iter=20, \n",
    "    # same state should give same rng distribution\n",
    "    random_state=42, \n",
    "    cv=CV, \n",
    "    scoring='f1_micro', \n",
    "    verbose=VERBOSE, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start = time()\n",
    "random_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(random_tuned, X_test, y_test, t)\n",
    "print('OK(random-search)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the output that only 20 different combinations of parameters were tested, and the best parameters were not the same as in GridSearchCV test. The f1_score is also lower at 0.914 instead of 0.990. This could potentially be improved by adding more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qd MNIST Search Quest II\n",
    "\n",
    "Finally, a search-quest competition: __who can find the best model+hyperparameters for the MNIST dataset?__\n",
    "\n",
    "You change to the MNIST data by calling `LoadAndSetupData('mnist')`, and this is a completely other ball-game that the iris _tiny-data_: it's much larger (but still far from _big-data_)!\n",
    "\n",
    "* You might opt for the exhaustive grid search, or use the faster but-less optimal random search...your choice. \n",
    "\n",
    "* You are free to pick any classifier in Scikit-learn, even algorithms we have not discussed yet---__except Neural Networks and KNeighborsClassifier!__. \n",
    "\n",
    "* Keep the score function at `f1_micro`, otherwise, we will be comparing 'æbler og pærer'. \n",
    "\n",
    "* And, you may also want to scale your input data for some models to perform better.\n",
    "\n",
    "* __REMEMBER__, DO NOT USE any Neural Network models. This also means not to use any `Keras` or `Tensorflow` models...since they outperform most other models, and there are also too many examples on the internet to cut-and-paste from!\n",
    "\n",
    "Check your result by printing the first _return_ value from `FullReport()` \n",
    "```python \n",
    "b1, m1 = FullReport(random_tuned , X_test, y_test, time_randomsearch)\n",
    "print(b1)\n",
    "```\n",
    "that will display a result like\n",
    "```\n",
    "best: dat=mnist, score=0.90780, model=SGDClassifier(alpha=1.0,eta0=0.0001,learning_rate='invscaling')\n",
    "```\n",
    "and paste your currently best model into the message box, for ITMAL group 09 like\n",
    "```\n",
    "Grp09: best: dat=mnist, score=0.90780, model=SGDClassifier(alpha=1.0,eta0=0.0001,learning_rate='invscaling')\n",
    "\n",
    "Grp09: CTOR for best model: SGDClassifier(alpha=1.0, average=False, class_weight=None, early_stopping=False,\n",
    "              epsilon=0.1, eta0=0.0001, fit_intercept=True, l1_ratio=0.15,\n",
    "              learning_rate='invscaling', loss='hinge', max_iter=1000,\n",
    "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
    "              random_state=None, shuffle=True, tol=0.001,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "```\n",
    "              \n",
    "on Brightspace: \"L09: Regularisering, optimering og søgning\" | \"Qd MNIST Search Quest\"\n",
    "\n",
    "> https://itundervisning.ase.au.dk/itmal_quest/index.php\n",
    "\n",
    "and, check if your score (for MNIST) is better than the currently best score. Republish if you get a better score than your own previously best. Deadline for submission of scores is the same as the deadline for the O3 journal handin.\n",
    "\n",
    "Remember to provide an ITMAL group name manually, so we can identify a winner: the 1. st price is  cake! \n",
    "\n",
    "For the journal hand-in, report your progress in scoring choosing different models, hyperparameters to search and how you might need to preprocess your data...and note, that the journal will not be accepted unless it contains information about Your results published on the Brightspace 'Search Quest II' page!\n",
    "\n",
    "It's time to embark on an epic adventure of finding the best model for the MNIST dataset. Here we will use gridsearch on several models to attempt to find the best model according to the f1_micro scoring metric. The best scores across different groups will then be compared to each other. May the best man win!\n",
    "\n",
    "In our first try, we'd like to test how fast the gridsearch performs, so we're gonna use a RandomizedSearchCV with our existing SGDClassifier, and check the time with a few number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: mnist..\n",
      "  org. data:  X.shape      =(70000;  784), y.shape      =(70000)\n",
      "  train data: X_train.shape=(49000;  784), y_train.shape=(49000)\n",
      "  test data:  X_test.shape =(21000;  784), y_test.shape =(21000)\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Parameter grid for parameter 'max_iter' is not iterable or a distribution (value=100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\UNI_2023\\ml\\swmal_grp10\\O3\\gridsearch_ans.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m random_tuned \u001b[39m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     sgd, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     tuning_parameters, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m random_tuned\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m t \u001b[39m=\u001b[39m time() \u001b[39m-\u001b[39m start\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/UNI_2023/ml/swmal_grp10/O3/gridsearch_ans.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m b0, m0 \u001b[39m=\u001b[39m FullReport(random_tuned, X_test, y_test, t)\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\envs\\swmal\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\envs\\swmal\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\envs\\swmal\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1807\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1805\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m   1806\u001b[0m     evaluate_candidates(\n\u001b[1;32m-> 1807\u001b[0m         ParameterSampler(\n\u001b[0;32m   1808\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1809\u001b[0m         )\n\u001b[0;32m   1810\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nastr\\anaconda3\\envs\\swmal\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281\u001b[0m, in \u001b[0;36mParameterSampler.__init__\u001b[1;34m(self, param_distributions, n_iter, random_state)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m dist:\n\u001b[0;32m    278\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dist[key], Iterable) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[0;32m    279\u001b[0m             dist[key], \u001b[39m\"\u001b[39m\u001b[39mrvs\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         ):\n\u001b[1;32m--> 281\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    282\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter grid for parameter \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m is not iterable \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mor a distribution (value=\u001b[39m\u001b[39m{\u001b[39;00mdist[key]\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m             )\n\u001b[0;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m=\u001b[39m n_iter\n\u001b[0;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state \u001b[39m=\u001b[39m random_state\n",
      "\u001b[1;31mTypeError\u001b[0m: Parameter grid for parameter 'max_iter' is not iterable or a distribution (value=100)"
     ]
    }
   ],
   "source": [
    "# Load mnist data separate block, since this can take extra time\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData('mnist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice different parameters, check sklearn documentation for SGDClassifier for description of these parameters\n",
    "tuning_parameters = {\n",
    "    'loss': ['hinge', 'log_loss', 'perceptron', 'modified_huber', 'squared_error', 'huber'], \n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 100],\n",
    "    'tol' : [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter' : [int(1e+5), int(1e+6)]\n",
    "}\n",
    "\n",
    "# This part is almost the same as in previous code block, we just swap the model\n",
    "grid_tuned = GridSearchCV(sgd,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 403.00 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'tol': 0.01, 'penalty': 'l1', 'max_iter': 100, 'loss': 'perceptron', 'alpha': 0.0001}\n",
      "\tbest 'f1_micro' score=0.8799999999999999\n",
      "\tbest index=3\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(loss='perceptron', max_iter=100, penalty='l1', tol=0.01)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.098 (+/-0.008) for {'tol': 0.0001, 'penalty': 'l1', 'max_iter': 100, 'loss': 'huber', 'alpha': 100}\n",
      "\t[ 1]: 0.877 (+/-0.019) for {'tol': 0.1, 'penalty': 'l2', 'max_iter': 100, 'loss': 'hinge', 'alpha': 0.001}\n",
      "\t[ 2]: 0.873 (+/-0.031) for {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 100, 'loss': 'modified_huber', 'alpha': 0.01}\n",
      "\t[ 3]: 0.880 (+/-0.011) for {'tol': 0.01, 'penalty': 'l1', 'max_iter': 100, 'loss': 'perceptron', 'alpha': 0.0001}\n",
      "\t[ 4]: 0.100 (+/-0.005) for {'tol': 0.0001, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'perceptron', 'alpha': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      2077\n",
      "           1       0.97      0.96      0.96      2385\n",
      "           2       0.90      0.86      0.88      2115\n",
      "           3       0.85      0.81      0.83      2117\n",
      "           4       0.89      0.90      0.90      2004\n",
      "           5       0.87      0.78      0.82      1900\n",
      "           6       0.94      0.93      0.93      2045\n",
      "           7       0.92      0.90      0.91      2189\n",
      "           8       0.65      0.87      0.75      2042\n",
      "           9       0.88      0.78      0.83      2126\n",
      "\n",
      "    accuracy                           0.88     21000\n",
      "   macro avg       0.88      0.87      0.88     21000\n",
      "weighted avg       0.88      0.88      0.88     21000\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(loss='perceptron', max_iter=100, penalty='l1', tol=0.01)\n",
      "\n",
      "best: dat=mnist, score=0.88000, model=SGDClassifier(alpha=0.0001,loss='perceptron',max_iter=100,penalty='l1',tol=0.01)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nastr\\anaconda3\\envs\\swmal\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tuning_parameters = {\n",
    "#     'loss': ['hinge', 'log_loss', 'perceptron', 'modified_huber', 'squared_error', 'huber'], \n",
    "#     'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "#     'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 100],\n",
    "#     'tol' : [0.0001, 0.001, 0.01, 0.1],\n",
    "#     'max_iter' : [1000]\n",
    "# }\n",
    "\n",
    "\n",
    "# We already have sgd classifier, let's test it using randomizedsearch first, since mnist data is considerably larger\n",
    "# random_tuned = RandomizedSearchCV(\n",
    "#     sgd, \n",
    "#     tuning_parameters, \n",
    "#     n_iter=5, \n",
    "#     random_state=42, \n",
    "#     cv=CV, \n",
    "#     scoring='f1_micro', \n",
    "#     verbose=VERBOSE, \n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "\n",
    "# start = time()\n",
    "# random_tuned.fit(X_train, y_train)\n",
    "# t = time() - start\n",
    "\n",
    "# b0, m0 = FullReport(random_tuned, X_test, y_test, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest gridsearch!\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'n_estimators' : [50, 100, 1000],\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth' : [None, 2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_tuned = GridSearchCV(forest,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "\n",
    "start = time()\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
