{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the right ML algorithms\n",
    "\n",
    "To be able to choose the right machine learning models, we need to formulate a clear and concise description of our problem. We would like to predict cancer malignancy (diagnosis) by looking at the size of cell features from images of cell substracts. The features of the cells concern the mean texture, mean radius, area, concavity and other geometrical features of the cells themself. With that said, the task of predicting whether a cancer diagnosis is malignant or benign, is clearly a classification task. \n",
    "\n",
    "Since in our dataset we already have the labeled diagnosis, it seems prudent to test some of the supervised models which scikit-learn offers. But first we need to import and prepare the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n",
      "33\n",
      "Data features: \n",
      " Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
      "      dtype='object')\n",
      "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
      "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
      "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
      "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
      "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
      "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
      "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
      "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
      "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
      "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
      "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
      "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
      "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
      "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
      "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
      "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
      "\n",
      "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "count        569.000000         569.000000       569.000000   \n",
      "mean           0.132369           0.254265         0.272188   \n",
      "std            0.022832           0.157336         0.208624   \n",
      "min            0.071170           0.027290         0.000000   \n",
      "25%            0.116600           0.147200         0.114500   \n",
      "50%            0.131300           0.211900         0.226700   \n",
      "75%            0.146000           0.339100         0.382900   \n",
      "max            0.222600           1.058000         1.252000   \n",
      "\n",
      "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
      "count            569.000000      569.000000               569.000000   \n",
      "mean               0.114606        0.290076                 0.083946   \n",
      "std                0.065732        0.061867                 0.018061   \n",
      "min                0.000000        0.156500                 0.055040   \n",
      "25%                0.064930        0.250400                 0.071460   \n",
      "50%                0.099930        0.282200                 0.080040   \n",
      "75%                0.161400        0.317900                 0.092080   \n",
      "max                0.291000        0.663800                 0.207500   \n",
      "\n",
      "       Unnamed: 32  \n",
      "count          0.0  \n",
      "mean           NaN  \n",
      "std            NaN  \n",
      "min            NaN  \n",
      "25%            NaN  \n",
      "50%            NaN  \n",
      "75%            NaN  \n",
      "max            NaN  \n",
      "\n",
      "[8 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read dataset\n",
    "data_breast_cancer = pd.read_csv(\"breast_cancer_win/data.csv\")\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "print(data_breast_cancer.shape)\n",
    "features = data_breast_cancer.columns\n",
    "print(len(features))\n",
    "\n",
    "print(\"Data features: \\n\", features)\n",
    "print(data_breast_cancer.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have printed all the features the data contains, and the description of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "means_labels : list[str] = list(data_breast_cancer.columns[1:11])\n",
    "worst_labels : list[str] = list(data_breast_cancer.columns[-10: -1])\n",
    "\n",
    "# Drop the faulty column\n",
    "data_breast_cancer.drop(columns=[\"Unnamed: 32\", \"id\"], inplace=True)\n",
    "\n",
    "# Set the data diagnosis results to integers\n",
    "data_breast_cancer['diagnosis'] = data_breast_cancer['diagnosis'].map({\"M\":1,\"B\":0})\n",
    "# split dataframe into two based on diagnosis\n",
    "dfM=data_breast_cancer[data_breast_cancer['diagnosis'] == 1]\n",
    "dfB=data_breast_cancer[data_breast_cancer['diagnosis'] == 0]\n",
    "\n",
    "# Copy result array and drop it from our dataset\n",
    "y_all = data_breast_cancer[\"diagnosis\"].copy()\n",
    "data_breast_cancer.drop(columns=[\"diagnosis\"], inplace=True)\n"
   ]
  },
  {
   "attachments": {
    "output.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyEAAAPjCAYAAACjzgFMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVxU1f8/8NewCIqgoYIiDCO7CAIqlDu5a0kauXw/WmDI8lHrU6aWlQumoqVlaiQFnyQxl3BJLcvMJU1MDFHLEFCQwQ23WFSQgfP7gx/348gio+MMy+v5eMzj4b33zL3vc2e4x/ecc8+VCSEEiIiIiIiIdMRA3wEQEREREVHTwiSEiIiIiIh0ikkIERERERHpFJMQIiIiIiLSKSYhRERERESkU0xCiIiIiIhIp5iEEBERERGRTjEJISIiIiIinWISQkREREREOsUkhOg+e/fuhUwmk5bnz5+PPn366DEiIiIiosaHSQhRLWbMmIEdO3boOwwiItKiPn36YP78+Vrb38SJExEcHKy1/RE1BUb6DoDoSbl37x6aNWv2WPto2bKllqIhIiKqnTbaLaKGgj0h1Gj4+/tjxowZCAkJgYWFBf7zn//glVdegZ2dHczMzNC9e3fs27dP7T2nT59Gjx49YGpqij59+iArK0tt+4PDsRQKBWJjY9XKyGQy7N27FwBw48YNjBkzBpaWljAzM4OXlxeSkpLqFPvMmTMRGhoKc3NzKBQK/PDDD8jNzcWgQYNgZmaG3r1748KFC2rvW7lyJRwcHNCiRQv4+vriwIED0ra0tDSMGDECbdu2RevWrTFixAi1+h04cAAymQy//PIL3N3dYW5ujlGjRuHWrVsPjZeIqKEKDg7Gb7/9hsjISMhkMigUCgDAxo0b4e7ujubNm8PDwwOJiYkAgLKyMvTq1QuvvvqqtI8//vgDpqam+O233zB//nysX78e8fHxkMlk0pDe6obzBgcHY+LEidKyQqHA0qVL8eKLL6JFixb47LPPao2lLnWbMGECZs+eDUtLS1hbW+Orr77CP//8gzFjxqBly5bo2rUrUlNT1d5X2/GuXr2Kl156Ce3bt4e5uTn69eun9v7s7GzIZDJs374dfn5+MDMzg7+/P3JycuoUMzVdTEKoUYmJiYGzszNSUlIwbdo0uLi4YOfOnTh58iQCAgLwwgsvIC8vD0BFw/Liiy9CLpfjjz/+wH/+8x/MnTv3sY4/Z84cFBYW4tdff8WpU6cwb968Ov+q9cUXX8DDwwMpKSl47rnn8PLLL2Py5Ml444038Mcff0AIgenTp0vl//vf/+LTTz9FdHQ0/vzzT7zyyisYMWIEsrOzAQBFRUV46aWXcPjwYRw+fBjNmjXD+PHjqxx34cKFWLt2Lfbv34/Tp09j4cKFj3UOiIjqs08//RR+fn546623cPnyZSQnJ2Pfvn147bXXEBkZib/++gvvvvsuXnnlFRw9ehSGhoaIj4/Hpk2bsHPnTpSUlOCVV17Ba6+9ht69e2PGjBkIDAzE2LFjcfnyZVy+fFmjeD788EMMHz4cf/75J8aMGVNrLHWxc+dOAMDRo0fx+uuvIzw8HP/6178watQonDhxAk5OTggJCZHKP+x4d+/eRb9+/fDzzz/jjz/+gLu7OwICAlBcXKx23Pnz52Pp0qU4duwY7ty5gzfffFOj80BNkCBqJPr37y/8/f1rLePq6iri4+OFEEL88MMPonnz5uLmzZvS9rffflvc/2cxb9480bt3b2nZ3t5efPnll2r7BCB+/vlnIYQQzz//vFiwYMEjxT58+HBp+fLlywKA+Oijj6R1GzZsEJaWltJyp06dxM6dO9X2M3jwYPHBBx9Ue4zKfV64cEEIIcT+/fsFAPH7779LZRYvXiy6d++ucfxERA1J7969xbx586TlZ599VqxatUqtTGhoqAgJCZGWV65cKdq3by8mT54s3N3dRXFxsbRtwoQJIigoSO39D7YfQggRFBQkJkyYIC3b29uL4OBgtTJ1iaUmQUFBwt3dXVpWqVTCzMxMTJ06VVqXlJQkAIiCgoJHOl7lPg8ePCiEECIrK0sAEJs2bZLKfPPNN6JNmzYPjZeaNt4TQo2Kj4+P2vKyZcvw9ddfIzc3F/fu3cPdu3ehVCoBAGfPnoWTkxOeeuopqbyfn99jHT80NBTjxo3Dnj17MHjwYIwbNw6urq51eq+np6f0b2trawBAly5d1NbdvHkTZWVluHv3LrKysjBu3Di12bxKSkpga2sLAMjPz8e7776LPXv24OrVqygvLwcAKJVKyOXyao/bvn17qaeIiKipOH36NJKSkvDOO+9I6+7du6c2nGratGnYvHkz/vvf/+L333+HiYmJVo79YLtVl1hq4+HhIf3b0NAQbdq0qdKWAMC1a9dgbm7+0OOVlpZi3rx52LZtGy5fvgyVSoU7d+5IbWmlB9uSGzduoKysDIaGhnWKm5oeJiHUqLRo0UL6d0JCAhYsWIBVq1bB29sbZmZmGD16NEpLSwEAQgi1/8DXhYGBAYQQ0nLlvioFBATg/Pnz2LlzJ3744QcsWrQIX3/9NcaNG/fQfRsbG0v/royrunVCCNy+fRsA8M0336g1LgBgbm4OAHjrrbdw9OhRrFixAp06dYJKpYKXl1eVmB88RmWyQkTUVBQVFWHZsmUYOnSo2vrmzZtL/75+/TrS09Mhk8mQlZWFHj161LrPB9sLoKLNeLDdub/dqmsstbn/mg5UXNera0sqr/UPO97SpUsRHx+PlStXwtXVFaampvDz83toWwKgSv2J7sckhBqto0ePYsCAAQgKCgJQcaG9/0Y5V1dXZGRk4J9//kHr1q0BAMnJybXus127drhy5Yq0fPr06SplOnTogLCwMISFhWHKlCmIj4+vUxKiCSsrK7Rv3x45OTl44YUXqi1z9OhRTJ48Gc899xwA4NChQ1qNgYiooTI2NkZZWZm07OXlhfPnz8PJyanG90yZMgWenp4YM2YMpkyZgv79+8PKykran0qlUiv/YHsBVLQZXbt2rTW2usSiTQ873tGjRzFmzBgEBgYCqOhN5wQmpA1MQqjRcnR0xObNm3Ho0CFYWlpi3rx5ar/yDx06FB06dMDkyZOxYMECnDlzBvHx8bXus1+/fvjvf/+LYcOGAQBmz56ttn3evHnw9fWFu7s7bt68id9++w0DBgzQet1kMhneffddzJkzBy1btkS/fv1w69Yt7N27F35+fhgwYAAcHR2RmJiIIUOG4ObNm5g5c6bW4yAiaojs7e1x9OhRXLx4ES1atMC7776LsWPHwtbWFs899xzu3r2LQ4cOoV27dhg3bhw2bNiAPXv24PTp05DL5di6dSvCw8Oxbds2aX+JiYnIzs5Gy5Yt0bZtW/Tt2xdTpkzB559/jkGDBuGrr75Cdnb2Q5OQh8WibQ87nqOjI3788UekpKQAqHh+lqmpqdbjoKaHs2NRoxUREYGBAwdixIgRGDx4MPr06QMvLy9pu6GhIbZu3YqsrCz4+Pjg448/xrx582rd57vvvgtvb28MGDAAEydOxLvvvqu23cjICDNmzIC7uzuee+45+Pn5PbHZpl577TV8+OGH+PDDD9G5c2eMHDkSx44dQ8eOHQEAy5cvhxAC3bt3R1hYGCIjI59IHEREDc2MGTNw48YNODg4wMfHBwEBAdiwYQPWrVsHT09PDBo0CLt27YK9vT2uXLmCadOm4ZNPPpHup4uNjcX+/fuxbt06ABX3A1paWsLd3R3t2rUDUHFvxieffIIPPvgAvr6+KC8vx+jRox8aW22xPAkPO97777+PTp06oU+fPggMDERoaCjatGnzRGKhpkUmOGCPiIiIiIh0iD0hRERERESkU0xCiHRg+PDhaNmyZbUvPlWWiIjqIiIiosa2hJOPUEPD4VhEOnDx4kXcvXu32m0KhQJGRpwjgoiIapeXl4eCgoJqt3Xs2LHO0/gS1QdMQoiIiIiISKc4HIuIiIiIiHSqUY0BKS8vx6VLl2Bubq7xk7CJiKjiCceFhYWwsbGBgUHT+J2KbQcR0ePTtP1oVEnIpUuXYGdnp+8wiIgaPKVSCVtbW32HoRNsO4iItKeu7UejSkLMzc0BVFTewsJCz9EQETU8BQUFsLOzk66nTQHbDiKix6dp+9GokpDKbnQLCws2JEREj6EpDUti20FEpD11bT+axoBfIiIiIiKqN5iEEBERERGRTjWq4VhERJoqKytDaWmpvsPQC2NjYxgaGuo7DCKiBkcIAZVKhbKyMn2HonPaajuYhBBRk1VUVITc3Fw01We2ymQy2NraomXLlvoOhYiowbh37x4uX76MO3fu6DsUvdBW28EkhKo1f/6TLU+kb2VlZcjNzUWLFi3Qrl27JnUjNlDxK961a9eQm5sLZ2dn9ohQg1JTm8O2iJ608vJyZGVlwdDQEDY2NmjWrFmTaj+02XYwCSGiJqm0tBRCCLRr1w7NmzfXdzh60a5dO2RnZ6O0tJRJCBFRHdy7dw/l5eWws7NDixYt9B2OXmir7eCN6UTUpDWlX7Ae1JTrTkT0OOryRPDGSlttR9M9g0REREREpBccjtWEcewskbon+TfxqPuWyWQoLCys8QbA7Oxs7NmzB2FhYY8eHJGOaHovB9spaiie1Hf1cfZb39sP9oQQETVg2dnZ+OKLL/QdBhERNTD6bj+YhBAR1SNbt26Fm5sbevbsiQ8++EBaP3HiRPTo0QNdu3bF888/j7y8PABAREQEzpw5A29vbwQEBAAAZs6cCV9fX3h7e6N///7IyMjQS12IiEh3Glr7wSSEiKieyMvLQ2hoKL777jskJSXBxMRE2rZixQocP34cp06dQp8+fbBgwQIAwJo1a+Du7o7U1FTs2LEDAPD2228jOTkZqamp+Pe//40333xTL/UhIiLdaIjth1bvCcnIyEBQUBCuX7+O1q1bY+3atXB3d1crk52djeDgYJw4cQLOzs44fvy42jYnJyd4eHhI67Zs2QJHR0dthklEVC8dPXoU3bp1g6urKwAgLCwMb7/9NgBg/fr1WLduHUpKSnD37l20b9++xv3s2bMHq1atQmFhIcrLy1FQUKCT+ImISD8aYvuh1Z6Q8PBwhIWFIT09HbNmzUJISEiVMhYWFli4cCG++eabavfRunVrpKamSi8mIETUVNT05PbU1FSsXr0au3fvxunTp/Hxxx+juLi42rI5OTl4/fXXsX79evz555/YuHFjjWWJiKhxaIjth9aSkLy8PKSkpGDixIkAgMDAQGRlZSE7O1utnKWlJfr06QMzM7PHPmZJSQkKCgrUXkREDVXPnj1x4sQJpKenAwBiY2MBALdu3YKFhQUsLS1x7949xMTESO+xsLBAfn6+tJyfn49mzZqhffv2EEJg9erVuq3EI8jIyECvXr3g4uICPz8/nDlzpkqZ7Oxs+Pv7o1WrVujRo0eV7bt27YKbmxucnJwQGBiIoqIiXYRORFQvNMT2Q2vDsZRKJWxsbGBkVLFLmUwGuVyOnJwcKBSKOu+noKAAvr6+KCsrw6hRo/Dee+/V+DTGqKgoREZGaiN8IiK9TwdqZWWFL774AiNHjkSbNm3w0ksvAQCeffZZJCQkwM3NDba2tujVqxd++uknAEDXrl3h6uoKDw8PODg4YMeOHRgzZgy6dOkCuVyOwYMH67NKdVLZix4cHIzExESEhIQgKSlJrUxlL3p+fj7mzZuntq2oqAghISE4ePAg3NzcMG3aNCxatAhRUVG6rAYRNWFsPzQnEzX132jojz/+wCuvvIK//vpLWufr64vly5ejX79+VcofOHAAM2bMULsnpKSkBPn5+bCyssLNmzcxbtw4DB48GLNmzar2mCUlJSgpKZGWCwoKYGdnh/z8fFhYWGijWo2aNv9g9P3HR6Sp4uJiZGVloVOnTjA1NdV3OHpR3TkoKChAq1atdHYdzcvLg4uLC65fvw4jIyMIIdChQwccPXq02h+wqms7vv32W6xduxbff/89AODMmTMYMWJElZ74Smw79OdJPyeEbRE9aWw7aj4HmrYfWhuOZWdnh9zcXKhUKgAVY9OUSiXkcnmd92FiYgIrKysAFcO2Xn31VRw6dKjW8hYWFmovIiJqOGrrRa+rnJwc2NvbS8sKhQIXL15EeXl5teWjoqLQqlUr6WVnZ/d4lSAiIo1pLQmxsrKCj48PEhISAFTMaqVQKDQaipWXl4fS0lIAFb9Ubd26FT4+PtoKkYiI6iGZTKa2/Cgd9A/uozazZ89Gfn6+9FIqlRofj4iIHo9Wp+iNiYlBcHAwFi9eDAsLC8THxwMAJk+ejICAAAQEBKCkpASOjo7S0CtbW1u8/PLLiIqKwuHDhzF37lwYGhpCpVJhwIABeO+997QZIj0h2upiZ1c6UdNyfy965XAsTXvR5XI59u3bJy1nZ2ejY8eOMDCo/nc2ExMTtTn06dHwOk5Ej0OrSYirq2uVmwmB/92hD1Rc/HNzc6t9/4svvogXX3xRmyEREdVKS7fFNUj1oe7396IHBwc/Ui/6sGHDMHXqVKSlpcHNzQ3R0dEYP378kwuaiJq8moZ7NgXaaju0moQQETUUxsbGkMlkuHbtGtq1a6fRcJ7GQAiBa9euQSaTwdjYWK+xPG4vurm5OWJjYzFq1CioVCp4enpK+yAi0qZmzZrBwMAAly5dQrt27dCsWbMm1X5os+1gEkJPFLvlqb4yNDSEra0tcnNza5xFqbGTyWSwtbWtcRp0XXncXnQAUrJCRPQkGRgYoFOnTrh8+TIuXbqk73D0QlttB5MQImqyWrZsCWdnZ2lCjKbG2NhY7wkIkS7w/hXSpmbNmkEul0OlUqGsrEzf4eicttoOJiFE1KQZGhryP+JERKSRyuFI+h7O2pBpbYpeIiIiIiKiumASQkREREREOsUkhIiIiIiIdIpJCBHVe1u3bkX37t3h7e2Nzp07Y+DAgdIc7QqFAn/++aeeI3wyfv/9d3h7e8PFxQUDBw7E5cuXqy13+/ZtTJo0CZ6ennB1dcU777xTZR734uJiuLu7o0ePHroInYhI79h21N52AMDBgwfh6+uLLl26wM3NTZqp8MCBA2jRogW8vb2l1927d7UaJ29MJ6J67cqVK4iIiEBycjLs7e0BACkpKY1+XnYhBCZMmIDY2Fj4+/tj2bJlmD59OjZs2FCl7OLFiwEAp06dgkqlwvPPP4/ExESMGTNGKvPee++hZ8+eOHnypM7qQESkL2w7Ht52XLp0CUFBQdi9ezc6d+6M4uJiFBcXS9vd3d1x/PjxJxYre0KIqF67fPkyjIyM0KZNG2ldt27dqm1IVq5ciT59+uDatWu4cuUKxo4dCz8/P3Tt2hVz584FAPz0008YOnQoAOCff/6BoaEhvvzySwBAXFwcQkJCAAD+/v54++230bdvXzg6OiIiIkI6TmFhIUJDQ6V9R0RESNP8Lly4EJ07d5Z+Obpw4QLu3r2LcePGwd3dHV5eXhgyZMhD6338+HGYmJjA398fABAeHo7t27dXO53wyZMnMXz4cGm2liFDhmDdunXS9kOHDiEjIwMvv/zyQ49LRNQYsO3wB1B72xEdHY2JEyeic+fOAABTU1O0bt36ocfQFiYhRFSveXl5oWfPnpDL5Rg9ejQ++ugjXLx4Ua1MeXk53nzzTRw8eBA///wz2rVrh6CgIEybNg3Hjh1DSkoKjh07hm3btqFfv344duwYSkpKsH//fjz99NP45ZdfAAB79+7FoEGDpP2eO3cOBw4cwJ9//omffvpJ6qZ+6623pP2cPHkSKpUKq1evxq1bt7Bs2TKkpKQgNTUVR44cgbW1NX788UfcunULZ86cwcmTJ7Fx40bpGN7e3tU+8ConJ0f69Q4AzM3NYW5uXm23uq+vLzZv3ox79+6hsLAQ27Ztkx7AePv2bbzxxhv4/PPPH/1DICLJ/PnVv6h+YdtRoba248yZM7h79y4GDRoEb29vvPbaa7hz5460/ezZs+jWrRt8fX0RHR39iJ9EzZiEEFG9ZmBggC1btuDIkSMYNmwYfvvtN3Tp0gWZmZlSmVdffRXFxcX49ttv0bx5c9y+fRv79u3D66+/Dm9vb/To0QOZmZlIS0tD8+bN4e3tjd9++w179+7F7NmzkZKSgvLycuzfvx8DBw6U9jt+/HgYGhpK7zl37hwAYPv27fjoo4/g7e0NHx8fqafBwsICzs7OmDhxImJiYnDz5k2YmprCy8sLaWlpmDJlCjZt2qQ2r3xqaipsbGyqrfuDv9g9eJ9Hpbfffht2dnbw8/NDQEAAevXqJR1j5syZmDp1Kjp27PhoHwARUQPEtuN/amo7SktLceDAAXz77bc4fvw48vPzMf//Z9TdunVDbm4uUlJSsG3bNqxZswabN29+pM+iJrwnhIgaBDc3N7i5uSE8PBzDhg3Djh07MH36dAAV3d8///wz8vLy0L59e5SXl0MmkyE5ObnaB0kNGjQIe/fuxaFDh7B06VJ06dIF69atg7W1NaysrKRypqam0r8NDQ2hUqkAVFzQt2/fDgcHhyr7Pnr0KI4cOYIDBw7gmWeewYYNG9C3b1+cOXMG+/btw969ezFr1iykpqbiqaeeqrG+crlc6s0AKrrxCwsL0aFDhyplTU1N8cknn0jLS5Ysgbu7OwDg8OHD+OGHH7BgwQIUFxfj1q1b6NKlC/76668aj01E1Fiw7ai57bC3t4ePj4+0v/Hjx+PDDz8EAFhYWEjlbG1t8X//9384dOgQxo4dW+OxNcWeECKq1y5evIjffvtNWr516xaysrLg6OgorQsODsZ7772HAQMG4MKFCzA3N0ffvn2xZMkSqcylS5eQm5sLoKIh+eabb/DUU0+hZcuWGDRoEObNm6fWnV6bgIAALFmyRGpYbt26hczMTBQWFuLq1avo27cv5syZgz59+uDEiRPIzc2FTCZDQEAAli1bBiEElEplrcfo3r07iouLceDAAQBATEwMRo0aVW3DWFBQIHWhZ2Vl4fPPP8dbb70FoOJm9ezsbGRnZ2Pjxo3w9PRkAkJEjR7bjgMAam87/vWvf2H//v0oKSkBAPz444/w8vICUHFPTeVMYoWFhdi1axd8fHzqVM+6YhJCRPWaSqXCggUL4OLiAm9vb/Tt2xdBQUF44YUX1MqNHTsWH330EYYMGYL09HSsX78ef//9Nzw9PeHp6YnAwEDcuHEDANCjRw/k5+dL3eeDBw/GhQsX6tyQrFixAkZGRvD29kbXrl0xaNAgZGdnIz8/Hy+++CI8PT3RtWtXlJaWIigoCKdPn0avXr3QtWtXdOvWDS+//DK6du0KoOZxvQYGBkhISMB//vMfuLi44Pvvv8fy5cul7SNGjJBmLTl//jy8vb3h7u6OF154AZ988gm8vb01PtdERI0F246Htx29evXCyJEj4e3tDU9PT1y7dg0LFiwAAGzZsgWenp7w8vLCM888g8GDB2PSpEkafgq1k4maBoo1QAUFBWjVqhXy8/PVupGoevXxRrr6GBNRU9IUr6NNsc7aUNP1urbruKbv0bRNeNL71/a+iBoTTa+l7AkhIiIiIiKd4o3pREREpFfsRSBqetgTQkREepWRkYFevXrBxcUFfn5+OHPmTLXl4uLi4OzsDEdHR4SFhUk3dwLAsmXL4OHhAW9vbzzzzDNITk7WVfhERPQImIQQEZFehYeHIywsDOnp6Zg1a5b05OH7ZWVlYc6cOTh8+DAyMzNx5coVxMXFAah4YvyqVatw9OhRpKamYtq0aZg6daquq0FERBpgEkJERHqTl5eHlJQUTJw4EQAQGBiIrKwstXnuASAxMRGjR4+GtbU1ZDIZIiIisGHDBml7aWkpbt++DQD4559/YGtrW+MxS0pKUFBQoPYiIiLd4j0hRESkN0qlEjY2NjAyqmiOZDIZ5HI5cnJyoFAopHI5OTmwt7eXlhUKBXJycgAAXl5emD59Ojp16gRLS0uYmJjg119/rfGYUVFRiIyMfDIVIr3ivSVEDQd7QoiISK9kMpnack0zx99f7v4yFy5cwI4dO3Du3Dnk5ubizTffxIQJE2o83uzZs5Gfny+9HvbwLyIi0j72hFCDxvnaiRo2Ozs75ObmQqVSwcjISHoisFwuVysnl8vVhmhduHBBKvPtt9/Cw8MDHTp0AABMmjQJr7/+OsrKymBoaFjlmCYmJjAxMXlylSIioodiTwgREemNlZUVfHx8kJCQAKDiKb0KhUJtKBZQca/Itm3bcPXqVQghsGbNGowfPx4A4ODggMOHD6OoqAgAsHPnTnTu3LnaBISIiOoH9oQQEZFexcTEIDg4GIsXL4aFhQXi4+MBAJMnT0ZAQAACAgLg4OCAyMhI9O7dG+Xl5RgwYIA0i9bo0aORnJyMHj16wMTEBObm5lJSQ/So2KNO9GQxCSEiIr1ydXVFUlJSlfWxsbFqy6GhoQgNDa1STiaTISoqClFRUU8sRiIi0i4OxyIiIiIiIp1iEkJERERERDrFJISIiIiIiHSKSQgREREREekUkxAiIiIiItIpzo5FREREfPgrEekUkxCqV9jYERERETV+Wh2OlZGRgV69esHFxQV+fn44c+ZMlTLZ2dnw9/dHq1at0KNHjyrbd+3aBTc3Nzg5OSEwMFB6Ai4RERERETUOWk1CwsPDERYWhvT0dMyaNUt6mu39LCwssHDhQnzzzTdVthUVFSEkJATbt29HZmYmOnTogEWLFmkzRCIiIiIi0jOtDcfKy8tDSkoK9uzZAwAIDAzEtGnTkJ2dDYVCIZWztLREnz59cODAgSr72L17N3r06AE3NzcAwJQpUzBixIgan4JbUlKCkpISabmgoEBb1SEiIqJGjkOAifRHa0mIUqmEjY0NjIwqdimTySCXy5GTk6OWhNQmJycH9vb20rJCocDFixdRXl4OA4OqnTZRUVGIjIzUSvyNGS+yRERERFSfaHU4lkwmU1sWQjz2Pmoze/Zs5OfnSy+lUqnx8YiIiIiISLe01hNiZ2eH3NxcqFQqGBkZQQgBpVIJuVxe533I5XLs27dPWs7OzkbHjh2r7QUBABMTE5iYmDx27EREREREpDtaS0KsrKzg4+ODhIQEBAcHY8uWLVAoFHUeigUAw4YNw9SpU5GWlgY3NzdER0dj/Pjx2gqRiIiINMQhvXXD56wQaUarzwmJiYlBcHAwFi9eDAsLC8THxwMAJk+ejICAAAQEBKCkpASOjo4oKSlBfn4+bG1t8fLLLyMqKgrm5uaIjY3FqFGjoFKp4OnpKe2DiIiIiIgaB60mIa6urkhKSqqyPjY2Vvq3iYkJcnNza9xHZbJCRERERESNk1ZvTCciIiIiInoYrfaEEBERaSojIwNBQUG4fv06WrdujbVr18Ld3b1Kubi4OCxZsgTl5eUYOHAgoqOjpWnhc3JyMHXqVKSnp0Mmk2Hq1Kl47bXXdF0VAu+BIKK6YU8IERHpVXh4OMLCwpCeno5Zs2YhJCSkSpmsrCzMmTMHhw8fRmZmJq5cuYK4uDgAFdPBjx49Gq+88grOnj2Lv//+G2PGjNF1NYiISANMQoiISG/y8vKQkpKCiRMnAgACAwORlZWF7OxstXKJiYkYPXo0rK2tIZPJEBERgQ0bNgAAfvnlFzRv3lxKPGQyGdq3b1/jMUtKSlBQUKD2IiIi3WISQkREeqNUKmFjYyMNq5LJZJDL5cjJyVErl5OTA3t7e2lZoVBIZc6cOYN27dph/Pjx8PHxwejRo3H+/PkajxkVFYVWrVpJLzs7uydQMyIiqg2TECIi0iuZTKa2LIR4aLn7y5SWlmLv3r2YM2cOTpw4geHDh9f6jKnZs2cjPz9feimVysesARERaYpJCBER6Y2dnR1yc3OhUqkAVCQXSqUScrlcrZxcLlcbonXhwgWpjL29PXx8fNClSxcAwMSJE/HHH3+grKys2mOamJjAwsJC7UVERLrFJISIiPTGysoKPj4+SEhIAABs2bIFCoUCCoVCrVxgYCC2bduGq1evQgiBNWvWSL0dw4cPx8WLF3Hx4kUAwI8//ggPDw8YGhrqtC5ERFR3nKKXiIj0KiYmBsHBwVi8eDEsLCwQHx8PAJg8ebL0AFsHBwdERkaid+/eKC8vx4ABA6RZtMzMzBAdHY3nnnsOQgi0bt0a33zzjT6rpDO1TYdb0zZOoUtE9QGTECIi0itXV1ckJSVVWR8bG6u2HBoaitDQ0Gr3MXToUAwdOvSJxEdERNrH4VhERERERKRTTEKIiIiIiEinmIQQEREREZFOMQkhIiIiIiKdYhJCREREREQ6xdmx6jFOr0hEREREjRF7QoiIiIiISKeYhBARERERkU4xCSEiIiIiIp1iEkJERERERDrFJISIiIiIiHSKSQgREREREekUkxAiIiIiItIpPieEGiVNn6XCZ68QEVF9UFt7xLaKGhP2hBARERERkU4xCSEiIiIiIp1iEkJERHqVkZGBXr16wcXFBX5+fjhz5ky15eLi4uDs7AxHR0eEhYVBpVKpbRdCYODAgWjbtq0uwiYiosfAe0KIiEivwsPDERYWhuDgYCQmJiIkJARJSUlqZbKysjBnzhycOHECVlZWeOGFFxAXF4fw8HCpzOrVq6FQKHDy5EldV4GoRjXdx8H7O6ipY08IERHpTV5eHlJSUjBx4kQAQGBgILKyspCdna1WLjExEaNHj4a1tTVkMhkiIiKwYcMGaXtGRgY2btyId95556HHLCkpQUFBgdqLiIh0i0kIERHpjVKphI2NDYyMKjrmZTIZ5HI5cnJy1Mrl5OTA3t5eWlYoFFKZ8vJyhIaG4rPPPoOxsfFDjxkVFYVWrVpJLzs7Oy3WiIiI6oLDsRoRdu0SUUMkk8nUloUQDy13f5lly5ahX79+8Pb2rtKDUp3Zs2dj+vTp0nJBQQETESIiHWMSQkREemNnZ4fc3FyoVCoYGRlBCAGlUgm5XK5WTi6XqyUYFy5ckMr8+uuvOHXqFL7++muoVCrcunULCoUCJ06cwFNPPVXlmCYmJjAxMXmi9SLSJd53Qg0Rh2MREZHeWFlZwcfHBwkJCQCALVu2QKFQQKFQqJULDAzEtm3bcPXqVQghsGbNGowfPx4AsGvXLuTk5CA7OxuHDx/GU089hezs7GoTECIiqh/YE9IA8ZcN7WtqvyI1tfpS/RYTE4Pg4GAsXrwYFhYWiI+PBwBMnjwZAQEBCAgIgIODAyIjI9G7d2+Ul5djwIABCAkJ0XPkRET0qLSahGRkZCAoKAjXr19H69atsXbtWri7u1cpFxcXhyVLlqC8vBwDBw5EdHQ0jIyMkJ2dDScnJ3h4eEhlt2zZAkdHR22GSURE9Yirq2uVKXkBIDY2Vm05NDQUoaGhte5LoVDg+vXrWo2PiIi0T6tJiDbmem/dujVSU1O1GRYREVGTw57NxoefKTUmWrsnRFtzvWuCc70TERERETU8WktCtDHXO1AxVaKvry+6deuGBQsWoKysrMZjcq53IiIiIqKGR6uzYz3uXO8dOnRAbm4ukpOTsXfvXhw6dAjLly+v8XizZ89Gfn6+9FIqlY9ZAyIiIiIietK0loTcP9c7gEea693ExARWVlYAAEtLS7z66qs4dOhQjcc0MTGBhYWF2ouIiIiIiOo3rSUh2pjrPS8vD6WlpQAq7vfYunUrfHx8tBUiERERERHVA1qdHetx53o/fPgw5s6dC0NDQ6hUKgwYMADvvfeeNkMkeqI0ff6GttbXhDOpEBERUX2k1STkced6f/HFF/Hiiy9qMyQiIiIiIqpntHpjOhERERER0cNotSeEHg2HzBARERFRU8KeECIiIiIi0ikmIUREREREpFNMQoiIiIiISKd4TwhRPaSv+4S0NTUwERERUW3YE0JERERERDrFnhAiIiIiHdNnDzN7vak+YBKiQ/zjbjz45HIi7cnIyEBQUBCuX7+O1q1bY+3atXB3d69SLi4uDkuWLEF5eTkGDhyI6OhoGBkZ4fTp05g6dSry8vJgbGyMnj17YtWqVTAxMdFDbYiIqC44HIuIiPQqPDwcYWFhSE9Px6xZsxASElKlTFZWFubMmYPDhw8jMzMTV65cQVxcHADA1NQUq1evRlpaGlJTU5Gfn4/ly5fruhpERKQB9oQQEZHe5OXlISUlBXv27AEABAYGYtq0acjOzoZCoZDKJSYmYvTo0bC2tgYARERE4MMPP0R4eDicnZ2lcoaGhvD19UVaWlqNxywpKUFJSYm0XFBQoOVaETUNtfXycwQAPQx7QoiISG+USiVsbGxgZFTxm5hMJoNcLkdOTo5auZycHNjb20vLCoWiShkAuH37NmJjYzFy5MgajxkVFYVWrVpJLzs7Oy3VhoiI6oo9IUS1aOi/5DT0+KlpkMlkastCiIeWq65MaWkpxo0bhyFDhuCFF16o8XizZ8/G9OnTpeWCggImIkREOsYkhIiI9MbOzg65ublQqVQwMjKCEAJKpRJyuVytnFwuR3Z2trR84cIFtTKlpaUYO3YsOnTogE8//bTWY5qYmPCmdSIiPWMSQkREemNlZQUfHx8kJCQgODgYW7ZsgUKhULsfBKi4V6RPnz6YO3curKyssGbNGowfPx4AoFKpMH78eFhaWuKLL76o0rPSGLBXk3SB3zPSJd4TQkREehUTE4OYmBi4uLhgyZIl0qxXkydPxo4dOwAADg4OiIyMRO/eveHo6AgrKytpFq1NmzZh69atOH78OHx8fODt7Y2pU6fqrT5ERPRw7AkhIiK9cnV1RVJSUpX1sbGxasuhoaEIDQ2tUm7ChAmYMGHCE4uPiIi0jz0hRERERESkU+wJISIiIiKdqOm+E96P0vQwCXkC+IdETQUbEyIiInoUHI5FREREREQ6xSSEiIiIiIh0isOxiIiInhAOWSQiqh6TECJ6KH3+h4n/iSMiImp8OByLiIiIiIh0ikkIERERERHpFIdj1QGHgxARkTax/SCipo49IUREREREpFNMQoiIiIiISKc4HIuIiIiItEpbQw71OSSew/GfLCYhj4FfQiIiIiIizXE4FhERERER6RSTECIiIiIi0ikOx7oPh1cRaYemf0uP8rdX38Yb66s8xyzXDzzfVB81pO/lk74mPup7Gqv6cC602hOSkZGBXr16wcXFBX5+fjhz5ky15eLi4uDs7AxHR0eEhYVBpVJJ23bt2gU3Nzc4OTkhMDAQRUVF2gyRiIjqGbYdRERNj1aTkPDwcISFhSE9PR2zZs1CSEhIlTJZWVmYM2cODh8+jMzMTFy5cgVxcXEAgKKiIoSEhGD79u3IzMxEhw4dsGjRIm2GSERE9QzbDiKipkdrw7Hy8vKQkpKCPXv2AAACAwMxbdo0ZGdnQ6FQSOUSExMxevRoWFtbAwAiIiLw4YcfIjw8HLt370aPHj3g5uYGAJgyZQpGjBiBqKioao9ZUlKCkpISaTk/Px8AUFBQ8Eh1uG9XRKRDtf3JPum/y5qOrelxNb3saGv/Ne3nES+D0vVTCPFoO9BQY2g7Kvb5yG8lIi16lPZEV9fX+uRJ1E3T9kNrSYhSqYSNjQ2MjCp2KZPJIJfLkZOTo9aQ5OTkwN7eXlpWKBTIycmpcdvFixdRXl4OA4OqnTZRUVGIjIysst7Ozk5b1SIiHViypOEf+0nXQdP9P248hYWFaNWq1ePtpA7YdhCRNj3KtU/X19f6TBt1q2v7odUb02UymdpyTZnQ/eUeLPPgPmoze/ZsTJ8+XVouLy/HzZs30aZNG43209AUFBTAzs4OSqUSFhYW+g6n3uH5qRnPTe14fiquyYWFhbCxsdHZMRtT29HYvkOsT/3G+tRvTa0+mrYfWktC7OzskJubC5VKBSMjIwghoFQqIZfL1crJ5XJkZ2dLyxcuXJDKyOVy7Nu3T9qWnZ2Njh07VvtLFgCYmJjAxMREbV3r1q21U6EGwMLColF8qZ8Unp+a8dzUrqmfH130gFRqrG1HY/sOsT71G+tTvzWl+mjSfmjtxnQrKyv4+PggISEBALBlyxYoFAq17nSgYrzvtm3bcPXqVQghsGbNGowfPx4AMGzYMCQnJyMtLQ0AEB0dLW0jIqLGh20HEVHTpNXZsWJiYhATEwMXFxcsWbJEmrlk8uTJ2LFjBwDAwcEBkZGR6N27NxwdHWFlZSXNhGJubo7Y2FiMGjUKTk5OuHjxIt59911thkhERPUM2w4ioiZIUINTXFws5s2bJ4qLi/UdSr3E81Mznpva8fzQ42ps3yHWp35jfeo31qd2MiF0NA8jERERERERtDwci4iIiIiI6GGYhBARERERkU4xCSEiIiIiIp1iEkJERERERDrFJKSee/3116FQKCCTyfDnn39K6/Py8jBs2DA4OzvDw8MDhw8f1mOU+lPT+fH394eDgwO8vb3h7e2NTz75RI9R6kdxcTFGjRoFFxcXeHt7Y9iwYdLD3pr696e2c8PvDtVVY7s+N7braWO7BjbG69aQIUPQtWtXeHt7o2/fvkhNTQXQMD8foOb6NNTPBwAiIyPVrgla/Wy0MscWPTEHDx4USqVS2Nvbi9OnT0vrJ02aJObNmyeEEOLYsWNCLpeL0tJSPUWpPzWdn/79+4udO3fqMTL9u3v3rvj+++9FeXm5EEKIVatWicGDBwsh+P2p7dzwu0N11diuz43tetrYroGN8bp169Yt6d/btm0TPj4+QoiG+fkIUXN9Gurn88cff4hhw4YJuVwuXRO0+dmwJ6Se69evH2xtbaus37x5M6ZOnQoA8PX1hbW1dYP5pUCbajo/BJiammLEiBGQyWQAgGeeeQbnz58HwO9PbeeGqK4a2/W5sV1PG9s1sDFet1q3bi39Oz8/HwYGFf8tbYifD1BzfRqikpISTJ06FdHR0dJ3DtDuZ9Nwz04TduPGDZSXl6Ndu3bSOoVCgZycHD1GVf/MnDkTnp6eGDduXIO/UGvDypUrMXLkSH5/qlF5birxu0OPqrH+fTWGv4nGdg1sLNetV155BXZ2dnj//fcRHx/f4D+fB+tTqaF9PnPnzsXEiRPRqVMnaZ22PxsmIQ3U/VkpAAg+c1LNunXr8Pfff+PUqVPo27cvnn/+eX2HpFeLFy9GRkYGFi1aBIDfn/s9eG743aHH1dj+vhrD30RjuwY2puvW119/DaVSiYULF2LmzJkAGvbnU119Gtrnk5SUhOTkZEyZMqXKNm1+NkxCGqA2bdoAAK5duyatu3DhAuRyub5Cqnfs7OwAVPyxTJs2DefPn8eNGzf0HJV+LFu2DFu3bsXu3bvRokULfn/u8+C5AfjdocfTGP++GvrfRGO7BjbW61ZQUBD2798vLTfUz6dSZX1u3LjR4D6fgwcPIi0tDZ06dYJCoUBubi6GDh2KY8eOAdDeZ8MkpIEaM2YMPvvsMwBAcnIyrly5gj59+ug5qvpBpVLh6tWr0vKWLVtgbW0tNTxNyccff4wNGzbg559/Vhuryu9P9eeG3x3Shsb099XQ/yYa2zWwMV23CgoKcOnSJWl527ZtaNOmDSwtLRvk51NTfSwsLBrc5/POO+/g0qVLyM7ORnZ2NmxtbfHTTz9h+PDhWv1sZKIh9XE1QVOnTsV3332HK1euoG3btmjZsiUyMzNx9epVvPzyy8jKykKzZs0QHR2N/v376ztcnavu/Jw8eRL9+/dHSUkJDAwM0LZtW3z88cfw8vLSd7g6lZubCzs7Ozg4OMDc3BwAYGJigt9//73Jf39qOjf79u3jd4fqrLFdnxvb9bSxXQMb23VLqVQiMDAQd+/ehYGBAdq1a4dly5bB29u7QX4+NdXH2dm5QX4+91MoFNi1axc8PDy0+tkwCSEiIiIiIp3icCwiIiIiItIpJiFERERERKRTTEKIiIiIiEinmIQQEREREZFOMQkhIiIiIiKdYhJCREREREQ6xSSEiIiIiIh0ikkIERERERHpFJMQIiIiIiLSKSYhRERERESkU0xCiIiIiIhIp5iEEBERERGRTjEJISIiIiIinWISQk3K2rVrYWtrq+8wiIiIiJo0mRBC6DsIIl25e/cuioqK0K5duyd2jL1792Lw4MHgnxYRERFR9Yz0HQCRLgghoFKp0Lx5czRv3lzf4dTJvXv30KxZM32HQUREdcBrNpFmOByL6i1/f3/MmDEDQUFBMDMzg729PTZv3ixtT0lJgb+/P5o3bw6FQoF58+ZBpVJJ22UyGWJjYzFgwAA0b94cu3btqjIcKzg4GBMmTMDs2bNhaWkJa2trfPXVV/jnn38wZswYtGzZEl27dkVqaqpabBs3boS7uzuaN28ODw8PJCYmAgCys7MxePBg6fgymQxr164FAFy7dg0TJkxA69at0bZtW0yYMAE3btyoUt+QkBBYWFhg5syZtZ6f+fPno0+fPvj000/RoUMHtG7dGosXL0ZJSQkiIiJgYWEBJycn/Pzzz2rv27t3L3r06IHmzZvDxcUFn332mbStpKQEr7zyCuzs7GBmZobu3btj3759au+vrNOgQYPQokULdO/eHadOnao1ViKihiguLg7e3t5SGzRnzhypnalsP2bNmoW2bdtizJgxAB7eNr3xxhtwcHBAixYt0KVLF2zatKlOsRw4cAAymQx79uyBu7s7WrRogbFjx6K4uBirV6+GjY0NrKys8OGHH6q97/z58xg5ciRatmwJGxsbTJs2DXfu3JG2R0VFoXPnzmjRogWcnZ2xcuVKtff7+/tj1qxZCA8Ph7m5ORQKBTZu3PhI55NIjSCqp/r37y9atmwpFixYINLS0sTChQuFkZGRyMjIENevXxeWlpZi6dKlIiMjQ+zfv184OTmJJUuWSO8HIDp27Ci+/fZbce7cOXH16lXx1VdfiY4dO0plgoKChLm5uXjnnXfE2bNnxcKFC4WxsbEYPny4SEhIEOnp6WL06NGiW7du0nt++eUX0bZtW7F582Zx7tw5sX79etG8eXORlJQkVCqV2Lx5swAgLl++LC5fvizu3LkjhBCiX79+4l//+pc4deqUOH36tBgxYoQYNmxYlfpGRUWJjIwMcf78+VrPz7x584S5ubkIDg4Wf//9t/jqq68EADFkyBCxcuVKkZ6eLqZMmSLat28vSkpKhBBCpKWlCXNzcxEbGyvOnTsndu7cKdq1ayc2btwohBCiqKhIfPDBB+LEiRMiIyNDzJ8/X7Rs2VJcvXpV7bx26tRJbN++XZw9e1Y8//zzaueHiKix+OKLL8TPP/8szp8/L3744QfRvn178dlnnwkhKtoPMzMz8frrr4u0tDSRnp5ep7ZpwYIF4vfffxfnzp0Tn3/+uTA2NhanTp16aCz79+8XAIS/v79ITk4Whw4dEm3atBGDBw8Wr776qlo7cPLkSSGEECUlJcLJyUm8+eabIi0tTRw7dkz4+fmJiIgIab/Lly8Xhw4dEufPnxebNm0SZmZm4vvvv5e29+/fX1hYWIiPP/5YZGRkiHnz5glTU1O1doHoUTAJoXqrf//+4umnn1Zb17t3b/HWW2+JyMhIERgYqLZt/fr1wtHRUVoGIObPn69WprokxN3dXVpWqVTCzMxMTJ06VVqXlJQkAIiCggIhhBDPPvusWLVqldp+Q0NDRUhIiBBCiJ9//lk8mN8fPHhQWFtbi9LSUmndxYsXBQChVCql+vr7+z/krPzPvHnzxFNPPSWKi4ulda6uruK5556Tli9fviwASA3cpEmTxFtvvaW2n0WLFomBAwfWeBxXV1cRHx8vLQMQS5culZaPHDkiAIjCwsI6x05E1BBFRUWJZ599VghR0X44ODiIsrIyaXtd2qYHDR06VERGRj702JVJyO+//y6tCw8PF5aWllXagZUrVwohhIiPjxfdu3dX289vv/0mmjVrJlQqVbXHCQ8PF5MmTZKW+/fvL4YPHy4tl5aWihYtWoidO3c+NGai2vCeEKrX/Pz8qiyfPXsWpqam2LFjB1q2bCltKysrQ2lpKcrLy2FgUDHS0MfH56HH8PDwkP5taGiINm3aoEuXLtI6a2trABXDqczNzXH69GkkJSXhnXfekcrcu3cPffr0qfEYp0+fxrVr19C6desq286fPy8NEatLvPdzdnaGiYmJWqw1xV4Zx+nTp7FmzRqpjEqlgo2NjbS8bNkyfP3118jNzcW9e/dw9+5dKJVKteN6enpK/27fvj0AIC8vT+3zICJq6I4cOYL58+fjr7/+Qn5+PlQqFezs7KTtXl5eUnsDVFxjH9Y2xcfHY9WqVcjOzkZxcTFKSkrU9vkw919/ra2t4eTkVKUduP+af/LkSbV4hBC4d+8eLl68CLlcju+//x5RUVHIyMjA7du3ce/ePfTv37/GYxoZGaFt27bIy8urc8xE1WESQvWaTCardn1RURHGjx+PuXPnVtl2f4PQokWLhx7D2Ni4yjHvX1cZQ3l5uXTsZcuWYejQoWrvq+2G96KiIjg5OeH777+vsq1jx44axfu4sU+fPh2vvvqq2vuMjCouBQkJCViwYAFWrVoljYMePXo0SktLazzug8cgImoMCgsL8dxzz2Hs2LFYsGABLC0t8c0330j3+QFVr9kPa5sOHTqE0NBQfPTRR+jfvz9atmyJ1157rco1tjYPXn+rawfuv+b369cPMTExVfbToUMHnD9/Hi+++CLefvttrFixAq1atcLSpUuRmZlZ4zEfPAbRo2ISQvXasWPH1JaTk5Px9NNPw8jICHv37oWTk5POY/Ly8sL58+drPHblxbqsrAyGhobSe3JycmBhYQErKyudxfogLy8vnD17tsbYjx49igEDBiAoKAhARQOWk5OjyxCJiOqFs2fP4p9//sHSpUulXuwHe4Uf5OXlVWvb9Pvvv8Pd3R3/+c9/AFT8eHPu3Dmp11rbvLy8sGPHDtja2sLU1LTK9pSUFDRv3hwLFiyQ1mVlZT2RWIgexNmxqF77888/sWjRIqSnpyMqKgpJSUkIDw/H1KlTce7cOYSGhuLkyZM4e/YsNm/ejIULFz7xmN5991189tln+OSTT5Ceno6TJ09i9erV0gwn9vb2AIAffvgB169fR0lJCYYMGQJPT0+8+OKLOHToEM6fP4+ff/4ZYWFhTzze+82cORO7du3C+++/jzNnzuCvv/7C2rVrER0dDQBwdHTEkSNHcOjQIfz1118IDg7mr11E1CTJ5XIYGxsjOjoa58+fx5o1a7B9+/Za3/OwtsnR0RFnz57Frl27cPbsWbz22mu4cuXKE6vDhAkT0KxZM4wbNw7JycnIzMzEzp07MWPGDCmegoICrF27FpmZmVi4cCGSk5OfWDxE92MSQvVaWFgYzpw5Ax8fH0RHRyMhIQHOzs6ws7PDr7/+CqVSid69e8PX1xfLli2DXC5/4jEFBARgw4YNWLduHTw9PTFo0CDs2rVLSj4UCgXefvttTJo0Ce3atcOGDRtgYGCAH3/8Ea6urnjxxRfRpUsXvPbaa9XeI/Ikde/eHT///DMOHjyI7t27o0+fPvjqq6+gUCgAABERERg4cCBGjBiBwYMHo0+fPvDy8tJpjERE9YGVlRW++OILREdHw9PTE3v27FG7F7A6D2ubRo0ahdDQULz88svo1asXzM3NMXLkyCdWB3Nzcxw4cADNmjXD4MGD4eXlhffffx8dOnQAUHEf4qJFizBr1ix069YN2dnZCA8Pf2LxEN2PT0ynesvf3x99+vTRSe8GEREREekOe0KIiIiIiEinmIQQ1VOLFy9Gy5Ytq32tX79e3+EREZEWHTp0qMZrfkREhL7DI9I6Dsciqqdu3ryJmzdvVrvN2toa5ubmOo6IiIielLt37+LixYvVbtP3zIpETwKTECIiIiIi0ikOxyIiIiIiIp1qVA8rLC8vx6VLl2Bubl7jk7aJiKhmQggUFhbCxsYGBgZN43cqth1ERI9P0/ajUSUhly5dgp2dnb7DICJq8JRKJWxtbfUdhk6w7SAi0p66th+NKgmpvFFXqVTCwsJCz9EQETU8BQUFsLOza1ITH7DtICJ6fJq2H40qCansRrewsGBDQkT0GJrSsCS2HURE2lPX9qNpDPglIiIiIqJ6o1H1hBARaaq8vBz37t3Tdxh60axZsyZz8zkRkbaVlZWhtLRU32HonLbaDiYhRNRk3bt3D1lZWSgvL9d3KHphYGCATp06oVmzZvoOhYiowRBC4MqVK/jnn3/0HYpeaKvtYBJCRE2SEAKXL1+GoaEh7OzsmlyPQOW0tJcvX4ZcLm9S94AQET2OygTEysoKLVq0aFLXT222HRonIRkZGQgKCsL169fRunVrrF27Fu7u7lXKxcXFYcmSJSgvL8fAgQMRHR0NIyMjnD59GlOnTkVeXh6MjY3Rs2dPrFq1CiYmJgAqbmbx9PSU/kOwatUq9O3b95ErSDWbP//RthE1BiqVCnfu3IGNjQ1atGih73D0ol27drh06RJUKhWMjY31HQ49Am1eq3ndJ3q4srIyKQFp06aNvsPRC221HRr/9BceHo6wsDCkp6dj1qxZCAkJqVImKysLc+bMweHDh5GZmYkrV64gLi4OAGBqaorVq1cjLS0NqampyM/Px/Lly9Xef+TIEaSmpiI1NZUJCBE9EWVlZQDQpIciVda98lwQEVHtKu8Baao/XgHaazs0SkLy8vKQkpKCiRMnAgACAwORlZWF7OxstXKJiYkYPXo0rK2tIZPJEBERgQ0bNgAAnJ2d0bVrVwCAoaEhfH19cf78+UcKvqSkBAUFBWovIiJNNKVu9Ac15boTET2Opnz91FbdNRqOpVQqYWNjAyMjIykIuVyOnJwcKBQKqVxOTg7s7e2lZYVCgZycnCr7u337NmJjY7F06VK19f7+/igtLcXAgQPxwQcfwMzMrNp4oqKiEBkZqUkV6AmpqRuf3fvUkDzJ72tT+Ft43OG6ALBr1y7MmDEDKpUKXl5eiI+PR8uWLXHp0iVMmjQJ2dnZMDExgZubG9asWQNLS0uNjk1E9CQ8qWt8Y247NB6O9WD2I4R4aLnqypSWlmLcuHEYMmQIXnjhBWn9hQsXcPz4cRw5cgTXrl3DzJkza4xl9uzZyM/Pl15KpVLT6hAR1WsymQxFRUU1bs/OzsYXX3yhw4hq9rjDdYuKihASEoLt27cjMzMTHTp0wKJFiwBU9JzPmTMHZ8+exalTp2Bvb4933nlHo2MTETUl9b390CgJsbOzQ25uLlQqFYCK5EKpVEIul6uVk8vlakO0Lly4oFamtLQUY8eORYcOHfDpp59WeS8AmJmZYcqUKTh06FCN8ZiYmEhPuOWTbomoKdJ3I1JJG8N1d+/ejR49esDNzQ0AMGXKFGmbtbU1+vTpI+3n6aefloby1vXYlTiUl4hI/+2HRkmIlZUVfHx8kJCQAADYsmULFAqF2lAsoKIB2LZtG65evQohBNasWYPx48cDqJiRZvz48bC0tMQXX3yh1mNy69Yt3LlzB0DFFGCbNm2Cj4/P49SPiKhB2bp1K9zc3NCzZ0988MEH0vqJEyeiR48e6Nq1K55//nnk5eUBACIiInDmzBl4e3sjICAAADBz5kz4+vrC29sb/fv3R0ZGxhOPu7bhuverbbhuddsuXrxY5TkuZWVl+OyzzzBy5EiNjl0pKioKrVq1kl52dnaPWXsiIv1raO2HxsOxYmJiEBMTAxcXFyxZskTqRp88eTJ27NgBAHBwcEBkZCR69+4NR0dHWFlZSV3jmzZtwtatW3H8+HH4+PjA29sbU6dOBQCkpaXhmWeegZeXFzw9PXHjxg2sWLFCS1UlIqrf8vLyEBoaiu+++w5JSUnS1OUAsGLFChw/fhynTp1Cnz59sGDBAgDAmjVr4O7ujtTUVOka/PbbbyM5ORmpqan497//jTfffFMn8WtjuO7DbngUQmDKlClo3bo1XnvtNY2PDXAoLxE1Pg2x/dD4OSGurq5ISkqqsj42NlZtOTQ0FKGhoVXKTZgwARMmTKh23z179sSpU6c0DYmIqFE4evQounXrBldXVwBAWFgY3n77bQDA+vXrsW7dOpSUlODu3bto3759jfvZs2cPVq1ahcLCQpSXl+tkuNH9w3WNjIweabiuXC7Hvn37pG3Z2dno2LGj2oMkX3/9dSiVSmzfvl1aX9djVzIxMVFroImIGrqG2H40rUcEExHVYzX9ep+amorVq1dj9+7dOH36ND7++GMUFxdXWzYnJwevv/461q9fjz///BMbN26ssaw2aWO47rBhw5CcnIy0tDQAQHR0tLQNqEhAMjMzsW3bNrXnu9T12EREjVVDbD807gmhpuFJT7nLKX2JqurZsydCQkKQnp4OFxcXqYf51q1bsLCwgKWlJe7du4eYmBjpPRYWFsjPz5eW8/Pz0axZM7Rv3x5CCKxevVpn8cfExCA4OBiLFy+GhYUF4uPjAVQM1w0ICEBAQIDacN3y8nIMGDBAGq5rbm6O2NhYjBo1CiqVCp6entI+fvvtN6xatQpubm54+umnAQCdOnXCtm3baj02EVFT0BDbDyYhRET/n76TYCsrK3zxxRcYOXIk2rRpg5deegkA8OyzzyIhIQFubm6wtbVFr1698NNPPwEAunbtCldXV3h4eMDBwQE7duzAmDFj0KVLF8jlcgwePFhn8T/ucF0AUrLyoN69e9d6n0dNxyYi0gW2H5qTidqu6g1MQUEBWrVqhfz8fE7XWweP8gejaQ+GttYTaVtxcTGysrLQqVMnmJqa6jscvajuHDTF62hDrrM2r5m8/hI9HNuOms+BptdS3hNCREREREQ6xSSEiIiIiIh0ikkIETVpjWhEqsaact2JiB7Hgw9RbUq01XbwxnQiapKMjY0hk8lw7do1tGvX7qEPyWtshBC4du0aZDIZjI2N9R0OEVGD0KxZMxgYGODSpUto164dmjVr1qTaD222HUxCiKhJMjQ0hK2tLXJzc9UenteUyGQy2NrawtDQUN+hEBE1CAYGBujUqRMuX76MS5cu6TscvdBW28EkhIiarJYtW8LZ2RmlpaX6DkUvjI2NmYAQEWmoWbNmkMvlUKlUKCsr03c4OqettoNJCBE1aYaGhvyPOBERaaRyOBKHsz463phOREREREQ6xSSEiIiIiIh0ikkIERERERHpFJMQIqr3tm7diu7du8Pb2xudO3fGwIEDpTnaFQoF/vzzTz1H+GT8/vvv8Pb2houLCwYOHIjLly9XW+727duYNGkSPD094erqinfeeUeax728vBwzZsyAh4cH3NzcEBISgnv37umyGkREetFU246XXnoJNjY2kMlkKCoqqrXswYMH4evriy5dusDNzQ1JSUkAgAMHDqBFixbw9vaWXnfv3tVqnLwxnYjqtStXriAiIgLJycmwt7cHAKSkpDT6edmFEJgwYQJiY2Ph7++PZcuWYfr06diwYUOVsosXLwYAnDp1CiqVCs8//zwSExMxZswYxMXF4dSpU0hJSYGxsTEmT56MTz/9FDNnztR1lYiIdKapth0AEBERgejoaFhbW9da7tKlSwgKCsLu3bvRuXNnFBcXo7i4WNru7u6O48ePP7E42RNCRPXa5cuXYWRkhDZt2kjrunXrVm1DsnLlSvTp0wfXrl3DlStXMHbsWPj5+aFr166YO3cuAOCnn37C0KFDAQD//PMPDA0N8eWXXwIA4uLiEBISAgDw9/fH22+/jb59+8LR0RERERHScQoLCxEaGirtOyIiQprmd+HChejcubP0y9GFCxdw9+5djBs3Du7u7vDy8sKQIUMeWu/jx4/DxMQE/v7+AIDw8HBs37692umET548ieHDh0uztQwZMgTr1q2Ttg0aNEh6oNaIESOkbUREjVVTbTsAYNCgQbCysnpouejoaEycOBGdO3cGAJiamqJ169Z1OoY2MAkhonrNy8sLPXv2hFwux+jRo/HRRx/h4sWLamXKy8vx5ptv4uDBg/j555/Rrl07BAUFYdq0aTh27BhSUlJw7NgxbNu2Df369cOxY8dQUlKC/fv34+mnn8Yvv/wCANi7dy8GDRok7ffcuXM4cOAA/vzzT/z0009SN/Vbb70l7efkyZNQqVRYvXo1bt26hWXLliElJQWpqak4cuQIrK2t8eOPP+LWrVs4c+YMTp48iY0bN0rH8Pb2rvaBVzk5OdKvdwBgbm4Oc3Pzaodk+fr6YvPmzbh37x4KCwuxbds26QGMvr6++O6771BYWIh79+5h48aNTfbhjETUdDTVtkMTZ86cwd27dzFo0CB4e3vjtddew507d6TtZ8+eRbdu3eDr64vo6OjHOlZ1NE5CMjIy0KtXL7i4uMDPzw9nzpyptlxcXBycnZ3h6OiIsLAwqFQqAMDp06fRr18/uLm5wdPTE2FhYSgpKZHeV9cx0ETUNBgYGGDLli04cuQIhg0bht9++w1dunRBZmamVObVV19FcXExvv32WzRv3hy3b9/Gvn378Prrr8Pb2xs9evRAZmYm0tLS0Lx5c3h7e+O3337D3r17MXv2bKSkpKC8vBz79+/HwIEDpf2OHz8ehoaG0nvOnTsHANi+fTs++ugjeHt7w8fHB4cOHUJGRgYsLCzg7OyMiRMnIiYmBjdv3oSpqSm8vLyQlpaGKVOmYNOmTWrzyqempsLGxqbauj/4i13lfR4Pevvtt2FnZwc/Pz8EBASgV69e0jFeeeUVDB06FP369cOAAQPQpUsXzmtPRI1eU2476qq0tBQHDhzAt99+i+PHjyM/Px/z588HUNFrlJubi5SUFGzbtg1r1qzB5s2bH+t4D9I4CQkPD0dYWBjS09Mxa9YsqfvpfllZWZgzZw4OHz6MzMxMXLlyBXFxcQAqunpWr16NtLQ0pKamIj8/H8uXLwfwvzHQK1asQHp6OoYPH47p06c/ZhWJqDFwc3OThiQ988wz2LFjh7TN398fR44cQV5eHoCKX7dkMhmSk5ORmpqK1NRUZGZmYvbs2QAquqr37t2LQ4cO4dlnn0WXLl2wbt06WFtbq3Vhm5qaSv82NDSUfkwRQmD79u3Svs+ePYvo6GgYGhri6NGjeOONN5CXl4dnnnkGhw4dgoODA86cOSM1hB4eHrh161at9ZXL5Wo9FoWFhSgsLESHDh2qlDU1NcUnn3yC1NRU7N+/H5aWlnB3dwdQkcjMnTsXJ06cwOHDh+Hm5iZtIyJq7Jpa26EJe3t7PPfcc3jqqadgZGSE8ePH49ixYwAACwsLtGrVCgBga2uL//u//8OhQ4e0dmxAwyQkLy8PKSkpmDhxIgAgMDAQWVlZVbr2ExMTMXr0aFhbW0MmkyEiIkK6mdLZ2Rldu3YFUPHB+Pr64vz58wA0GwMNACUlJSgoKFB7EVHjcvHiRfz222/S8q1bt5CVlQVHR0dpXXBwMN577z0MGDAAFy5cgLm5Ofr27YslS5ZIZS5duoTc3FwAFQ3JN998g6eeegotW7bEoEGDMG/ePLXu9NoEBARgyZIlUsNy69YtZGZmorCwEFevXkXfvn0xZ84c9OnTBydOnEBubi5kMhkCAgKwbNkyCCGgVCprPUb37t1RXFyMAwcOAABiYmIwatSoansxCgoKpC70rKwsfP7553jrrbcAAMXFxfjnn38AANevX8eSJUswa9asOtWTiKihaqpthyb+9a9/Yf/+/dKIpB9//BFeXl4AKu6pqZxJrLCwELt27YKPj4/Wjg1oODuWUqmEjY0NjIwq3iaTySCXy5GTkwOFQiGVe3Ass0KhQE5OTpX93b59G7GxsVi6dGm177t/DLRcLq/y/qioKERGRmpSBXpM/7+XjkhnVCoVFixYgKysLLRo0QIqlQpBQUF44YUX1MqNHTsWZmZmGDJkCHbu3In169dj+vTp8PT0BAC0bNkSa9asga2tLXr06IH8/Hyp+3zw4MGYNm1anRuSFStW4O2334a3tzcMDAxgbGyMpUuXwtTUFC+99BJu374NmUwGZ2dnBAUF4ciRI9K0ueXl5Xj55ZelH2O8vb3xww8/VOlWNzAwQEJCAiIiInD37l107NgRCQkJ0vYRI0ZgwYIF6NGjB86fP4+xY8fCyMgIRkZG+OSTT+Dt7Q0AyM/PR//+/WFoaIiysjK88cYbGDly5CN9FkREDUVTbTuAimQnJSUFAODq6gpnZ2fpB637245evXph5MiR8Pb2hpGRETw8PLBmzRoAwJYtW/D555/DyMgIKpUKY8aMwaRJkzT/IGohEzUNMq7GH3/8gVdeeQV//fWXtM7X1xfLly9Hv379pHWvvfYa5HK5NAXkX3/9hZEjR0o9HkDFOLTRo0fDwcEBK1euBFBR4f/+97/4/vvvpXLt2rXDH3/8UW0SUlJSonY/SUFBAezs7JCfnw8LC4u6VqvJ0kVCUdMxNF1PRLpRUFCAVq1aNanraEOuszavmbz+EtHj0PRaqlFPiJ2dHXJzc6FSqWBkZCR1Cz2YIDw4lvnChQtqZUpLSzF27Fh06NABn376aY3vq20MNACYmJjAxMREkyoQEREREZGeaXRPiJWVFXx8fKQhAVu2bIFCoVAbigVU3Cuybds2XL16FUIIrFmzBuPHjwdQ0T02fvx4WFpa4osvvlCb/UWTMdBERERERNQwafzE9JiYGAQHB2Px4sWwsLBAfHw8AGDy5MkICAhAQEAAHBwcEBkZid69e6O8vBwDBgyQZtHatGkTtm7diq5du0o3uPTu3RufffbZQ8dAExERERFRw6dxEuLq6io9dOV+sbGxasuhoaEIDQ2tUm7ChAmYMGFCjfvv2bMnTp48qWlYRERE9ATwHj4iehL4xHQiItKKx32YLQDs2rULbm5ucHJyQmBgIIqKiqRtL730EmxsbCCTydTWAxWzMLq5ucHb2xve3t7YtGnTk6kkERFphcY9IURERNWpfJhtcHAwEhMTERISUqXnvPJhtidOnICVlRVeeOEFxMXFITw8HEVFRQgJCcHBgwfh5uaGadOmYdGiRYiKigIAREREIDo6GtbW1tUePzExER4eHk+8no0VezaISJfYE0JERI9NGw+z3b17N3r06AE3NzcAwJQpU6RtQMWDwu5/KvGj4oNuiYj0j0kIERE9ttoeZnu/2h5mW922ixcvSk/tfZgJEybA09MTkydPxrVr12osFxUVhVatWkkvOzu7OteTiIi0g8Ox6Ili9z5R03H/lOsAUNOzcO8v92CZB/dRV7/++ivkcjlKS0vx/vvvIygoCD/88EO1ZWfPno3p06dLy5UPuiUiIt1hEkJERI9NGw+zlcvl2Ldvn7QtOzsbHTt2hIHBwzvtK/dhbGyMN954Ay4uLjWW5YNuiYj0j8OxiIjosWnjYbbDhg1DcnIy0tLSAADR0dHSttrcvn0b//zzj7S8YcMG6TlURERUP7EnpAngkCgi0oXHfZitubk5YmNjMWrUKKhUKnh6ekr7AICAgACkpKQAqHhmlbOzMw4cOICrV68iMDAQZWVlEELAwcEBX3/9te5PABER1ZlM1DRotwEqKChAq1atkJ+fDwsLC32HU280pCSkIcVK1Bg1xetoQ66zPq+ZvF4T0f00vZZyOBYREREREekUkxAiIiIiItIpJiFERERERKRTTEKIiIiIiEinmIQQEREREZFOcYpeahBqmoWFs7MQERERNTzsCSEiIiIiIp1iEkJERERERDrFJISIiIiIiHRK4yQkIyMDvXr1gouLC/z8/HDmzJlqy8XFxcHZ2RmOjo4ICwuDSqUCABQVFWHo0KFo27Yt2rZtW+V9MpkMXbt2hbe3N7y9vXHo0CFNQyQiIiIionpM4yQkPDwcYWFhSE9Px6xZsxASElKlTFZWFubMmYPDhw8jMzMTV65cQVxcHADA2NgYs2bNwt69e2s8xpEjR5CamorU1FT07dtX0xCJiIiIiKge0ygJycvLQ0pKCiZOnAgACAwMRFZWFrKzs9XKJSYmYvTo0bC2toZMJkNERAQ2bNgAADAxMcHAgQPRunXrxw6+pKQEBQUFai8iIiIiIqrfNEpClEolbGxsYGRUMbOvTCaDXC5HTk6OWrmcnBzY29tLywqFokqZ2vj7+8PLywvTp0/H7du3aywXFRWFVq1aSS87OztNqkNERERERHqg8XAsmUymtiyEeGi5mspU58KFCzh+/DiOHDmCa9euYebMmTWWnT17NvLz86WXUqms83GIiIiIiEg/NHpYoZ2dHXJzc6FSqWBkZAQhBJRKJeRyuVo5uVyuNkTrwoULVcrUpLKcmZkZpkyZgrCwsBrLmpiYwMTERJMqEBERERGRnmmUhFhZWcHHxwcJCQkIDg7Gli1boFAooFAo1MoFBgaiT58+mDt3LqysrLBmzRqMHz/+ofu/desWTExM0KJFC5SXl2PTpk3w8fHRqELUtPBJ6kTUFPCaRkSNjcbDsWJiYhATEwMXFxcsWbJEmvVq8uTJ2LFjBwDAwcEBkZGR6N27NxwdHWFlZaU2i1a3bt3Qs2dP3Lp1C7a2tnj55ZcBAGlpaXjmmWfg5eUFT09P3LhxAytWrNBCNYmIiIiIqL7QqCcEAFxdXZGUlFRlfWxsrNpyaGgoQkNDq91HSkpKtet79uyJU6dOaRoSERERERE1IHxiOhERERER6RSTECIiIiIi0ikmIUREREREpFNMQoiIiIiISKc0vjGdiIiInozGMBVvbXVoDPUjIu1gTwgREREREekUkxAiIiIiItIpJiFERKQVGRkZ6NWrF1xcXODn54czZ85UWy4uLg7Ozs5wdHREWFgYVCqVtG3Xrl1wc3ODk5MTAgMDUVRUJG176aWXYGNjA5lMprZek2OT9syfX/2LiKgumIQQEZFWhIeHIywsDOnp6Zg1axZCQkKqlMnKysKcOXNw+PBhZGZm4sqVK4iLiwMAFBUVISQkBNu3b0dmZiY6dOiARYsWSe+NiIhAamrqIx+biIjqDyYhRET02PLy8pCSkoKJEycCAAIDA5GVlYXs7Gy1comJiRg9ejSsra0hk8kQERGBDRs2AAB2796NHj16wM3NDQAwZcoUaRsADBo0CFZWVo987EolJSUoKChQexERkW4xCSEiosemVCphY2MDI6OKSRdlMhnkcjlycnLUyuXk5MDe3l5aVigUUpnqtl28eBHl5eVaOXalqKgotGrVSnrZ2dlpXmEiInosTEKIiEgrZDKZ2rIQ4qHlHizz4D60fWwAmD17NvLz86WXUql8pGMSEdGj43NCiIjosdnZ2SE3NxcqlQpGRkYQQkCpVEIul6uVk8vlasOkLly4IJWRy+XYt2+ftC07OxsdO3aEgUHtv5fV9diVTExMYGJi8og1JSIibWBPCDUpnM2F6MmwsrKCj48PEhISAABbtmyBQqGAQqFQKxcYGIht27bh6tWrEEJgzZo1GD9+PABg2LBhSE5ORlpaGgAgOjpa2qaNYxMRUf3BJISIiLQiJiYGMTExcHFxwZIlS6RZryZPnowdO3YAABwcHBAZGYnevXvD0dERVlZW0kxW5ubmiI2NxahRo+Dk5ISLFy/i3XfflfYfEBAAW1tbAICrqyv8/f0femwiIqqfOByLiIi0wtXVFUlJSVXWx8bGqi2HhoYiNDS02n0EBAQgICCg2m2ViYwmxyYiovqJPSFERERERKRT7AlpgGq6h6Ex3NvQGOpARERERLVjTwgREREREemUxklIRkYGevXqBRcXF/j5+eHMmTPVlouLi4OzszMcHR0RFhYGlUoFACgqKsLQoUPRtm1btG3btsr7fv/9d3h7e8PFxQUDBw7E5cuXNQ2RiIiIiIjqMY2TkPDwcISFhSE9PR2zZs2SZjW5X1ZWFubMmYPDhw8jMzMTV65ckWYqMTY2xqxZs7B3794q7xNCYMKECVixYgXS09MxfPhwTJ8+/RGq1bBw2lgiIiIiako0SkLy8vKQkpKCiRMnAqiY7z0rK0vtwVMAkJiYiNGjR8Pa2hoymQwRERHYsGEDgIqHRA0cOBCtW7eusv/jx4/DxMREmnYxPDwc27dvR2lpabXxlJSUoKCgQO1FRERERET1m0ZJiFKphI2NDYyMKu5nl8lkkMvlyMnJUSuXk5MDe3t7aVmhUFQpU50H32dubg5zc/Mah2RFRUWhVatW0svOzk6T6hARERERkR5oPBxLJpOpLQshHlqupjKPs38AmD17NvLz86WXUqms83GIiIiIiEg/NJqi187ODrm5uVCpVDAyMoIQAkqlEnK5XK2cXC5XG6J14cKFKmWq8+D7CgsLUVhYiA4dOlRb3sTEBCYmJppUgYiIiIiI9EyjnhArKyv4+PggISEBALBlyxYoFAooFAq1coGBgdi2bRuuXr0KIQTWrFmD8ePHP3T/3bt3R3FxMQ4cOAAAiImJwahRo2BsbKxJmEREREREVI9p/LDCmJgYBAcHY/HixbCwsEB8fDwAYPLkyQgICEBAQAAcHBwQGRmJ3r17o7y8HAMGDFCbRatbt264fPkybt26BVtbWzz77LNYt24dDAwMkJCQgIiICNy9excdO3aUEh4iIiIiImocNE5CXF1dkZSUVGV9bGys2nJoaChCQ0Or3UdKSkqN++/ZsydOnjypaViNEqfpJSIiIqLGiE9MJyIiIiIindK4J4SIiIgeD3u6iaipYxLSiLBRa7pq+uz5nSAiIqL6iMOxiIiIiIhIp5iEEBERERGRTnE4FlEtOMyJiIiISPuYhBAREZFO8IcdIqrE4VhERERERKRTTEKIiIiIiEinOByLSIsaylCDhhInERERNU7sCSEiIiIiIp1iTwgRERHpFXtniZoeJiFEYENHpA0ZGRkICgrC9evX0bp1a6xduxbu7u5VysXFxWHJkiUoLy/HwIEDER0dDSOjiuZo165dmDFjBlQqFby8vBAfH4+WLVsCAH7//XeEh4fjzp07sLOzQ0JCAjp06AAAUCgUMDU1hampKQBg9uzZGDdunI5qTkREmuJwLCIi0orw8HCEhYUhPT0ds2bNQkhISJUyWVlZmDNnDg4fPozMzExcuXIFcXFxAICioiKEhIRg+/btyMzMRIcOHbBo0SIAgBACEyZMwIoVK5Ceno7hw4dj+vTpavtOTExEamoqUlNTmYAQEdVzTEKIiOix5eXlISUlBRMnTgQABAYGIisrC9nZ2WrlEhMTMXr0aFhbW0MmkyEiIgIbNmwAAOzevRs9evSAm5sbAGDKlCnStuPHj8PExAT+/v4AKhKe7du3o7S0VONYS0pKUFBQoPYiIiLd4nAsonqI46OpoVEqlbCxsZGGVclkMsjlcuTk5EChUEjlcnJyYG9vLy0rFArk5OTUuO3ixYsoLy+vss3c3Bzm5ua4fPky5HI5AGDChAkoLy/H008/jaioKLRr167aWKOiohAZGam1uhMRkebYE0JERFohk8nUloUQDy33YJkH91HX/f/66684efIkUlJS0KZNGwQFBdW4n9mzZyM/P196KZXKGssSEdGTwZ4QIiJ6bHZ2dsjNzYVKpYKRkRGEEFAqlVIvRSW5XK42ROvChQtSGblcjn379knbsrOz0bFjRxgYGFR5X2FhIQoLC6Ub0yv3YWxsjDfeeAMuLi41xmpiYgITE5PHrTIRET0GjXtCMjIy0KtXL7i4uMDPzw9nzpyptlxcXBycnZ3h6OiIsLAwqFQqaduuXbvg5uYGJycnBAYGoqioSNomk8nQtWtXeHt7w9vbG4cOHXqEahERkS5ZWVnBx8cHCQkJAIAtW7ZAoVCoDcUCKu4V2bZtG65evQohBNasWYPx48cDAIYNG4bk5GSkpaUBAKKjo6Vt3bt3R3FxMQ4cOAAAiImJwahRo2BsbIzbt2/jn3/+kY6xYcMG+Pj4PNkKExHRY9G4J6Ry9pPg4GAkJiYiJCQESUlJamUqZz85ceIErKys8MILLyAuLg7h4eHS7CcHDx6Em5sbpk2bhkWLFiEqKkp6/5EjR6QpGYkaA33dy8F7SEiXYmJiEBwcjMWLF8PCwgLx8fEAgMmTJyMgIAABAQFwcHBAZGQkevfujfLycgwYMECaRcvc3ByxsbEYNWoUVCoVPD09pX0YGBggISEBERERuHv3Ljp27CglPFevXkVgYCDKysoghICDgwO+/vpr/ZwE0ipN74/T9JrHaySR/miUhFTOfrJnzx4AFb9oTZs2DdnZ2Wq/dt0/+wkARERE4MMPP0R4eHi1s5+MGDFCLQmpq5KSEpSUlEjLnOGEiEh/XF1dq/woBQCxsbFqy6GhoQgNDa12H5XJSnV69uyJkydPVlnv4OCAEydOPELERESkLxolIU969hMDg4rRYf7+/igtLcXAgQPxwQcfwMzMrNp4OMMJERER1Qfa6rVh7ww1FRoPx3rSs59U3qR4+/ZtREREYObMmYiOjq627OzZs9UeVlVQUAA7O7uH1oEaP17EiYiIiOovjW5Mv3/2EwCPPPvJ/dvun/2kcjsAmJmZYcqUKbXemG5iYgILCwu1FxERERER1W8a9YTcP/tJcHBwrbOf9OnTB3PnzoWVlVWV2U+mTp2KtLQ0uLm5qc1+cuvWLZiYmKBFixYoLy/Hpk2bOMMJERERNVjavFmevfzUmGg8HOtJzn6SlpaG8PBwyGQyqFQqdOvWDZ9++qkWq6sbHOfZ+HG2KyIiIqJHp3ES8iRnP+nZsydOnTqlaUhERET1En84aLj42RE9WRo/rJCIiIiIiOhxMAkhIiIiIiKd0ng4FhEREVFjwCFXRPrDnhAiIiIiItIpJiFERERERKRTHI5FRBJOL01ERES6wJ4QIiIiIiLSKfaEEBERUYPC3lmiho9JCBE9lKYNvjbL8z8bREREjQ+HYxERERERkU4xCSEiIiIiIp1iEkJERERERDrFe0LqQFvTlnJsOxFR48TrO+mCtv7foYvp2DnlOz0Me0KIiIiIiEinmIQQEREREZFOcTgWEWldQ+qGb0ixEhERNRZMQoiIiIhIr7R1/wp/QKqb+nD+OByLiIiIiIh0SuOekIyMDAQFBeH69eto3bo11q5dC3d39yrl4uLisGTJEpSXl2PgwIGIjo6GkVHF4Xbt2oUZM2ZApVLBy8sL8fHxaNmyJQDg999/R3h4OO7cuQM7OzskJCSgQ4cOj1nNuuFsV0T1T337u9TX7DT17TxUR5/tQ12PTURE9YPGSUh4eDjCwsIQHByMxMREhISEICkpSa1MVlYW5syZgxMnTsDKygovvPAC4uLiEB4ejqKiIoSEhODgwYNwc3PDtGnTsGjRIkRFRUEIgQkTJiA2Nhb+/v5YtmwZpk+fjg0bNmitwkRE9GTos32oy7GJmpon/aNJY6HPejfVcw5omITk5eUhJSUFe/bsAQAEBgZi2rRpyM7OhkKhkMolJiZi9OjRsLa2BgBERETgww8/RHh4OHbv3o0ePXrAzc0NADBlyhSMGDECUVFROH78OExMTODv7w+golGxsrJCaWkpjI2Nq8RTUlKCkpISaTk/Px8AUFBQoEm17tvfI72NiOqopj9Nbf7tafrnX9OxtRWrpvt50sd9+Psq3iiE0Oh9+mwfbt26VadjV9J221Gxz0d+K1G99yh/Gtq6xmmrfG20ua+GcuwncVyN2w+hgePHj4vOnTurrfP19RUHDx5UWzdt2jSxdOlSafmvv/4SnTp1EkIIsWzZMvHvf/9b2nb79m1hZGQkysrKRGJiohg+fLjavtq1aycuXLhQbTzz5s0TAPjiiy+++NLyS6lUatI86LV9qOux2XbwxRdffD35V13bD42HY8lkMrVlUUO2c3+5B8s8uI9H2T8AzJ49G9OnT5eWy8vLcfPmTbRp06bKfgoKCmBnZwelUgkLC4sa96lvjFN7GkKMAOPUtoYQZ32OUQiBwsJC2NjYaPxefbYPT6rtaMzq8/dQV3gOKvA88BwAj38ONG0/NEpC7OzskJubC5VKBSMjIwghoFQqIZfL1crJ5XJkZ2dLyxcuXJDKyOVy7Nu3T9qWnZ2Njh07wsDAoMr7CgsLUVhYWOON6SYmJjAxMVFb17p161rrYGFh0SC+XIxTexpCjADj1LaGEGd9jbFVq1Yav0ef7YOpqWmdjl3pUdqOxqy+fg91ieegAs8DzwHweOdAk/ZDoyl6rays4OPjg4SEBADAli1boFAoqoy5DQwMxLZt23D16lUIIbBmzRqMHz8eADBs2DAkJycjLS0NABAdHS1t6969O4qLi3HgwAEAQExMDEaNGlXt/SBERFR/6LN9qOuxiYio/tB4OFZMTAyCg4OxePFiWFhYID4+HgAwefJkBAQEICAgAA4ODoiMjETv3r1RXl6OAQMGICQkBABgbm6O2NhYjBo1CiqVCp6entI+DAwMkJCQgIiICNy9excdO3aUGhUiIqrf9Nk+1HRsIiKqp+p050gjUFxcLObNmyeKi4v1HUqtGKf2NIQYhWCc2tYQ4mwIMVLjx+8hz0ElngeeAyF0fw5kQmg4DyMREREREdFj0OieECIiIiIiosfFJISIiIiIiHSKSQgREREREekUkxAiIiIiItKpRp+EREZGQiaT4c8//wQA5OXlYdiwYXB2doaHhwcOHz6s1/hKSkowbdo0ODs7o0uXLpg4cWK9i/Onn35C9+7d4ePjAw8PD2nqS33H+Prrr0OhUKh9vg+L686dO/i///s/ODk5wcXFBVu3btVbnK+++ipcXV3h7e2Nfv36ITU1VW9x1hRjpfj4eMhkMuzatUtvMdYWpxAC8+fPh4uLCzw8PODv718v4zx+/Dh69uwJHx8fdO7cGR9++KFe46TGTaFQwM3NDd7e3vD29samTZsA1L9rpDZpu10oLy/Ha6+9BkdHRzg5OSE6Olqn9XlUNZ0Hf39/ODg4SN+JTz75RNrW2M5DcXExRo0aBRcXF3h7e2PYsGHSA0+byvehtnNQL74LOpmDS0/++OMPMWzYMCGXy8Xp06eFEEJMmjRJzJs3TwghxLFjx4RcLhelpaV6i/GNN94Qr732migvLxdCCHHp0iUhRP2Js7y8XFhaWoqTJ08KIYTIysoSJiYmoqCgQO8xHjx4UCiVSmFvby99vkLUfu4iIyNFUFCQEEKI8+fPC2tra3Hz5k29xPndd99Jce3cuVM4OztL23QdZ00xCiGEUqkUPXv2FM8884zYuXOn3mKsLc4VK1aIF198UZSUlAgh/vd3VN/i9Pb2Ft99950QQogbN26Idu3aib/++ktvcVLjVt3fsxD17xqpTdpuF+Lj48WAAQOESqUSN27cEPb29uLvv//WaZ0eRU3noX///mrX8fs1tvNw9+5d8f3330v/v1q1apUYPHiwEKLpfB9qOwf14bvQaJOQ4uJi8cwzz4jz58+r/RGamZmJvLw8qZyvr6/Yv3+/XmIsKioSrVq1EoWFhVW21Zc4K5OQgwcPCiGEOHnypLCxsRElJSX1JsYHL7K1xeXu7i6OHTsmbRszZoz46quv9BLn/a5duyaaNWsmysrKhBD6i7O6GIcPHy6OHj1a5YJVn85lx44dRUZGRrVl61Oc3t7eIj4+XgghRE5OjujYsaO4fPmy3uOkxqmma059vUZqk7bahREjRojNmzdL22bOnCn957Uh0CQJacznQQghkpOThaOjoxCi6X4f7j8H9eG70GiHY82dOxcTJ05Ep06dpHU3btxAeXk52rVrJ61TKBTIycnRR4g4d+4c2rRpg4ULF6JHjx7o27cvfvnll3oVp0wmw+bNm/Hiiy/C3t4effr0QXx8PAoLC+tNjPd72LnLycmBvb19tdv06dNPP8WIESNgYFDxJ1lf4vz888/RpUsXPP3001W21ZcYCwoKcO3aNWzbtg3PPPMMnnnmGWnYSX2KEwC++uorzJkzB3K5HC4uLoiKikL79u3rXZzUeEyYMAGenp6YPHkyrl271mCvkY/jcercGM/HzJkz4enpiXHjxuH8+fPS+sZ+HlauXImRI0c26e9D5TmopO/vQqNMQpKSkpCcnIwpU6ZU2SaTydSWhR6f1VhaWorz58/D3d0dx48fx+rVqzF+/HioVKp6E6dKpUJUVBS+++47XLhwAb/88guCgoIA1K9zeb+HxXX/9voQc0JCAjZv3oyYmBi19fqOMysrC19++SUWLFhQYxl9xwhU/B3du3cPd+/exdGjR7F582ZMnz5dbRx0fYgTAD766CN89NFHyMnJwV9//YX33nsPZ8+elbbXlzipcfj1119x8uRJpKSkoE2bNnW+djfG7+Hj1LkxnY9169bh77//xqlTp9C3b188//zzatsb63lYvHgxMjIysGjRIgBN8/vw4DmoD9+FRpmEHDx4EGlpaejUqRMUCgVyc3MxdOhQHDt2DABw7do1qeyFCxcgl8v1Eqe9vT0MDAwwYcIEAICXlxc6deqEv//+u97EmZqaikuXLqF3794AAF9fX9jY2ODUqVP1Jsb7tWnTBkDNccnlcummrAe36cOmTZsQGRmJn3/+GVZWVtL6+hBnUlISLl26hM6dO0OhUODo0aMICQnBl19+WW9iBCo+85YtW0qTOsjlcvTu3RvHjx+vV3Fev34d27Ztw9ixYwEADg4OePrpp3HkyJF6FSc1HpXfH2NjY7zxxhs4dOhQg7tGasPj1LmxnQ87OzsAFf+JnDZtGs6fP48bN24AaLznYdmyZdi6dSt2796NFi1aNMnvw4PnAKgn34VHGsTVwNw/JjIoKEjtZiQ7Ozu93pg+ePBg8f333wshhMjOzhZt27YVly5dqjdxXrlyRZibm4u0tDQhhBAZGRniqaeeErm5ufUmxgfHvNYW17x589RutrKyshI3btzQS5ybNm0STk5OIjs7u0pZfcVZ230rD44frU/nMjQ0VHz22WdCCCFu3rwp7O3txR9//FGv4lSpVOKpp54SBw4cEEJU3Adka2srjbvVZ5zU+BQVFYlbt25Jy8uXLxd9+/YVQtTfa6Q2aatd+Oqrr8TAgQOlm3Dlcrk4c+aMTuvyOO4/D6WlpeLKlSvStsTERCGXy6Xlxngeli9fLrp161ZlcoWm9H2o7hzUl+9Ck0tCrly5IgYPHiycnJyEu7u79B8CfTl37pzo37+/8PDwEF5eXmLr1q31Ls5vvvlGeHh4iK5duwpPT0+xYcOGehHjlClTRMeOHYWhoaGwtraWbraqLa6ioiIxduxY4ejoKJydncW3336rtziNjIyEra2t8PLykl7Xr1/XS5w1xXi/B5OQ+nQur127Jp5//nnRpUsX0aVLF7FmzZp6GefPP/8sunXrJrp27So6d+4sVqxYodc4qfE6d+6c8Pb2Fp6ensLDw0MEBASIrKwsIUT9u0Zqk7bbBZVKJaZMmSIcHByEg4ODWLVqlc7r9CiqOw9FRUWie/fuUns+YMAAkZqaKr2nsZ0HpVIpAAgHBwepjfXz8xNCNJ3vQ03noL58F2RCNKABbURERERE1OA1yntCiIiIiIio/mISQkREREREOsUkhIiIiIiIdIpJCBERERER6RSTECIiIiIi0ikmIUREREREpFNMQoiIiIiISKeYhBARERERkU4xCSEiIiIiIp1iEkJERERERDrFJISIiIiIiHSKSQgREREREekUkxAiIiIiItIpJiFEtThw4ABkMhlUKpW+QyEiIiJqNJiEEP1/77//Pvz9/fUdBhERNXKZmZmQyWTIzs7WdyhEesMkhIiIiIiIdIpJCOnVhg0b4ObmBlNTU7Rv3x5hYWEAAIVCgY8++ggvvvgiWrRoAXd3dyQnJ+P06dN4+umn0bJlSzz33HO4efOmtK/bt29j8uTJeOqpp9CyZUsEBgbi6tWr0naVSoVZs2bBysoKzZs3x+DBg5GRkQEAWLt2LRYtWoSDBw9CJpNV+YXq4MGDcHd3h7m5OUaNGoVbt25J2/z9/TFr1iyEh4fD3NwcCoUCGzduVKtnSkoK/P390bx5cygUCsybN08a4iWEwOzZs9GxY0eYmprCwcEBMTExAIDi4mKEhoZKMbu5uWH79u0PPa/BwcGYMGECZs+eDUtLS1hbW+Orr77CP//8gzFjxqBly5bo2rUrUlNT1d63ceNGuLu7o3nz5vDw8EBiYqK07erVq3jppZfQvn17mJubo1+/fmrvz87Ohkwmw/bt2+Hn5wczMzP4+/sjJyfnofESET2MSqXC3LlzIZfLYWpqis6dO2Pnzp0AgK+//hpOTk4wMTGBp6cndu/eLb2vcljtnj174O7ujhYtWmDs2LEoLi7G6tWrYWNjAysrK3z44YfSeyqvZ5s3b4a3tzdMTU0xYMAAKJVKqcyOHTvwzDPPwNzcHDY2NpgyZQpu376tFvPGjRvh6ekJExMT2NraYuHChQAAZ2dnAECnTp0gk8kwf/58ABVt3/LlyzFmzBiYmZmhc+fO2Ldvn9o+9+7dix49eqB58+ZwcXHBZ599Jm2rrc24ceMGxowZA0tLS5iZmcHLywtJSUkPPe/+/v6YOXMmQkNDpTbuhx9+QG5uLgYNGgQzMzP07t0bFy5cUHvfypUr4eDggBYtWsDX1xcHDhyQtqWlpWHEiBFo27YtWrdujREjRiArK6vKZ/bLL7/U2PZSIyCI9OTSpUvCxMREbNy4UWRnZ4vk5GSxZs0aIYQQ9vb2wsrKSqxbt06cPXtWjBo1Sri6uopnn31WHDhwQJw4cUI4OTmJ6dOnS/sLDQ0VTk5O4uDBg+KPP/4QTz/9tBg8eLC0fdGiRcLKykrs2rVLnD59WowcOVK4ubkJlUol7ty5I9544w3Rs2dPcfnyZXH58mWhUqnE/v37BQDh7+8vfv/9d5GcnCwcHBzUjtu/f39hYWEhPv74Y5GRkSHmzZsnTE1NxdWrV4UQQly/fl1YWlqKpUuXioyMDLF//37h5OQklixZIoQQYtOmTUIul4vDhw+L7OxssW/fPrFt2zYhhBBLly4VPj4+4vjx4+L8+fPihx9+EL/88stDz21QUJAwNzcX77zzjjh79qxYuHChMDY2FsOHDxcJCQkiPT1djB49WnTr1k16zy+//CLatm0rNm/eLM6dOyfWr18vmjdvLpKSkoQQQmRlZYlPP/1UnDp1Spw9e1aEh4cLOzs7cffuXWk7AOHl5SX27dsn/vzzT+Hr6ytefPHFR/l6EBGpeffdd0X79u3Fli1bRGZmpvjhhx/E7t27xW+//SYMDQ3Fp59+KtLS0sScOXNEs2bNRFZWlhBCqF3Hk5OTxaFDh0SbNm3E4MGDxauvvir+/vtv8dVXXwkA4uTJk0KI/13PnJycxE8//SRSU1NF3759Rf/+/aV4Nm3aJHbs2CHOnTsnDh48KNzc3MTMmTOl7T/99JMwNjYWy5cvF+np6eLIkSMiNjZWCCFEUlKSACCOHTsmLl++LAoLC4UQ/2v74uPjRXp6uggNDRUdOnQQJSUlQggh0tLShLm5uYiNjRXnzp0TO3fuFO3atRMbN24UQtTeZvz73/8WQ4cOFadPnxaZmZliy5Yt4vjx4w8975Vt3IoVK0R6erqYMmWKsLS0FEOHDhU7d+4Uf//9t+jZs6fatT4uLk44ODiI3bt3i3PnzomVK1eK5s2bS59JcnKyiIuLE3///bc4ffq0eOGFF4Sfn5/0/rq0vdTwMQkhvTl+/LiwsLCQLr73s7e3F//+97+l5coL9rfffiuti4qKkv4TXVBQIIyMjMT3338vbf/7778FAPHnn38KIYSwtrYWn332mbT9xo0bonnz5mLXrl1CCCHee+89tQZGiP9dCH///Xdp3eLFi0X37t2l5f79+4vhw4dLy6WlpaJFixZi586dQgghIiMjRWBgoNp+169fLxwdHYUQQixbtkwMHDhQlJeXVzkP06ZNE6+++mqV9Q8TFBQk3N3dpWWVSiXMzMzE1KlTpXWV57SgoEAIIcSzzz4rVq1apbaf0NBQERISUu0xKvd58OBBIcT/Gu1NmzZJZb755hvRpk0bjeMnIrrfnTt3hImJiVobUGncuHFizJgxauuefvppMWPGDCFE9dfx8PBwYWlpKYqLi6V1rq6uYuXKlUKI/13PPv/8c2l7RkaGACBOnz5dbYwbNmwQnTp1kpb79eunds29X+W+Kv9TXunBtu/SpUtqx5w0aZJ466231N6zaNEiMXDgQCFE7W3G888/LxYsWFDttto82MZdvnxZABAfffSRtG7Dhg3C0tJSWu7UqZPUBlYaPHiw+OCDD6o9RuU+L1y4IISoW9tLDR+HY5HeeHl5oWvXrnBwcEBwcDA2b96Me/fuSds9PT2lf1tbWwMAunTporbu2rVrAIDz589DpVLhmWeekba7ubmhdevWOHv2LPLz83H16lW17ZaWlnB1dcXZs2cfGuv9sbRv3x55eXk1bjcyMkLbtm2lMqdPn8aOHTvQsmVL6RUSEoLs7GyUl5cjMDAQZ86cQefOnfHmm2/i4MGD0r5efvllJCYmonv37nj33Xfxxx9/PDTWSh4eHtK/DQ0N0aZNmyrnD4B0Dk+fPo2ZM2eqxbl27VqcP38eAFBaWop3330XnTt3RuvWrdGqVSvcuXNHbXhCdefqxo0bKCsrq3PcREQPyszMRElJSbWTh5w9e1bt2g4APXv2rHJtf7BNqRy+df+6yuthJT8/P+nfTk5OeOqpp6T9njlzBqNHj4ZcLoe5uTkmTZqkdj38888/H2mykwevoQDU2pPVq1erXacXLFggXadrazNCQ0OxePFi9O3bFwsWLKhT21ddTDW1xzdv3kRZWRmKioqQlZWFcePGqcW5f/9+Kc78/HxMnToVzs7OsLCwgJOTEwA8tD15sO2lhs1I3wFQ02VkZIQDBw7g119/xY8//ohZs2bhww8/xJEjRwAAxsbGUlmZTFbtuvLycgAV91U8STUdt7rtD5YpKirC+PHjMXfu3Cr7NTAwgEKhQEZGBnbv3o2ffvoJI0eORFBQEFatWgU/Pz9kZWXh+++/x48//ojevXtj4cKFmDFjhkYxV8ZU3Tm9P85ly5Zh6NChau9r3rw5AGDp0qWIj4/HypUr4erqClNTU/j5+aG0tLTWcwU8+c+HiBq32q4hdb2+PHhtqu26ff+6mgQEBKBr165Yv349rKys8Ouvv0r3NT6Oh12np0+fjldffVXtPUZGFf+dq63NCAgIwPnz57Fz50788MMPWLRoEb7++muMGzfukWKq6VpfeV/MN998o5aoAIC5uTkA4K233sLRo0exYsUKdOrUCSqVCl5eXg9tTx78fKhhY08I6ZWhoSGeffZZLF26FMeOHcMff/xR5WbpunB0dISRkRGOHj0qrUtLS8M///wDNzc3tGrVCtbW1mrbb968ibNnz8LNzQ1AxcXuSfxi7+XlhTNnzsDJyanKq5KZmRleeuklfPnll4iNjUVcXJy0zdLSEi+//DLWr1+PBQsW4L///a/WY6yM8/z581Vi7NixIwDg6NGjGDNmDAIDA+Hh4QETExPeJEhEOuHs7AwTExO1m5srubm5qV3bASApKUm6tj+OY8eOSf8+d+4cbt26BVdXV1y/fh3nzp3D3Llz0bdvX7i6uuLKlStq7/Xw8Kg2XuB//7nWtM3x8vLC2bNnq1ynFQqFVKa2NqNDhw4ICwvD9u3bERISgvj4eI2OXxdWVlZo3749cnJyqsRZ2Yty9OhRTJ48Gc899xzc3d2Rn5+v9Tio/mNPCOnN77//jgMHDmDw4MFo06YNvv32W5iYmMDe3l7jfZmbm+PVV1/FG2+8AXNzc5iZmWHKlCkYPHgw3N3dAQD/+c9/EBkZCYVCAXt7e8yePRv29vbSL//29vY4e/Ys0tLS0LZtW1haWmqlnlOnTkVMTAxCQ0Mxbdo0mJqa4uTJk0hPT8f777+P+Ph4CCHw9NNPw9DQENu3b4erqysA4JNPPoGtrS28vb1RXFyMPXv2SNu07d1338XYsWNha2uL5557Dnfv3sWhQ4fQrl07jBs3Do6Ojvjxxx+RkpICAJgxYwZMTU2fSCxERPdr3rw53nrrLbz++uswMDCAj48PMjIyUF5ejtdffx39+vXD6tWrMWTIECQkJODEiRNVZil8FMuXL4ejoyPatWuH//znP+jXrx88PDxQVlaGp556Cl9++SXeeustJCcnS7MaVnrvvffw/PPPw9HREc8//zxu3bqFv/76C5MmTUL79u3RrFkz7NmzBy+99BLMzMzQokWLh8Yzc+ZM9OrVC++//z7+9a9/QQiB5ORk3LlzB1OmTKm1zZg3bx58fX3h7u6Omzdv4rfffsOAAQMe+xw9SCaT4d1338WcOXPQsmVL9OvXD7du3cLevXvh5+eHAQMGwNHREYmJiRgyZAhu3ryJmTNnaj0Oqv/YE0J6Y2FhgV9++QVDhgxB586dsWHDBmzdulX6pURTy5cvR9++fTFy5Ej069cPHTt2xLp166TtM2fORFBQEIKDg9GjRw/cuXMHO3bsgKGhIQDgpZdegp+fH3x9fdGuXTutTS1rZ2eHX3/9FUqlEr1794avry+WLVsGuVwOAGjVqhWio6Ph5+cHPz8/3Lx5U2o8zczM8MEHH8DLywv+/v6wtLTE559/rpW4HhQQEIANGzZg3bp18PT0xKBBg7Br1y4pKXz//ffRqVMn9OnTB4GBgQgNDUWbNm2eSCxERA+KjIzEpEmTMG3aNHTu3BlvvPEGysrK0KtXL/z3v//FihUr4OHhgW3btmH79u1qvQOPasGCBZg+fbp0b8jXX38NoKIXf/369dizZw+6dOmCmJgYREZGqr13yJAh+Oqrr/DFF1+gS5cuCAwMxOXLlwEAJiYm+Oijj7BgwQJYW1urTQ9cm+7du+Pnn3/GwYMH0b17d/Tp0wdfffWVVNfa2gwjIyPMmDED7u7ueO655+Dn5ydNGaxtr732Gj788EN8+OGH6Ny5M0aOHIljx45JPevLly+HEALdu3dHWFhYlXNHTYNMcLA2ERERkSQ7OxudOnVCRkaG2tBZItIe9oQQEREREZFOMQkhaoAiIiLUpj68/3Xo0CF9h0dERA3E8OHDa2xPtDUsmag6HI5F1ADl5eWhoKCg2m0dO3aUptUlIiKqzcWLF3H37t1qtykUCmn6XyJtYxJCREREREQ6xeFYRERERESkU0xCiIiIiIhIpxrVQL/y8nJcunQJ5ubmkMlk+g6HiKjBEUKgsLAQNjY2MDBoGr9Tse0gInp8mrYfjSoJuXTpEuzs7PQdBhFRg6dUKmFra6vvMHSCbQcRkfbUtf1oVEmIubk5gIrKW1hY6DkaIqKGp6CgAHZ2dtL1tClg20FE9Pg0bT8aVRJS2Y1uYWHBhoSI6DE0pWFJbDuIiLSnru1H0xjwS0RERERE9Uaj6gkhItJUWVkZSktL9R2GXhgbG8PQ0FDfYRARNTji/7F352FNXfn/wN8BJEgFVAQUWSKKICLEnSparLi2tta941qdolV/fqd26tLWuoyWurRjrTrq2FqLjlu1rW1n3KXVqjWO4lI3BMKioNSFoGIAc35/+PV+jewS7k3g/Xqe+zzeJTefc7iek0/OuTdCoLCwEA8fPlQ6FNlZqu9gEkJENdbdu3eRkZGBmvqbrSqVCj4+PqhTp47SoRAR2Yz8/HxkZmbi/v37SoeiCEv1HUxCiKhGevjwITIyMuDs7AwPD48adQ8E8OhbvOzsbGRkZCAwMJAjIkRE5WAymZCSkgJ7e3t4e3vD0dGxRvUfluw7mIRQjTRnTsW2U/VTUFAAIQQ8PDxQu3ZtpcNRhIeHB/R6PQoKCpiEENtFonLIz8+HyWSCr68vnJ2dlQ5HEZbqO3hjOhHVaDXpG6yn1eSyExFVRk35MdfiWKrvqLk1SEREREREiuB0LCKi/1WV0044pYWIqPqqqja+Ovcdio2E9OzZE2FhYdBqtejSpQsSEhIAADdu3EDv3r0RGBiI0NBQHD58WKkQiYgUp1KpcPfu3RL36/V6rFmzRsaIiIjIFlh7/6FYErJ161acOXMGCQkJeOeddzB27FgAwIwZMxAREYHExESsW7cOw4cPR2FhoVJhEhFZNaU7ESIisk1K9x+KTceqW7eu9O+cnBzpBp+tW7ciJSUFANC+fXt4eXnh8OHDiIqKKnIOo9EIo9EorRsMhiqNmYioqu3YsQPvvfce6tWrh759+0rbR4wYgYsXLyI/Px9+fn748ssv4enpiQkTJiAtLQ1arRZ+fn7YuXMn3n33XcTHx6OgoABubm5Yu3YtAgMDFSwVVZXSpmpU52kcRFSUrfUfit6YPmrUKPj6+uKDDz7A+vXrcfPmTZhMJnh4eEjHaDQapKWlFfv62NhYuLm5SYuvr69coRMRWdyNGzfw5ptv4vvvv8fRo0ehVqulfUuXLsWJEydw5swZREZGYt68eQCAVatWISQkBAkJCdi5cycAYPr06dDpdEhISMBbb72Ft99+W5HyWNqUKVOg0WigUqlw7tw5aTun8RJRTWeL/YeiN6Z//fXXAID169fj3XffRVxcXJHHfpX2S8YzZ87E1KlTpXWDwcBEhIhs1rFjx9CmTRsEBQUBAGJiYjB9+nQAwMaNGxEXFwej0Yi8vDw0bNiwxPPs2bMHn3/+OXJzc2EymarNKPGgQYMwbdo0REZGmm1/PI13165d0Ol0GDRoEJKSkuDgwGevEFHNYIv9h1W00KNHj8aECROk9ezsbGk0JDU1FX5+fsW+Tq1Wm2V6RES2rKQvXRISErB8+XIcOXIEHh4e2Llzp/RN1tPS0tIwZcoUHD9+HAEBAThz5gxefPHFqgxbNl27di12e0Wm8QKcyktE1Y8t9h+KJCEGgwF3796Ft7c3AODbb7+Fu7s76tevj8GDB2PFihWYM2cOdDodsrKyinzrRVRVOL+alPT8889j3LhxuHz5Mpo3b461a9cCAG7fvg1XV1fUr18f+fn5WL16tfQaV1dX5OTkSOs5OTlwdHREw4YNIYTA8uXLZS+HnCo6jRd4NJV37ty5coSnKP4COlHNYYv9hyJJSE5ODgYOHIi8vDzY2dnBw8MDP/74I1QqFRYuXIiRI0ciMDAQjo6OiIuL45A6EclC6Q9nnp6eWLNmDfr16wd3d3cMGjQIANCtWzds2LABwcHB8PHxQadOnbB7924AQFhYGIKCghAaGoqAgADs3LkTgwcPRsuWLeHn54cePXooWSRZVGQaL8CpvERkeew/Kk4lymqtbYjBYICbmxtycnLg6uqqdDhkxZ6lsVC6gSHLevDgAVJSUtCkSRM4OTkpHY4iiqsDW2hHNRoNfvzxR4SGhgIAnnvuOej1emk0pEOHDli0aFGJ07GeZgtlLokl2zKOnBCVjX1HyXVQ0baUQwykGEtOfWLnSVRzcRovEZHtUfQRvUREROU1adIk+Pj4ICMjA9HR0WjWrBkAYOHChThy5AgCAwMxZswYTuMlIrIBbKWJqEarRjNSK8zWyr5ixQqsWLGiyHYvLy/s2bNHgYiIqKYymUxKh6AYS/UdTEKIqEaqVasWVCqV9Ejwp29uru6EEMjOzoZKpUKtWrWUDoeIyCY4OjrCzs4O165dg4eHBxwdHWtU/2HJvoNJCBHVSPb29tLUHr1er3Q4ilCpVPDx8YG9vb3SoRAVi/f7kbWxs7NDkyZNkJmZiWvXrikdjiIs1XcwCSGiGqtOnToIDAxEQUGB0qEoolatWkxAiIgqyNHREX5+figsLMTDhw+VDkd2luo7mIQQUY1mb2/PD+JERFQhj6cjcTrrs2MSQlXOksPmHIInIpIXp0QRUVXgI3qJiIiIiEhWTEKIiIiIiEhWTEKIyOrt2LEDbdu2hVarRYsWLdC9e3fpGe0ajQbnzp1TOMKq8dtvv0Gr1aJ58+bo3r07MjMzSz0+OzsbXl5eGDRokNn2s2fPIioqCi1atEBQUBB27NhRlWETEVmFmtp3DBo0CN7e3lCpVLh7926Jx+l0OnTq1AnOzs5F+g2TyYS//vWvCA0NRXBwMMaNG4f8/HyLxsl7QojIqmVlZWHChAnQ6XTw9/cHAJw8ebLaP5ddCIHhw4dj7dq1iIqKwpIlSzB16lRs2rSpxNdMnDgRffv2RW5urrTt/v376N+/P9avX4/IyEgUFhbi9u3bchSBrBTv5aCaoKb2HQAwYcIErFy5El5eXqUe16hRIyxduhSnTp3C3r17zfZ98cUXOHPmDE6ePIlatWrhz3/+Mz777DO8++67FouTIyFEZNUyMzPh4OAAd3d3aVubNm2K7UiWLVuGyMhIZGdnIysrC0OGDEGHDh0QFhaGDz/8EACwe/du9OrVCwBw584d2Nvb45///CeAR43uuHHjAABRUVGYPn06unTpgqZNm2LChAnS++Tm5uLNN9+Uzj1hwgTpMb/z589HixYtoNVqodVqkZqairy8PAwdOhQhISEIDw9Hz549yyz3iRMnoFarERUVBQAYP348vvvuuxIfJ7xx40Z4eXnhhRdeMNv+r3/9C88//zwiIyMBAA4ODvDw8Cjz/YmIbFlN7TsAIDo6Gp6enmUe5+Pjgw4dOkCtVhfZd/r0aURHR0s/xti3b1/ExcWV6/3Li0kIEVm18PBwPP/88/Dz88Nrr72GxYsX4+rVq2bHmEwmvP322/j555+xd+9eeHh4YPTo0Zg8eTKOHz+OkydP4vjx4/j222/RtWtXHD9+HEajEQcPHkTHjh2xf/9+AMC+ffsQHR0tnTcpKQnx8fE4d+4cdu/ejaNHjwIA3nnnHek8p0+fRmFhIZYvX47bt29jyZIlOHnyJBISEnDkyBF4eXlh165duH37Ns6fP4/Tp09j8+bN0ntotdpif/AqLS1N+vYOAFxcXODi4lLslKxr167h008/xccff1xk3/nz5+Hk5ISXX34ZWq0Wo0aNQnZ2dgX/CkREtqWm9h2W0r59e3z//ffIzc1Ffn4+Nm/ebPEf9mUSQkRWzc7ODtu3b8eRI0fQu3dv/Prrr2jZsiWuXLkiHTN27Fg8ePAA27ZtQ+3atXHv3j0cOHAAU6ZMgVarRbt27XDlyhVcvHgRtWvXhlarxa+//op9+/Zh5syZOHnyJEwmEw4ePIju3btL5x02bBjs7e2l1yQlJQEAvvvuOyxevBharRatW7fGoUOHkJiYCFdXVwQGBmLEiBFYvXo1bt26BScnJ4SHh+PixYuYOHEitmzZYvZc+YSEBHh7exdb9qe/sRNCFHvcm2++iUWLFqFOnTpF9hUUFGD37t1YvXo1Tp06BV9fX0yaNKn8fwAiIhtUk/sOSxg1ahR69eqFrl274sUXX0TLli0t/psovCeEiGxCcHAwgoODMX78ePTu3Rs7d+7E1KlTATwa/t67dy9u3LiBhg0bwmQyQaVSQafTFdtoRkdHY9++fTh06BAWLlyIli1bIi4uDl5eXmZD2E5OTtK/7e3tUVhYCOBRMvDdd98hICCgyLmPHTuGI0eOID4+HhEREdi0aRO6dOmC8+fP48CBA9i3bx+mTZuGhIQE1KtXr8Ty+vn5mX3rlJubi9zcXDRq1KjIsUePHpWmAty9exd5eXno1asXdu/eDX9/f3Tr1g2NGzcGAAwfPhx9+/YtraqJiKqNmtZ3WIpKpcKHH34oTUfbvHkzQkJCLPoeHAkhIqt29epV/Prrr9L67du3kZKSgqZNm0rbxowZg/fffx8vvvgiUlNT4eLigi5duphNT7p27RoyMjIAPOpI/vWvf6FevXqoU6cOoqOjMXv2bLPh9NK88sor+Pjjj6WO5fbt27hy5Qpyc3Nx/fp1dOnSBbNmzUJkZCROnTqFjIwMqFQqvPLKK1iyZAmEEEhPTy/1Pdq2bYsHDx4gPj4eALB69Wr079+/2I7x1q1b0Ov10Ov1WLJkCfr06YPdu3cDAIYMGQKdTgeDwQAA2LVrF8LDw8tVTiIiW1VT+w5LefDgAe7cuQMA+OOPP/Dxxx9j2rRpFn0PJiFEZNUKCwsxb948NG/eHFqtFl26dMHo0aPx6quvmh03ZMgQLF68GD179sTly5exceNGXLhwAa1atUKrVq0wcOBA3Lx5EwDQrl075OTkSMPnPXr0QGpqark7kqVLl8LBwQFarRZhYWGIjo6GXq9HTk4OBgwYgFatWiEsLAwFBQUYPXo0zp49i06dOiEsLAxt2rTByJEjERYWBqDkeb12dnbYsGED/ud//gfNmzfHTz/9hE8++UTa37dvX5w4caLMWP38/DBz5kw8//zzCA8Px759+7BixYpylZOIyFbV1L4DeJTs+Pj4AACCgoKkB5wA5n1HUlISfHx8MHXqVPz73/+Gj48PVq5cCQDIyclBREQEWrZsicjISEyYMAH9+vUrZ+2Xj0qUNMnYBhkMBri5uSEnJweurq5Kh1NtlfR4x4put+R7VPV5lH5vIrnUxHbUlsusZHsix3uzHSWyHRVtSzkSQkREREREsmISQkRE1cLu3bvRtm1btG7dGqGhoVi/fr3SIRERUQn4dCyiSuK0ACLlCSHwpz/9CQcPHkRYWBj0ej2Cg4MxYMAAuLi4KB0eERE9hUkIERFVG4+f5mIwGODu7l7sLwEbjUYYjUZp/fGTw4iISD5MQoiIyOapVCps3boVAwYMwHPPPYfbt29jx44dcHR0LHJsbGws5s6dq0CURET0GO8JISIim1dYWIjY2Fh8//33SE1Nxf79+zF69GjcunWryLEzZ85ETk6OtMj13H0iIvo/HAkhIiKbl5CQgGvXrqFz584AgPbt28Pb2xunT59Gt27dzI5Vq9XFTtOiiuHjc4moMjgSQkRENs/X1xcZGRm4dOkSAODKlStISkpC8+bNFY6MiIiKw5EQIiKyeV5eXli9ejUGDRoEOzs7CCGwcuVKNG7cWOnQiIioGExCyCpxOJ+IKur111/H66+/rnQYRERUDpyORUREREREsmISQkREREREsmISQkREREREsuI9IURERFSt8XHCRNaHIyFERERERCQrJiFERERERCQrRaZjPXjwAMOGDcP58+fh7OyMhg0bYtWqVdBoNLhx4wZGjRqFpKQkqNVqrFq1CpGRkUqESdWAJYfaOWxPREREZBmKjYTExMTg0qVLSEhIwMsvv4yYmBgAwIwZMxAREYHExESsW7cOw4cPR2FhoVJhEhERERGRhSmShDg5OaFv375QqVQAgIiICCQnJwMAtm7dikmTJgEA2rdvDy8vLxw+fLjY8xiNRhgMBrOFiIiIiIism1XcE7Js2TL069cPN2/ehMlkgoeHh7RPo9EgLS2t2NfFxsbCzc1NWnx9feUKmYiIiIiInpHiSchHH32ExMRELFiwAACk0ZHHhBAlvnbmzJnIycmRlvT09CqNlYiIiIiIKk/R3wlZsmQJduzYgX379sHZ2RnOzs4AgOzsbGk0JDU1FX5+fsW+Xq1WQ61WyxYvERERERFVnmIjIZ9++ik2bdqEvXv3om7dutL2wYMHY8WKFQAAnU6HrKwsPh2LiIiIiKgaUWQkJCMjA++88w4CAgLQrVs3AI9GNX777TcsXLgQI0eORGBgIBwdHREXFwcHB/6wOxER1VzV5RHh/OVyInpMkU/3Pj4+Jd7r4eXlhT179sgcERERERERyUXxG9OJiIiIiKhmYRJCRETVgtFoxOTJkxEYGIiWLVtixIgRSodEREQl4M0WZDGc01s+nBNNVDVmzJgBOzs7XL58GSqVCpmZmUqHVCOxLSOi8mASQkRENu/evXtYt24dMjIypN+batSoUbHHGo1GGI1Gad1gMMgSIxER/R9OxyIiIpuXlJQEd3d3zJ8/H+3atUOXLl2wf//+Yo+NjY2Fm5ubtPj6+socLRERcSSEiIhsXkFBAZKTkxESEoKPP/4Yp0+fRnR0NM6fPy/9+O1jM2fOxNSpU6V1g8HARERhlprCxalgRLaDIyFERGTz/P39YWdnh+HDhwMAwsPD0aRJE/z+++9FjlWr1XB1dTVbiIhIXkxCiIjI5jVo0ADdu3fH7t27AQCpqalISUlBUFCQwpEREVFxOB2LiIiqhVWrVmHs2LGYPn067O3tsWbNmhJvTiciImUxCSEiomohICAA8fHxSodBRETlwOlYREREREQkKyYhREREREQkKyYhREREREQkKyYhREREREQkKyYhREREREQkKyYhREREREQkKz6il4iISGZz5igdgW1j/RHZPo6EEBERERGRrJiEEBERERGRrDgdi8iGlTQlgVMViIiIyJpxJISIiIiIiGTFJISIiIiIiGTFJISIiIiIiGTFJISIiIiIiGTFJISIiIiIiGTFJISIiIiIiGTFJISIiIiIiGTFJISIiKqVuXPnQqVS4dy5c0qHQkREJWASQkRE1cbJkydx7Ngx+Pn5KR0KERGVgkkIERFVC0ajEZMmTcLKlSuhUqlKPc5gMJgtREQkLwelAyCi0s2Zo3QERLbhww8/xIgRI9CkSZNSj4uNjcXcuXNlioqIiIrDkRAiIrJ5R48ehU6nw8SJE8s8dubMmcjJyZGW9PR0GSIkIqInMQkhIiKb9/PPP+PixYto0qQJNBoNMjIy0KtXL/znP/8pcqxarYarq6vZQkRE8uJ0LCIisnkzZszAjBkzpHWNRoMff/wRoaGhCkZFtqyiU2FLOr6i24lqCo6EEBERERGRrBRJQqZMmQKNRlPkOe43btxA7969ERgYiNDQUBw+fFiJ8IiIyMbp9XqOghARWTFFkpBBgwbh8OHD8Pf3N9s+Y8YMREREIDExEevWrcPw4cNRWFioRIhERERERFRFFLknpGvXrsVu37p1K1JSUgAA7du3h5eXFw4fPoyoqKhijzcajTAajdI6n/VeOs5LJSIiIiJrYDX3hNy8eRMmkwkeHh7SNo1Gg7S0tBJfExsbCzc3N2nx9fWVI1QiIiIiIqoEq0lCABT5hVshRKnH81nvRERERES2x2oe0evu7g4AyM7OlkZDUlNT4efnV+Jr1Go11Gq1LPHVRJymZbs49Y6IiIismVWNhAwePBgrVqwAAOh0OmRlZSEyMlLhqIiIiIiIyJIUSUImTZoEHx8fZGRkIDo6Gs2aNQMALFy4EEeOHEFgYCDGjBmDuLg4ODhYzWANERERERFZgCKf8FesWCGNeDzJy8sLe/bsUSAiIiIiIiKSC4cZiKwE79cgIiKimsKq7gkhIiIiIqLqj0kIERERERHJitOxiNOAiIiIiEhWHAkhIiIiIiJZMQkhIiIiIiJZMQkhIiIiIiJZMQkhIiIiIiJZMQkhIiIiIiJZMQkhIiKb9+DBA/Tv3x/NmzeHVqtF7969odfrlQ6LiIhKwEf02qiSHqvLx+0SUU0VExODPn36QKVSYfny5YiJicGePXuUDotqCDn6X/b9VJ1wJISIiGyek5MT+vbtC5VKBQCIiIhAcnJysccajUYYDAazhYiI5MUkhIiIqp1ly5ahX79+xe6LjY2Fm5ubtPj6+socHRERMQkhIqJq5aOPPkJiYiIWLFhQ7P6ZM2ciJydHWtLT02WOkIiIeE8IEZWI84/J1ixZsgQ7duzAvn374OzsXOwxarUaarVa5siIiOhJTEKIiKha+PTTT7Fp0ybs27cPdevWVTocIiIqBZMQIiKyeRkZGXjnnXcQEBCAbt26AXg04vHbb78pHBkRERWHSQgRcXoV2TwfHx8IIZQOg6jc+Ehfqul4YzoREREREcmKSQgREREREcmKSQgREREREcmK94QQERFRjcR7I8xV9B6S0uqPdUtl4UgIERERERHJikkIERERERHJitOxiIiIqginpJAceJ2RLeJICBERERERyYpJCBERERERyYpJCBERERERyYr3hBDVIJw3TEREFe0LLNl3PMvjfquakvVRk3EkhIiIiIiIZMUkhIiIiIiIZMXpWFbCUsOTHCIkOTzLdWbJX+Ilsja8XonMWerzC/9vVV8cCSEiIiIiIlkxCSEiIiIiIlkxCSEiIiIiIllZ5T0hiYmJGD16NP744w/UrVsXX331FUJCQqr8feWYj8h7PKimstS1LMf/Cf6/s01K9R1EJD9L3puoJKXuhbGGe3CsciRk/PjxiImJweXLlzFt2jSMGzdO6ZCIiMjKse8gIrIdVjcScuPGDZw8eRJ79uwBAAwcOBCTJ0+GXq+HRqMxO9ZoNMJoNErrOTk5AACDwfBM7/3Eqcw84+kq9B5EZK6k/3dy/B+y5P95W/O4/RRCKBxJxSjZdzw65zO/lIhKYcm+wFLnkuNzYVX3Q1XxvhXuP4SVOXHihGjRooXZtvbt24uff/65yLGzZ88WALhw4cKFi4WX9PR0uZp9i2DfwYULFy7WsZS3/7C6kRAAUKlUZuuihIxq5syZmDp1qrRuMplw69YtuLu7FzmHEgwGA3x9fZGeng5XV1elw7Go6lw2oHqXrzqXDWD5KksIgdzcXHh7e1v83FWtuvQd5WHL1zljVwZjV44tx1+R2Cvaf1hdEuLr64uMjAwUFhbCwcEBQgikp6fDz8+vyLFqtRpqtdpsW926dWWKtPxcXV1t7qIrr+pcNqB6l686lw1g+SrDzc2tSs5blapj31EetnydM3ZlMHbl2HL85Y29Iv2H1d2Y7unpidatW2PDhg0AgO3bt0Oj0RSZ00tERPQY+w4iIttidSMhALB69WqMGTMGH330EVxdXbF+/XqlQyIiIivHvoOIyHZYZRISFBSEo0ePKh1GpanVasyePbvIsH91UJ3LBlTv8lXnsgEsX01WXfqO8rDl64CxK4OxK8eW46/K2FWipDv3iIiIiIiIqoDV3RNCRERERETVG5MQIiIiIiKSFZMQIiIiIiKSFZMQIiIiIiKSFZOQZ5CYmIhOnTqhefPm6NChA86fP1/scV988QUCAwPRtGlTxMTEoLCwUNqXlpaGfv36ISgoCMHBwfj888/lCr9UlijbkiVLEBoaCq1Wi4iICOh0OrnCL1N5yqfX6xEVFQU3Nze0a9euyP4ff/wRwcHBaNasGQYOHIi7d+/KEXq5VLZ8Z8+eRdeuXREcHIxWrVohJiYGRqNRrvBLZYm/HfDoF127d++OBg0aVHXIFWKJ8llru0LlV9k2WK/Xw8HBAVqtVlqSkpKsJnZrbV8rG7u11/uBAwfQsWNHhISEIDQ0FO+//z6efC6Rkv1aZeO39ro/evSoFFfLli0xfvx4s37Vmq/50mK3SL0LqrBu3bqJdevWCSGE2LZtm4iIiChyTHJysmjUqJHIysoSJpNJ9OvXT6xatUoIIYTJZBJt2rQRW7duldYzMzNli780lS1bQkKC8PPzE7m5uUIIIeLi4kT79u1li78s5SnfzZs3xaFDh8SPP/4o2rZta7YvNzdXeHp6igsXLgghhJg0aZKYMWNGlcddXpUt3+XLl8Xp06eFEEIUFhaKIUOGiAULFlR53OVR2bI9tmzZMjF27Fjh7u5eleFWWGXLZ83tCpVfZdvglJQUxa5tW25fKxu7tdf7yZMnRVJSkhBCiLy8PNG5c2exceNGIYTy/Vpl47f2ur93757Iz88XQgjx8OFD8dprr4nPPvtMCGH913xpsVui3pmEVND169eFm5ubKCgoEEI86ui9vLxESkqK2XGLFi0SEydOlNZ/+ukn8cILLwghhNi7d6/o3LmzXCGXmyXKlpCQIHWOQgjx+eefi9dee02W+MtS3vI9dvDgwSIdzdatW0Xfvn2l9d9//134+/tXVcgVYonyPW3x4sVi3Lhxlg61wixVtsuXL4tOnTqJy5cvW1USYonyWWu7QuVniTZYqQ9ktty+WiJ2W6n3xyZNmiT+9re/CSGU7dcsEb8t1X1eXp7o3bu3+Pzzz4UQtnPNC1E0dkvUO6djVVB6ejq8vb3h4PDodx5VKhX8/PyQlpZmdlxaWhr8/f2ldY1GIx1z/vx5eHh4YNiwYWjdujVee+01JCcny1eIEliibOHh4Zg6dSqaNGkCHx8f/P3vf7eaKSHlLV9piiv71atXYTKZLB5vRVmifE+6d+8e1q5di379+lkyzGdiibKZTCa8+eabWLFiBWrVqlVVoT4TS5TPWtsVKj9LtMEAYDAY0L59e7Rp0wbz5s3Dw4cPrSb20ijVvlqq7bSVes/KysI333yDvn37AlC2X7NE/ID1171er4dWq0WDBg3g6uqKmJgYALZxzZcUO1D5emcS8gxUKpXZuijh9x6fPO7JYwoKCrBv3z7MmjULp06dQp8+fTBs2LCqCbaCKlu21NRU7Ny5E0lJScjIyMDbb7+N4cOHV02wz6C85avIOayJJcoHPLpGhw4dip49e+LVV1+1RGiVVtmyLVmyBF27doVWq7VgVJZT2fJZc7tC5VfZNrhRo0bIyMiATqfDvn37cOjQIXzyySdVE2wpMT0d17OeQy6Vjd1W6t1gMKBfv36YNm0a2rRpU+I55FTZ+G2h7jUaDRISEpCVlQWj0YgdO3aUeA65VDZ2S9Q7k5AK8vX1RUZGhnQToBAC6enp8PPzMzvOz88Per1eWk9NTZWO8ff3R+vWrdGyZUsAwIgRI/Df//5Xlsy9NJYo27Zt2xAaGopGjRoBAN544w388ssvipcNKH/5SvN02fV6PRo3bgw7O+X/K1mifMCjD7NDhgxBo0aN8Nlnn1VFqBVmibL98ssv+Oqrr6DRaBAZGYnbt29Do9Hg9u3bVRV2uVmifNbarlD5WaINVqvV8PT0BADUr18fY8eOxaFDh6wm9tIo1b5aInZbqPfc3Fz07t0br7zyCqZOnSptV7Jfs0T8tlD3j9WpUwfDhg3Dxo0bAdjWNf907Jaod+U/OdkYT09PtG7dGhs2bAAAbN++HRqNBhqNxuy4gQMH4ttvv8X169chhMCqVaukbyX79OmDq1ev4urVqwCAXbt2ITQ0FPb29rKW5WmWKFtAQAAOHz4sPd3hhx9+QIsWLRQvG1D+8pWmd+/e0Ol0uHjxIgBg5cqVVvNtsyXKV1hYiGHDhqF+/fpYs2aN1Yz6WKJsP/74I9LS0qDX63H48GHUq1cPer0e9erVq6Koy88S5bPWdoXKzxJt8I0bN1BQUAAA0reWrVu3tprYS6NU+2qJ2K293u/evYvevXujV69emDVrltk+Jfs1S8Rv7XWflJQkxZefn48dO3YgLCwMgPVf86XFbpF6r9QdJTXUxYsXRUREhAgMDBRt27YV586dE0IIMW7cOPH9999Lx61Zs0Y0bdpUNGnSRIwbN056woAQQuzatUuEh4eLsLAw0bVrV+kcSqts2Uwmk5gxY4YICgoSYWFhonPnzuLkyZOKlKU45SnfgwcPROPGjUWDBg1ErVq1ROPGjc2eVvH999+LoKAg0bRpU9G/f3+Rk5OjSFmKU9nybdiwQQAQYWFhIjw8XISHh5vdAKskS/ztHlPyaSolsUT5rLVdofKrbBu8fft20bJlSxEWFiZCQkLE5MmTxYMHD6wmdmttXysbu7XX+/z584WDg4PUroeHh4v58+dL51CyX6ts/NZe92vXri0SX15ennQOa77mS4vdEvWuEuIZJ40TERERERE9A07HIiIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJISIiIiIiWTEJIaoCX331FXx8fJQOg4iIqrH4+HioVCoUFhYqHQpRhamEEELpIIiqm7y8PNy9exceHh4AgBEjRsDBwQFfffWVsoEREVG1kZ+fj1u3bqFhw4blOr6wsBC1atXCwYMHERUVVbXBEZXBQekAiKqj2rVro3bt2kqHQURE1Zijo2O5ExAia8PpWGTVCgsL8eGHH8LPzw9OTk5o0aIFfvjhBwDA119/jWbNmkGtVqNVq1b4z3/+I73u8RD1/v37ERISAhcXF/Tv3x+3b98u17kvXryIvn37okGDBqhbty769u2LlJQU6XUeHh7YunWrWaxLlixB69atAZhPx5ozZw42btyI9evXQ6VSQaVS4erVq3BwcMD58+fNzjFy5EiMGTOmzHrRaDRYvHgxBgwYAGdnZ4SEhECn0+Hs2bPo2LEj6tSpg5deegm3bt2SXvPw4UPMmjULPj4+cHFxQVRUFM6cOSPtP3LkCLp164a6devCw8MDr7/+Ov744w9p/+MyffPNN2jSpAnq1q2LsWPHwmg0lhkvEVF5lNYuA9bd7gPAvn370K5dO9SuXRvNmzfHihUrSi2vRqPBwoUL0a9fP9SuXRvBwcGIj483O6Y8ZX48HWvOnDmIjIzE8uXL0ahRIzRo0ADTpk3D40kvzZo1AwB069YNKpVK6m82bdqE4OBgODk5oWHDhoiJiSk17iffe8+ePQgJCYGzszOGDBmCBw8eYPny5fD29oanpycWLVpk9rrk5GT069cPderUgbe3NyZPnoz79+9L+2NjY9GiRQs4OzsjMDAQy5YtM3t9VFQUpk2bhvHjx8PFxQUajQabN28uM16yQoLIir333nuiYcOGYvv27eLKlSvi3//+t/jPf/4jfv31V2Fvby8+++wzcfHiRTFr1izh6OgoUlJShBBCHDx4UAAQUVFR4rfffhM6nU4EBASIqVOnlnluIYTQ6XTiiy++EBcuXBBnz54Vr776qujQoYP02piYGDFgwACzWNu3by9iY2OFEEKsW7dONG7cWAghRG5urhg4cKAYMmSIyMzMFJmZmUIIIXr16iVmzJghvf7u3bviueeeE/v37y+zXvz9/YWnp6eIi4sTly5dEv379xdBQUGiW7duIj4+Xpw6dUo0a9bMrLyzZs0Sbdq0Eb/88otITEwU7733nvD09BQ5OTlCCCF2794ttmzZIhITE4VOpxOdO3cWgwcPll6/bt064eTkJF5++WVx5swZceDAAVG/fn2xbNmysv+QRETlUFq7bO3t/sWLF4WLi4tYu3atSEpKEj/88IPw8PAQmzdvLrG8/v7+om7duuIf//iHuHDhgpg8ebJwc3MTd+7cqVCZCwoKhBBCzJ49W7i4uIhRo0aJ8+fPi2+//VbUqlVL7Ny5UwghRGZmpgAgtm/fLjIzM8WdO3fEtWvXhFqtFps3bxZ6vV7odDqxatWqMv9WT9a3TqcThw4dEu7u7qJHjx5i7Nix4sKFC2LdunUCgDh9+rQQQgij0SiaNWsm3n77bXHx4kVx/Phx0aFDBzFhwgTpvJ988ok4dOiQSE5OFlu2bBHPPfec+Omnn6T9L7zwgnB1dRWffvqpSExMFLNnzxZOTk7i+vXrZcZM1oVJCFmt+/fvC7VaLbZt21Zk39ChQ80+IAshRMeOHcVf//pXIcT/NY6//fabtP+jjz4Sbdu2LfPcxXnccKempgohhNi/f7+oXbu2yM3NFUIIkZycLFQqlUhOThZCmCchQggxfPhwMXr0aLNzbtq0Sfj6+oqHDx8KIYRYv3692Xpp/P39xVtvvSWtHz16VAAwK09sbKxo06aNEEKIvLw8Ubt2bXH27Fmz8wQGBoq4uLhi3+Po0aPCwcFBFBYWSmVSqVQiKytLOiYmJkYMHDiwzHiJiMpSVrts7e3+G2+8Id555x2zcyxYsEB07969xPfw9/cXQ4cOldYLCwuFn5+f+PzzzytU5ieTkHr16om8vDzp+J49e0pxFRQUCADi4MGD0v4TJ04IV1dXqVzlVVx9jx8/XtSvX188ePBA2hYUFCR9WbV+/Xrp7/HYr7/+KhwdHaW+5mnjx48Xb7zxhrT+wgsviD59+kjrBQUFwtnZWfzwww8Vip+Ux+lYZLWuXLkCo9FY7M1zly5dQkREhNm2559/HpcuXTLb1qpVK+nfDRs2xI0bN8o8NwDk5ORg0qRJCAwMhKurqzSEnZ6eDuDRcLCbm5s0jL9lyxa0b98eTZo0KXf5+vfvj9zcXGnoPS4uDiNGjICdXfn+Wz5ZNi8vLwBAy5YtzbZlZ2cDAJKSkpCXl4eIiAjUqVNHWpKSkpCcnAwAyMjIwMiRIxEQEAAXFxd0794dhYWFyMrKks7p4eEhvRdgXqdERJVRVrts7e3+2bNnsXz5crM2dt68eVIbW5IOHTpI/7a3t0fbtm2lMpW3zE8KDAyEk5NTsXVQnPDwcISFhSEgIABjxozB1q1bkZ+fX2rMT3q6L3o8dezJbY/7orNnz+L06dNmddSjRw/k5+fj6tWrAICffvoJkZGR8PLyQp06dfDll19Kf4Pi3tPBwQENGjRgX2SDeGM6WS1RyoPbStv3pFq1akn/VqlUMJlM5Xr9O++8g2PHjmHp0qVo0qQJCgsLER4ejoKCAgCAnZ0dBg0ahC1btuD111/Hli1bMGrUqHLF9JiTkxOGDh2Kr7/+GkFBQThw4AA+//zzcr/+6bIVt+1xee/evQvg0RzeunXrmp2nfv36AIAxY8YgPz8f//znP9G4cWOkpKSgb9++UpmfPv/T70FEVBlltcvW3u7fvXsXU6dOxdixY83O6+BQ+ketx+13ccpb5icV104/fPiwxOMdHBwQHx+PX375Bbt27cK0adOwaNEiHDlyBI6OjhV6P5VKVWo/cffuXXTt2hWrV68ucp5GjRohOTkZAwYMwPTp07F06VK4ublh4cKFuHLlSpllZF9ke5iEkNUKDAyEWq1GfHw8Bg0aZLYvODgYx44dM9t29OhRdO3atdLnBoBjx47hz3/+M1566SUAwKFDh4ocM2zYMHTv3h0nTpzA6dOnMXjw4BLfr1atWsU+x/2NN95AdHQ0NBoN2rVrh+Dg4HLFX1EtWrSAo6MjMjMz0a5du2KPOXbsGDZs2IDu3bsDAHQ6XZXEQkRUnLLaZWtv98PDw3Hp0iVpBKW8jh8/Lv3bZDLh5MmTePHFFwFUvsxPs7e3h52dXZGkxN7eHt26dUO3bt3wzjvvwMvLCwkJCWajNJYQHh6OnTt3wsfHx2y05rGTJ0+idu3amDdvnrTt8cMBqPphEkJWq3bt2njnnXcwZcoU2NnZoXXr1khMTITJZMKUKVPQtWtXLF++HD179sSGDRtw6tSpcj8ho7Rz9+7dG02bNsU333yDnj174tatW3j33XeLnKNTp07w9PTEG2+8gcjIyFJ/nNDf3x/ffPMN9Ho96tSpgwYNGgAAOnbsCF9fX3z00Uf4+9///mwVVQ6urq6YPHky3nrrLeTn56NNmzbIysrCDz/8gOHDh6Nly5Zo2rQp4uLiEBoaiitXruCjjz6qsniIiJ5WVrts7e3+u+++i06dOuGDDz7An/70JwghoNPpcP/+fUycOLHEuHbv3o01a9bghRdewMqVK3H79m2MGDECACpd5qepVCr4+vriwIEDaNWqFZydnfH7778jPj4ePXr0gLu7O7Zt2wa1Wg1/f/9neo/SDB8+HAsXLsTQoUPxwQcfoF69erhw4QJ+/vlnLFmyBE2bNoXBYMBXX32FyMhIbN68GTqdDm3atLF4LKQ83hNCVm3u3Ll44403MHnyZLRo0QJ/+ctf8PDhQ3Tq1Alffvklli5ditDQUHz77bf47rvvoNFoKn1uAPjkk08ghEDbtm0RExODuXPnFnm9SqXCkCFDcO7cOQwdOrTU93rzzTdRv359hISESD9g+NioUaOgUqkwbNiwcsf+LBYvXoyJEyfir3/9K4KCgjBkyBCkp6fD3d0dALB27VpcuXIFoaGhmDVrFubPn1+l8RARPa20dtna2/22bdti7969+Pnnn9G2bVtERkZi3bp1ZcY3bdo0fPvttwgPD8euXbvw7bffStNmLVHmpy1atAgbN25Eo0aNMHnyZLi6umL//v3o2bMnWrRogU2bNmHHjh1m9/9ZiouLC+Lj4+Ho6IgePXogPDwcH3zwARo1agQAaN26NRYsWIBp06ahTZs20Ov1GD9+vMXjIOvAX0wnUtiUKVOQkZGBHTt2KB0KERHJSKPR4IMPPsCf//xnpUMhkh2nYxEp5O7duzh9+jTWr1+P7du3Kx0OERERkWw4HYtIIZMnT0Z0dDRGjRqF6Ohos30tW7Y0e4ThkwsREVFVO3ToUIn90IQJE5QOj6oBTsciskKpqalmj8Z9UkWfvEJERFRReXl50m93PM3V1RWenp4yR0TVDZMQIiIiIiKSFadjERERERGRrKrVjekmkwnXrl2Di4tLqb9ASkRExRNCIDc3F97e3rCzqxnfU7HvICKqvIr2H9UqCbl27Rp8fX2VDoOIyOalp6eX+gOc1Qn7DiIiyylv/1GtkhAXFxcAjwrv6uqqcDRERLbHYDDA19dXak9rAvYdRESVV9H+o1olIY+H0V1dXdmREBFVQk2alsS+g4jIcsrbf9SMCb9ERERERGQ1mIQQEREREZGsqtV0LCKiinr48GGJPwxZ3dWqVQv29vZKh0FEZHOEECgsLMTDhw+VDkV2luo7mIQQUY119+5dZGRkoKb+ZqtKpYKPjw/q1KmjdChERDYjPz8fmZmZuH//vtKhKMJSfQeTkCoyZ07FthORvB4+fIiMjAw4OzvDw8OjRt2IDTz6Fi87OxsZGRkIDAzkiIiNKq1PYX9DZHkmkwkpKSmwt7eHt7c3HB0da1T/Ycm+g0kIEdVIBQUFEELAw8MDtWvXVjocRXh4eECv16OgoIBJCBFROeTn58NkMsHX1xfOzs5Kh6MIS/UdvDGdiGq0mvQN1tNqctmJiCqjPL8IXl1Zqu/gSAgR0f+qyukrnBpDRFR9VVUbX537DkXSuClTpkCj0UClUuHcuXPS9hs3bqB3794IDAxEaGgoDh8+rER4RERWQ6VS4e7duyXu1+v1WLNmjYwRERGRLbD2/kORJGTQoEE4fPgw/P39zbbPmDEDERERSExMxLp16zB8+HAUFhYqESIRkU1QuhMhIiLbpHT/och0rK5duxa7fevWrUhJSQEAtG/fHl5eXjh8+DCioqKKPd5oNMJoNErrBoPB4rESEclpx44deO+991CvXj307dtX2j5ixAhcvHgR+fn58PPzw5dffglPT09MmDABaWlp0Gq18PPzw86dO/Huu+8iPj4eBQUFcHNzw9q1axEYGKhgqYiIqKrZWv9hNXfV3Lx5EyaTCR4eHtI2jUaDtLS0El8TGxsLNzc3afH19ZUjVCKiKnHjxg28+eab+P7773H06FGo1Wpp39KlS3HixAmcOXMGkZGRmDdvHgBg1apVCAkJQUJCAnbu3AkAmD59OnQ6HRISEvDWW2/h7bffVqQ8REQkD1vsP6zqxvSn77Yv6wfEZs6cialTp0rrBoNB1kSkOt8sRETyO3bsGNq0aYOgoCAAQExMDKZPnw4A2LhxI+Li4mA0GpGXl4eGDRuWeJ49e/bg888/R25uLkwmE0eJiYiqOVvsP6wmCXF3dwcAZGdnS6Mhqamp8PPzK/E1arXaLNMjIrJlJX3xkpCQgOXLl+PIkSPw8PDAzp07pW+ynpaWloYpU6bg+PHjCAgIwJkzZ/Diiy9WZdhERKQwW+w/rGY6FgAMHjwYK1asAADodDpkZWUhMjJS4aiIiOTx/PPP49SpU7h8+TIAYO3atQCA27dvw9XVFfXr10d+fj5Wr14tvcbV1RU5OTnSek5ODhwdHdGwYUMIIbB8+XJ5C0FERLKzxf5DkZGQSZMm4fvvv0dWVhaio6NRp04dXLlyBQsXLsTIkSMRGBgIR0dHxMXFwcHBagZrLKKkKVyc2kWkPKX/H3p6emLNmjXo168f3N3dMWjQIABAt27dsGHDBgQHB8PHxwedOnXC7t27AQBhYWEICgpCaGgoAgICsHPnTgwePBgtW7aEn58fevTooWSRLOrBgwcYNmwYzp8/D2dnZzRs2BCrVq2CRqPBjRs3MGrUKCQlJUGtVmPVqlX8EouIZMP+o+JUoqwbL2yIwWCAm5sbcnJy4OrqWuXvZ8kLTumLl6imefDgAVJSUtCkSRM4OTkpHY4iiqsDudvRinjw4AEOHDiAPn36QKVSYfny5di5cyf27NmDsWPHws/PD3PmzIFOp8OgQYOQlJRUri+yrLnMZSmt72C/QmR57DtKroOKtqVWNR2LiIioJE5OTujbt6/0EJOIiAgkJycDePSI90mTJgEwf8R7cYxGIwwGg9lCRETyYhJCREQ2admyZejXr1+FH/HOx7sTESmPSQgR1WjVaEZqhdly2T/66CMkJiZiwYIFACr2iPeZM2ciJydHWtLT06s0ViKqfmy5/awsS5W9et31TURUTvb29gCA/Px81K5dW+FolJGfnw/g/+rCVixZsgQ7duzAvn374OzsDGdnZwDlf8Q7H+9ORM+qVq1aAID79++z76hk38EkhIhqJAcHBzg7OyM7Oxu1atWCnV3NGhg2mUzIzs6Gs7OzTT2F8NNPP8WmTZuwb98+1K1bV9r++BHvj29M5yPeiagq2Nvbo27durhx4wYAwNnZuchIbHVmyb7DdnoeIiILUqlUaNSoEVJSUpCamqp0OIqws7ODn5+fzXSgGRkZeOeddxAQEIBu3boBeDSq8dtvv9WIR7wTkXV4/IvjjxORmsZSfQdbaCKqsRwdHREYGCgNLdc0jo6ONjUC5OPjU+JcZC8vL+zZs0fmiIioJnr8JZanpycKCgqUDkd2luo7mIQQUY1mZ2dXY5/1TkREz87e3t7m7qmzJrbzFRgREREREVULHAkhIiKycvz1cyKqbjgSQkRWb8eOHWjbti20Wi1atGiB7t27w2QyAXj0o3Tnzp1TOMKqMWjQIHh7e0OlUuHu3btlHp+dnQ0vLy8MGjTIbPsXX3yBwMBANG3aFDExMSgsLKyqkImIrAb7jtL7Dp1Oh06dOsHZ2blIv/H1119Dq9VKS4MGDTBgwACLxsmRECKyallZWZgwYQJ0Oh38/f0BACdPnrSZJzpVxoQJE7By5Up4eXmV6/iJEyeib9++yM3NlbalpKRg1qxZOHXqFDw9PfHqq6/iiy++wPjx46sqbCIixbHvKLvvaNSoEZYuXYpTp05h7969ZvtGjRqFUaNGSeutWrXC8OHDLRonR0KIyKplZmbCwcEB7u7u0rY2bdoU25EsW7YMkZGRyM7ORlZWFoYMGYIOHTogLCwMH374IQBg9+7d6NWrFwDgzp07sLe3xz//+U8Aj0YMxo0bBwCIiorC9OnT0aVLFzRt2hQTJkyQ3ic3NxdvvvmmdO4JEyZIT0iZP38+WrRoIX17lJqairy8PAwdOhQhISEIDw9Hz549y1X26OhoeHp6luvYjRs3wsvLCy+88ILZ9m+++QavvfYavLy8oFKpMGHCBGzatKlc56Tqac6c4hei6oR9R9l9h4+PDzp06FDmj7ceP34c169fxyuvvFKu9y8vJiFEZNXCw8Px/PPPw8/PD6+99hoWL16Mq1evmh1jMpnw9ttv4+eff8bevXvh4eGB0aNHY/LkyTh+/DhOnjyJ48eP49tvv0XXrl1x/PhxGI1GHDx4EB07dsT+/fsBAPv27UN0dLR03qSkJMTHx+PcuXPYvXs3jh49CgB45513pPOcPn0ahYWFWL58OW7fvo0lS5bg5MmTSEhIwJEjR+Dl5YVdu3bh9u3bOH/+PE6fPo3NmzdL76HVanHt2rVK1dG1a9fw6aef4uOPPy6yLy0tTfoWEHg0BSEtLa1S70dEZO3Yd1jOF198gZEjR0q/Fm8pTEKIyKrZ2dlh+/btOHLkCHr37o1ff/0VLVu2xJUrV6Rjxo4diwcPHmDbtm2oXbs27t27hwMHDmDKlCnQarVo164drly5gosXL6J27drQarX49ddfsW/fPsycORMnT56EyWTCwYMH0b17d+m8w4YNg729vfSapKQkAMB3332HxYsXQ6vVonXr1jh06BASExPh6uqKwMBAjBgxAqtXr8atW7fg5OSE8PBwXLx4ERMnTsSWLVvMGvKEhAR4e3tXqo7efPNNLFq0CHXq1Cl2/5Pf/JX0OxtERNUJ+w7LuH//PrZs2SKN9FgS7wkhIpsQHByM4OBgjB8/Hr1798bOnTsxdepUAI+Gv/fu3YsbN26gYcOGMJlMUKlU0Ol0xX5zEx0djX379uHQoUNYuHAhWrZsibi4OHh5eZkNYT/5+yH29vbSDd1CCHz33XcICAgocu5jx47hyJEjiI+PR0REBDZt2oQuXbrg/PnzOHDgAPbt24dp06YhISEB9erVs0jdHD16VOog7t69i7y8PPTq1Qu7d++Gn58f9Hq9dGxqair8/Pws8r5ERNaOfUflfPPNN2jRogVCQkIsfm6OhBCRVbt69Sp+/fVXaf327dtISUlB06ZNpW1jxozB+++/jxdffBGpqalwcXFBly5dzKYnXbt2DRkZGQAedST/+te/UK9ePdSpUwfR0dGYPXu22XB6aV555RV8/PHHUsdy+/ZtXLlyBbm5ubh+/Tq6dOmCWbNmITIyEqdOnUJGRgZUKhVeeeUVLFmyBEIIpKenW6J6AAC3bt2CXq+HXq/HkiVL0KdPH+zevRsAMHDgQHz77be4fv06hBBYtWoVhg0bZrH3JiKyRuw7LOPLL7+sklEQwEqTkN27d6Nt27Zo3bo1QkNDsX79eqVDIiKFFBYWYt68eWjevDm0Wi26dOmC0aNH49VXXzU7bsiQIVi8eDF69uyJy5cvY+PGjbhw4QJatWqFVq1aYeDAgbh58yYAoF27dsjJyZGGz3v06IHU1NRydyRLly6Fg4MDtFotwsLCEB0dDb1ej5ycHAwYMACtWrVCWFgYCgoKMHr0aJw9exadOnVCWFgY2rRpg5EjRyIsLAxA6fN6X3nlFfj4+AAAgoKCEBUVJe3r27cvTpw4UWasAQEBmDt3Ljp37oymTZvC09OzyjoUsi68AZ1qMvYdZfcdSUlJ8PHxwdSpU/Hvf/8bPj4+WLlypXRsUlIS/vvf/2Lo0KHlKl9FqYSVTRAWQqBBgwY4ePAgwsLCoNfrERwcjOzsbLi4uJT6WoPBADc3N+Tk5MDV1bXKY7VkY86OgYisgdztqDWwhTLL0UewHyKiyqhoW2q194TcuXMHwKMCubu7F/v4MKPRCKPRKK0bDAa5wiMiIiIiomdkdUmISqXC1q1bMWDAADz33HO4ffs2duzYAUdHxyLHxsbGYu7cuRZ775K+BeK3Q0RERERElmN194QUFhYiNjYW33//PVJTU7F//36MHj0at27dKnLszJkzkZOTIy1y36xDREREREQVZ3VJSEJCAq5du4bOnTsDANq3bw9vb2+cPn26yLFqtRqurq5mCxERERERWTerS0J8fX2RkZGBS5cuAQCuXLmCpKQkNG/eXOHIiIiIiIjIEqzunhAvLy+sXr0agwYNgp2dHYQQWLlyJRo3bqx0aEREREREZAFWl4QAwOuvv47XX39d6TCIiIiIiKgKWN10LCIiIiIiqt6YhBARERERkayYhBARERERkayYhBARERERkayYhBARkU2YMmUKNBoNVCoVzp07J22PiopCQEAAtFottFot/v73vysYJRERlYdVPh2LiIjoaYMGDcK0adMQGRlZZN+yZcvw8ssvKxAVERE9CyYhRERkE7p27WqR8xiNRhiNRmndYDBY5LxERFR+nI5FREQ2791330WrVq0wdOhQJCcnl3psbGws3NzcpMXX11emKImI6DEmIUREZNPi4uJw4cIFnDlzBl26dClzWtbMmTORk5MjLenp6TJFSkREjzEJISIim/Z4JEOlUmHy5MlITk7GzZs3SzxerVbD1dXVbCEiInnxnhArMWdOxbYTERFQWFiImzdvwsvLCwCwfft2eHl5wd3dXeHIiIioNExCiIjIJkyaNAnff/89srKyEB0djTp16uD06dN46aWXYDQaYWdnhwYNGmDnzp1Kh0pERGVgEkJERDZhxYoVWLFiRZHtJ06cUCAaIiKqDCYh5cApUURERERElsMb04mIiIiISFZMQoiIiIiISFacjkVERGQlOP2XiGoKjoQQEREREZGsrDIJMRqNmDx5MgIDA9GyZUuMGDFC6ZCIiIiIiMhCrHI61owZM2BnZ4fLly9DpVIhMzNT6ZAUwx8xJCIiIqLqxuqSkHv37mHdunXIyMiASqUCADRq1KjYY41GI4xGo7RuMBhkiZGIiIiIiJ6d1U3HSkpKgru7O+bPn4927dqhS5cu2L9/f7HHxsbGws3NTVp8fX1ljpaIiIiIiCrK6pKQgoICJCcnIyQkBCdOnMDy5csxbNgwZGdnFzl25syZyMnJkZb09HQFIiYiIiIiooqwuiTE398fdnZ2GD58OAAgPDwcTZo0we+//17kWLVaDVdXV7OFiIiIiIism9UlIQ0aNED37t2xe/duAEBqaipSUlIQFBSkcGRERERERGQJVndjOgCsWrUKY8eOxfTp02Fvb481a9aUeHM6ERERERHZFqtMQgICAhAfH690GEREREREVAWsbjoWERERERFVb0xCiIiIiIhIVkxCiIiIiIhIVkxCiIiIiIhIVkxCiIiIiIhIVlb5dCwiIiKS15w5FdtORFQZHAkhIiIiIiJZMQkhIiIiIiJZcToWERHZhClTpmDnzp1ITU3F2bNnERoaCgC4ceMGRo0ahaSkJKjVaqxatQqRkZEKR1s6TnEiopqOIyFERGQTBg0ahMOHD8Pf399s+4wZMxAREYHExESsW7cOw4cPR2FhoUJREhFReXAkhIiIbELXrl2L3b5161akpKQAANq3bw8vLy8cPnwYUVFRxR5vNBphNBqldYPBYPFYiYiodExCiIjIZt28eRMmkwkeHh7SNo1Gg7S0tBJfExsbi7lz58oRHpUTn8xFVPNwOhYREdk0lUplti6EKPX4mTNnIicnR1rS09OrMjwiIioGR0JsFL81IiIC3N3dAQDZ2dnSaEhqair8/PxKfI1arYZarZYlPqo52C8TVQxHQoiIyKYNHjwYK1asAADodDpkZWVZ/dOxiIhqOiYhRERkEyZNmgQfHx9kZGQgOjoazZo1AwAsXLgQR44cQWBgIMaMGYO4uDg4OHCgn4jImrGVphJVdGiZQ9FEVJVWrFghjXg8ycvLC3v27FEgov/D9o+IqGI4EkJERERERLKy2iRk7ty5UKlUOHfunNKhEBERERGRBVnldKyTJ0/i2LFjpT7dhCqO0wWIiOTF9pWIqHhWNxJiNBoxadIkrFy5ssiz34s71mAwmC1ERERERGTdrC4J+fDDDzFixAg0adKkzGNjY2Ph5uYmLb6+vjJESERERERElWFV07GOHj0KnU6Hjz/+uFzHz5w5E1OnTpXWDQYDE5FnwOkCRERERCQnqxoJ+fnnn3Hx4kU0adIEGo0GGRkZ6NWrF/7zn/8Ue7xarYarq6vZQkRERERE1s2qRkJmzJiBGTNmSOsajQY//vgjQkNDFYyKbBlvxiciqjnY5hPZDqsaCSEiIiIiourPqkZCnqbX65UOgYiIiIiILMyqkxCqOA45ExEREZG143QsIiIiIiKSFZMQIiIiIiKSFadjERERUYn4xCkiqgocCSEiIiIiIlkxCSEiIiIiIllxOhZVmJJD8JwWQERUc7DNJ6q+OBJCRERERESy4kgIERERVdizjEbUxBEMjuYQFY8jIUREREREJCsmIUREREREJCtOxyIiIiJ6CqdREVUtjoQQEVG1oNFoEBwcDK1WC61Wiy1btigdEhERlYAjIUREVG188803CA0NVToMIiIqA5MQIiKqUYxGI4xGo7RuMBgUjIaIqGbidCwiIqo2hg8fjlatWuHPf/4zsrOziz0mNjYWbm5u0uLr6ytzlERExCSEiIiqhV9++QWnT5/GyZMn4e7ujtGjRxd73MyZM5GTkyMt6enpMkdKRERWNx3rwYMHGDZsGM6fPw9nZ2c0bNgQq1atgkajUTo0srDSnjDCp48QUUX5+fkBAGrVqoW//OUvaN68ebHHqdVqqNVqOUMjKjf2jVRTWOVISExMDC5duoSEhAS8/PLLiImJUTokIiKyYvfu3cOdO3ek9U2bNqF169bKBURERKWyupEQJycn9O3bV1qPiIjA0qVLiz2WNxfahmf55obf9hBRRVy/fh0DBw7Ew4cPIYRAQEAAvv76a6XDoqewbf8/rAuq6awuCXnasmXL0K9fv2L3xcbGYu7cuTJHRERE1iYgIACnTp1SOgwiIionq5yO9dhHH32ExMRELFiwoNj9vLmQiIiIiMj2WO1IyJIlS7Bjxw7s27cPzs7OxR7DmwvpMWsc1i4pJmuMlYjIlliqHeV0YSLlWGUS8umnn2LTpk3Yt28f6tatq3Q4RERERERkQVaXhGRkZOCdd95BQEAAunXrBuDRiMdvv/2mcGRERERERGQJVpeE+Pj4QAihdBhERERUTXAKFZH1seob04mIiIiIqPphEkJERERERLKyuulYRErikD0RERFR1eNICBERERERyYojIUQyq+hoS2nH87dIiIhqjoq2+VXdRzxL/0T0GEdCiIiIiIhIVkxCiIiIiIhIVpyORURERGTDOPWJbBFHQoiIiIiISFZMQoiIiIiISFacjkU1UnUfuq4OT82qDmUgIqoOrLHdfZaYrLEcNRlHQoiIiIiISFYcCSGycvzmhoiILMka+xWOftc8HAkhIiIiIiJZMQkhIiIiIiJZcToWEZXIksPjVT3U/iznrw7D/9WhDERU/dhS22SNsVpjTJbGkRAiIiIiIpIVkxAiIiIiIpKVVU7HSkxMxOjRo/HHH3+gbt26+OqrrxASEqJ0WEQ2r6qnPil9LkupaExylMEa68nasO8gqn6U7G+qQ19Q0WldcvY1VjkSMn78eMTExODy5cuYNm0axo0bp3RIRERk5dh3EBHZDqsbCblx4wZOnjyJPXv2AAAGDhyIyZMnQ6/XQ6PRmB1rNBphNBql9ZycHACAwWB4pvd+4lREZKVK+u9d0v/f0poDS/2ff8Ymp0IqGuuzxvS4/RRCPNsJFKJk3/HonM/8UqIapaJtuC2xZF9Q1f3Ts/SZZb9XBfsPYWVOnDghWrRoYbatffv24ueffy5y7OzZswUALly4cOFi4SU9PV2uZt8i2Hdw4cKFi3Us5e0/rG4kBABUKpXZuigho5o5cyamTp0qrZtMJty6dQvu7u5FzlEWg8EAX19fpKenw9XVteJBV3Osn9KxfsrGOiqdtdSPEAK5ubnw9vZWLIZnpUTfAVjP3+5pjKtirDUuwHpjY1wVY61xAZaJraL9h9UlIb6+vsjIyEBhYSEcHBwghEB6ejr8/PyKHKtWq6FWq8221a1bt1Lv7+rqanUXhjVh/ZSO9VM21lHprKF+3NzcFH3/Z6F03wFYx9+uOIyrYqw1LsB6Y2NcFWOtcQGVj60i/YfV3Zju6emJ1q1bY8OGDQCA7du3Q6PRFJnTS0RE9Bj7DiIi22J1IyEAsHr1aowZMwYfffQRXF1dsX79eqVDIiIiK8e+g4jIdlhlEhIUFISjR4/K+p5qtRqzZ88uMkRPj7B+Ssf6KRvrqHSsn8pTou8ArPdvx7gqxlrjAqw3NsZVMdYaF6BMbCpR0p17REREREREVcDq7gkhIiIiIqLqjUkIERERERHJikkIERERERHJqsYlIYmJiejUqROaN2+ODh064Pz588Ue98UXXyAwMBBNmzZFTEwMCgsLZY5UGeWpH71ej6ioKLi5uaFdu3YKRKmc8tTPgQMH0LFjR4SEhCA0NBTvv/9+iT+aVt2Up36OHj0KrVYLrVaLli1bYvz48TAajQpEq4zytkEA8ODBA4SEhNS4/2dKsUT/8OOPPyI4OBjNmjXDwIEDcffuXWnfb7/9Bq1Wi+bNm6N79+7IzMyULbazZ8+ia9euCA4ORqtWrRATE2P2/06lUiEsLEz6v3no0CFZ4tLr9XBwcJDeV6vVIikpSXrds9ZZZePat2+fWUze3t5o06aNLPVVVh+r5DVWWmxKXmOlxaXkNVZaXEpeY2V9Tqmqa6yIcv2uejXSrVs3sW7dOiGEENu2bRMRERFFjklOThaNGjUSWVlZwmQyiX79+olVq1bJHKkyylM/N2/eFIcOHRI//vijaNu2rcwRKqs89XPy5EmRlJQkhBAiLy9PdO7cWWzcuFHOMBVTnvq5d++eyM/PF0II8fDhQ/Haa6+Jzz77TM4wFVWeOnps6tSpYuzYsTXu/5lSKts/5ObmCk9PT3HhwgUhhBCTJk0SM2bMEEIIYTKZRNOmTcXBgweFEEIsXrxYDBs2TLbYLl++LE6fPi2EEKKwsFAMGTJELFiwQHotAJGbm1vueCwVV0pKinB3dy/23JWpM0v39S+99JJYsmSJtF6V9VVaH6v0NVZabEpeY6XFpeQ1VpHPS3JeY6V9TqnKa+xpNSoJuX79unBzcxMFBQVCiEeV6eXlJVJSUsyOW7RokZg4caK0/tNPP4kXXnhBxkiVUd76eezgwYM16sNRRevnsUmTJom//e1vMkSorGepn7y8PNG7d2/x+eefyxSlsipSR7/88ovo169fjft/phRL9A9bt24Vffv2lfb9/vvvwt/fXwghxPHjx0VISIi0z2AwCCcnJykhr+rYnrZ48WIxbtw4af1ZPvBYIq7SPiA+a51Zur6uXr0qateuLa5fvy5tq8r6eqy4//tKX2OlxfY0Oa+x0uJS8horLa4nKXWNPfbk55SqusaKU6OmY6Wnp8Pb2xsODo9+HkWlUsHPzw9paWlmx6WlpcHf319a12g0RY6pjspbPzXVs9RPVlYWvvnmG/Tt21euMBVTkfrR6/XQarVo0KABXF1dERMTI3e4iihvHd27dw9/+ctf8I9//EOJMGskS/QPxe27evUqTCZTkX0uLi5wcXEp11QGS/dd9+7dw9q1a9GvXz+z7VFRUQgPD8fUqVNx79492eIyGAxo37492rRpg3nz5uHhw4fFvq68dWbp+lq/fj369OkDT09Ps+1VVV+lUfoaKy+5r7GyKHWNlZeS19jTn1Oq6horTo1KQoBHf5AniRLm6j95XEnHVEflrZ+aqiL1YzAY0K9fP0ybNs1snmd1Vt760Wg0SEhIQFZWFoxGI3bs2CFHeFahPHX07rvvYtKkSWjcuLFcYREs0z88fY5nOX9VxQYABQUFGDp0KHr27IlXX31V2p6amooTJ07gyJEjyM7OxrvvvitLXI0aNUJGRgZ0Oh327duHQ4cO4ZNPPqnw+S0d15PWrVuHcePGmW2r6vqqyDksdX5L9f9KXWMlUfoaKw+lrrGSPqdU1TX2tBqVhPj6+iIjI0O68UwIgfT0dPj5+Zkd5+fnB71eL62npqYWOaY6Km/91FQVqZ/c3Fz07t0br7zyCqZOnSp3qIp4luunTp06GDZsGDZu3ChXmIoqbx0dPnwY8+bNg0ajwbBhw3D27Fm0bNlSiZBrDEv0D0/v0+v1aNy4Mezs7Irsy83NRW5uLho1aiRLbMCjD4dDhgxBo0aN8NlnnxV5LQA899xzmDhxYrlugrVEXGq1Wvr2t379+hg7dqz03s9aZ5bs63/55Rfcv38fvXr1KvJaoGrqqzRKX2NlUeoaK42S11h5KHWNlfQ5paquseLUqCTE09MTrVu3xoYNGwAA27dvh0ajgUajMTtu4MCB+Pbbb3H9+nUIIbBq1SoMGzZMgYjlVd76qanKWz93795F79690atXL8yaNUuBSJVR3vpJSkpCQUEBACA/Px87duxAWFiY3OEqorx1dObMGej1euj1emzevBmtWrXC77//rkDENYcl+ofevXtDp9Ph4sWLAICVK1dK+9q2bYsHDx4gPj4eALB69Wr0798ftWrVkiW2wsJCDBs2DPXr18eaNWvMvs28ffs27t+/DwAwmUzYsmULWrduLUtcN27ckNqDx6Oij9/7WevMkn39l19+iTFjxsDe3l62+iqN0tdYaZS8xkqj5DVWHkpcY6V9Tqmqa6xYz3QniQ27ePGiiIiIEIGBgaJt27bi3LlzQgghxo0bJ77//nvpuDVr1oimTZuKJk2aiHHjxj3zTTe2pjz18+DBA9G4cWPRoEEDUatWLdG4cWPpyQnVXXnqZ/78+cLBwUGEh4dLy/z585UMWzblqZ+1a9eKli1birCwMBESEiImT54s8vLylAxbVuVtgx7jjenysUT/8P3334ugoCDRtGlT0b9/f5GTkyPtO3LkiAgLCxOBgYEiKipKZGRkyBbbhg0bBAARFhYmtUuPb8o+cuSIaNWqlfR/csSIEeLmzZuyxLV9+/Yi7cGDBw8qXWeW+FsaDAZRp04d6SlCT8ZUlfVVVh+r5DVWWmxKXmOlxaXkNVbW31Kpa6yszylVdY09TSUEJ/0TEREREZF8atR0LCIiIiIiUh6TECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIiIikhWTECIiIqpyf/zxB3r16gVnZ2doNBqlw5GMGTMGI0aMeKbXfvDBB4iKipLWo6Ki8MEHH1goMsuLj4+HSqVCYWGh0qEQwUHpAIiqow8++ACHDx9GfHy80qEQEVmFlStX4urVqzhz5gzc3Nwsfv7CwkLUqlULBw8eNEsM5LRjxw44Ojoq8t7l0alTJ2RmZsLBgR//SHm8CokUUlBQAAcHB6hUKqVDISKqcsnJyWjbti2aNWtWZJ/JZILJZLL5D8f169dXOoRSOTo6omHDhkqHQQSA07HISm3atAnBwcFwcnJCw4YNERMTgwkTJmDIkCFmxyUlJcHOzg4pKSkAAJVKhS+//BIvvvgiateujQ4dOiA5ORnx8fEIDQ2Fq6srRo4ciQcPHkjn0Gg0WLx4MQYMGABnZ2eEhIRAp9Ph7Nmz6NixI+rUqYOXXnoJt27dkl7z8OFDzJo1Cz4+PnBxcUFUVBTOnDkDAPjqq6+wYMEC/Pzzz1CpVFCpVNDr9dIw+H/+8x+EhISgdu3a2Lx5M7y9vfHw4UPp3EII+Pv746uvviq1jvR6PVQqFXbs2IF27dqhdu3aiI6Oxs2bN7Ft2zY0bdoU9erVw9tvvw0hhPS67OxsDB8+HHXr1kWDBg0wfPhw3Lx5U9r/xRdfQKvV4rnnnoO/vz9mzZplNnT/eOrCBx98gPr168Pb2xuffvppBf66RFTTREVFYf369fj666+hUqkwZswYqFQqbNu2De3bt4eTkxPOnj2LI0eOoFu3bqhbty48PDzw+uuv448//jA71969e9GxY0c4OTnBy8sLEydOBAApuenWrZv0HkDZbVpFbNu2Df7+/njuuecwatQos77kcTmfnI71LH3S/fv3MWnSJHh4eKBu3bp4+eWXodfrpf1ltcEPHjzAm2++CU9PT9SuXRvBwcH47rvvABQ/HWvx4sXw9fWFWq1GREQEjh8/Lu376quv4OPjg2+++QZNmjRB3bp1MXbsWBiNxjLr6vF77dmzByEhIXB2dsaQIUPw4MEDLF++HN7e3vD09MSiRYvMXpecnIx+/fqhTp068Pb2xuTJk3H//n1pf2xsLFq0aAFnZ2cEBgZi2bJlRf4G06ZNw/jx4+Hi4gKNRoPNmzeXGS8pQBBZmWvXrgm1Wi02b94s9Hq90Ol0YtWqVeLo0aPCyclJ3LlzRzp29uzZokuXLtI6ANGkSROxc+dOcf78efH888+Ljh07iu7duwudTicOHz4s3N3dxbJly6TX+Pv7C09PTxEXFycuXbok+vfvL4KCgkS3bt1EfHy8OHXqlGjWrJmYOnWq9JpZs2aJNm3aiF9++UUkJiaK9957T3h6eoqcnBxx//598Ze//EU8//zzIjMzU2RmZorCwkJx8OBBAUBERESIX3/9VZw/f17k5OSIunXril27dknnPnjwoHB2dhYGg6HUekpJSREARHh4uFmc3bp1E6+88oo4e/as+PHHH4Wjo6PYuXOn9LquXbuKP/3pT+LMmTPi7Nmzom/fvqJ3797S/jVr1oi9e/eK5ORk8e9//1s0bNhQrFixQto/evRo4eLiIqZNmyYuXbokVq9eLQCI06dPV/AvTUQ1xc2bN8XAgQPFkCFDRGZmpkhISBAARHBwsNi9e7dITEwUd+7cEbt37xZbtmwRiYmJQqfTic6dO4vBgwdL5/n9999FrVq1xHvvvSfOnz8v/vvf/0rteWZmpgAgtm/fLjIzM6W+ojxt2vDhw8ssw5UrV4SDg4OYN2+euHjxopg3b56oU6eOeOGFF6RjXnjhBfH+++9L68/SJ40cOVL06NFD6HQ6cfHiRfHGG2+I0NBQUVhYKMVbWhu8cOFC0bp1a3HixAmpzPv37xdCCKkfKigoEEIIsXHjRuHs7Cw2bNggzp8/L958803h7u4ucnJyhBBCrFu3Tjg5OYmXX35ZnDlzRhw4cEDUr1/fLN6SPH6vqKgoodPpxKFDh4S7u7vo0aOHGDt2rLhw4YJYt26dWexGo1E0a9ZMvP322+LixYvi+PHjokOHDmLChAnSeT/55BNx6NAhkZycLLZs2SKee+458dNPP5n9DVxdXcWnn34qEhMTxezZs4WTk5O4fv16mTGTvJiEkNU5ceKEcHV1Fbm5uUX2BQcHizVr1kjrTZs2Ff/85z+ldQBi4cKF0vqmTZsEAKHT6aRt48ePFwMGDJDW/f39xVtvvSWtHz16VAAQ27Ztk7bFxsaKNm3aCCGEyMvLE7Vr1xZnz541iy0wMFDExcUJIYR4//33zTomIf6vQY6PjzfbPn78ePGnP/1JWn/jjTfK1SE+TkK2bNliFqdKpTJrbHv16iUlUD///LPw8vKSOiAhhLh69aoAINLT04t9n9jYWNGtWzdpffTo0SIkJMTsmObNm4vPP/+8zJiJqOYaPny4GD16tBDi/9qvr776qtTXHD16VDg4OEgfwEeNGiVeeumlYo8tKCgQAMTBgwdLPWdxbVp52txp06aJjh07mm3r2LFjmUlIRfqklJQU4ejoKG7duiXtz8/PF87OzuLQoUNSvKW1wZMnTxZjx44ttgxPJyEdO3YU7777rrS/oKBA+Pj4iOXLlwshHiUhKpVKZGVlScfExMSIgQMHllRNRd7rt99+Mytr/fr1xYMHD6RtQUFBUlKzfv160bZtW7Pz/Prrr8LR0VG6Bp42fvx48cYbb0jrL7zwgujTp49ZmZydncUPP/xQZswkL07HIqsTHh6OsLAwBAQEYMyYMdi6dSvy8/MBAKNHj0ZcXBwA4Ndff8XVq1cxePBgs9e3atVK+reXlxcAoGXLlmbbsrOzn/k1SUlJyMvLQ0REBOrUqSMtSUlJSE5OLrN8rVu3NlsfM2YMvvvuO+Tm5iIvLw/bt2/HqFGjyjxPSbF7eHjA09Oz2NjPnj2L7Oxs1K1bV4q7efPmACDFfuTIEfTs2RONGzdGnTp1MGfOHKSnp5u9Z2hoqNl6w4YNcePGjXLHTEQEFG0PMzIyMHLkSAQEBMDFxQXdu3dHYWEhsrKyAADnzp2r8E3n5WnTyuPSpUvo0KGD2ban14tTkf7l999/R0FBAXx9faU2ul69esjLyzPrX0prg0eOHIlvvvkGbdu2xXvvvYf//ve/pZYpIiJCWndwcEC7du1w6dIlaZuHh4cU99PvVR5Pl79Zs2ZQq9XFlv/s2bM4ffq0Wd/ao0cP5Ofn4+rVqwCAn376CZGRkfDy8kKdOnXw5ZdfFvl7PvmeDg4OaNCgAfsoK2Tbd4BRteTg4ID4+Hj88ssv2LVrF6ZNm4ZFixbhyJEjGDVqFGbNmoWUlBR8/fXX6N+/f5GnrNSqVUv69+Obvp/eZjKZnvk1d+/eBfBovmvdunXNzlOemxKdnZ3N1iMiIuDn54ft27dDrVbDxcUF0dHRZZ6npNifXH+87fE9J3fv3kWzZs3w008/FTlP48aNkZubi5deeglDhgzBvHnzUL9+ffzrX/8qcn9Kce/xdJ0SEZXl6fZwzJgxyM/Pxz//+U80btwYKSkp6Nu3LwoKCgDA7P628ihvm1YeQohnepBIRfuX2rVrIyEhoch5nvxyqbQ2uEOHDkhJScFPP/2EXbt2oXPnzpg/fz7++te/Vjj2st6roq8vqY96svxdu3bF6tWri5ynUaNGSE5OxoABAzB9+nQsXboUbm5uWLhwIa5cuWLRmEkeTELIKtnb26Nbt27o1q0b3nnnHXh5eSEhIQEdOnRAdHQ0vvjiC2zbtg0bN26UPbYWLVrA0dERmZmZaNeuXbHH1KpVy+xm87KMGTMGcXFxUKvVGD58OOzsqmaQMjw8HGlpaXB1dTXr0B47ceIE7ty5g4ULF0oJ1rN8Y0hE9CyOHTuGDRs2oHv37gAAnU5ntr9Vq1aIj48v9gO1vb097OzszNreS5cuWaxNCwoKwqFDh8y26XQ6s2/1Kys8PBz3799HXl6e2bf5FVW/fn2MHDkSI0eORHh4OL788sti6ywoKAjHjh3DgAEDADx6zPGJEyfQo0ePZ37vyggPD8fOnTvh4+MDJyenIvtPnjyJ2rVrY968edK2xw+mIdvD6VhkdX777TcsXLgQJ0+eRGpqKr7++muo1Wr4+/sDePSBfdGiRVCr1ejZs6fs8bm6umLy5Ml46623sH37dqSkpODo0aN477338PvvvwMA/P39cenSJVy8eBF//PFHmd/AjBw5EocOHcKePXsqNBWronr27IlWrVphwIABOHToEJKTk7F3717ExMQAAPz8/FCrVi2sXLkSycnJWLVqlfRUFSKiqta0aVPExcXhypUr2LVrFz766COz/dOnT8eePXvw/vvv4+LFizh9+jSWL18O4NG33b6+vjhw4ABu3LiBu3fvWrRNi4mJgU6nw4IFC3D58mUsWLAA586dq2yRzQQHB2PAgAEYNmwYdu/ejZSUFPzyyy/4f//v/5k9xbA0f//737Ft2zYkJibi7Nmz2LNnD4KCgoo99n/+53+wcuVK/Otf/8LFixcxceJE5OXlPfOPN1bW8OHD4ejoiKFDh0Kn0+HKlSv44YcfpASqadOmMBgM+Oqrr3DlyhXMnz+/SKJKtoNJCFkdV1dX7N+/Hz179kSLFi2wadMm7NixQ5qT2r9/fzg7O+NPf/oT7O3tFYlx8eLFmDhxIv76178iKCgIQ4YMQXp6Otzd3QEAgwYNQocOHdC+fXt4eHggLS2t1PN5e3vjxRdfRHh4uNlcYUuzs7PDrl27EBQUhAEDBqBly5b4f//v/0nfEHp6emLNmjVYuXIlWrVqhT179mDGjBlVFg8R0ZPWrl2LK1euIDQ0FLNmzcL8+fPN9oeEhOCHH37Arl27EB4ejp49e5rdv7Bo0SJs3LgRjRo1wuTJky3apjVr1gwbNmzA6tWr0bp1a5w/f176AseSNm7ciN69e2Ps2LEIDg7GmDFjUFBQUGTqWkmee+45/O1vf0N4eDiioqJQv359/OMf/yj22Ndffx2zZ8/GtGnTEB4ejjNnzuDf//43XF1dLVmkcnNxcUF8fDwcHR3Ro0cPhIeH44MPPkCjRo0APLqHaMGCBZg2bRratGkDvV6P8ePHKxIrVZ5KVHSCJZHCbty4AR8fH5w4cQJhYWFKh2Mx4eHhGDduHKZMmaJ0KERERERViveEkM0wmUzIzMzEnDlz0KFDh2qTgNy6dQvffPMNkpKSqnQqFhEREZG14HQsshlpaWnw8fHBwYMHsWLFCqXDsZg2bdpgxowZ+Mc//mH2tK20tDSzxxQ+ufTp00e5gImIqqFDhw6V2OZOmDBB6fCsDuuLKovTsYisVGFhIfR6fbH7ateujcaNG8sbEBFRNZaXlyf9FsXTSnqiYE3G+qLKYhJCRERERESy4nQsIiIiIiKSVbW6Md1kMuHatWtwcXF5pl81JSKq6YQQyM3Nhbe3d5X9aKa1Yd9BRFR5Fe0/qlUScu3aNfj6+iodBhGRzUtPT4ePj4/SYciCfQcRkeWUt/+oVkmIi4sLgEeFV+qHdoiIbJnBYICvr6/UntYE7DuIiCqvov1HtUpCHg+ju7q6siMhIqqEmjQtiX0HEZHllLf/qBkTfomIiIiIyGpUq5EQIqKKMplMyM/PVzoMRTg6OtaYm8+JiCzt4cOHKCgoUDoM2Vmq72ASQkQ1Vn5+PlJSUmAymZQORRF2dnZo0qQJHB0dlQ6FiMhmCCGQlZWFO3fuKB2KIizVdzAJIaIaSQiBzMxM2Nvbw9fXt8aNCDx+LG1mZib8/Pxq1D0gRESV8TgB8fT0hLOzc41qPy3ZdzAJIasyZ07FthM9q8LCQty/fx/e3t5wdnZWOhxFeHh44Nq1aygsLEStWrWUDoeqidLaa7blZOsePnwoJSDu7u5Kh6MIS/UdNeurPyKi//Xw4UMAqNFTkR6X/XFdEBFR6R7fA1JTv7wCLNd3MAkhohqtJg2jP60ml52IqDJqcvtpqbJzOhYR0f+qyqkinIZCtorTZInKVlX/H6rz/zOOhBARWTGVSoW7d++WuF+v12PNmjUyRkRERLbA2vsPJiFERDZM6U6EiIhsk9L9B5MQIiIrsmPHDgQHB+P555/H3/72N2n7iBEj0K5dO4SFheHll1/GjRs3AAATJkzA+fPnodVq8corrwAA3n33XbRv3x5arRYvvPACEhMTFSkLERHJx9b6D94TQlWqqucSc64yVSc3btzAm2++iSNHjiAoKAiLFi2S9i1duhQNGjQAAHz88ceYN28eli9fjlWrVuGvf/0rTpw4IR07ffp0LF68GACwefNmvP322/jxxx/lLQwREcnGFvsPJiFERFbi2LFjaNOmDYKCggAAMTExmD59OgBg48aNiIuLg9FoRF5eHho2bFjiefbs2YPPP/8cubm5MJlMMBgMssQvh927d+O9996DyWRCQUEB3n33XYwePRo3btzAqFGjkJSUBLVajVWrViEyMlLpcImIZGGL/QeTECIiKyGEKHZ7QkICli9fjiNHjsDDwwM7d+7EvHnzij02LS0NU6ZMwfHjxxEQEIAzZ87gxRdfrMqwZSOEwJ/+9CccPHgQYWFh0Ov1CA4OxoABAzBjxgxERERg165d0Ol0GDRoEJKSkuDgwG6OiKo/W+w/eE8IEZGVeP7553Hq1ClcvnwZALB27VoAwO3bt+Hq6or69esjPz8fq1evll7j6uqKnJwcaT0nJweOjo5o2LAhhBBYvny5vIWQwZ07dwAABoMB7u7uUKvV2Lp1KyZNmgQAaN++Pby8vHD48OFiX280GmEwGMwWIiJbZov9B78iIiL6X0rfS+Tp6Yk1a9agX79+cHd3x6BBgwAA3bp1w4YNGxAcHAwfHx906tQJu3fvBgCEhYUhKCgIoaGhCAgIwM6dOzF48GC0bNkSfn5+6NGjh5JFsiiVSoWtW7diwIABeO6553D79m3s2LFDmjbg4eEhHavRaJCWllbseWJjYzF37ly5wiaiGoD9R8WpREnjNzbIYDDAzc0NOTk5cHV1VTocQsVvHK/q7USPPXjwACkpKWjSpAmcnJyUDkcRxdWBNbejhYWF6N27N+bOnYvOnTtDp9Ohf//+OHPmDPz8/HDv3j3p2MGDB6Nfv34YNWpUkfMYjUYYjUZp3WAwwNfX1yrLbA0s2f6ybSZbx76j5DqoaP/BkRAiIrIJCQkJuHbtGjp37gzg0bQrb29vnDlzBgCQnZ0tjYakpqbCz8+v2POo1Wqo1Wp5giYiomLxnhAiIrIJvr6+yMjIwKVLlwAAV65cQVJSEpo3b47BgwdjxYoVAACdToesrCw+HYuIyIpxJISIarRqNCO1wmyt7F5eXli9ejUGDRoEOzs7CCGwcuVKNG7cGAsXLsTIkSMRGBgIR0dHxMXF8clYRFRlTCaT0iEoxlJ9B1toIqqRatWqBZVKJU3hUalUSockKyEEsrOzoVKpUKtWLaXDKbfXX38dr7/+epHtXl5e2LNnjwIREVFN4ujoCDs7O1y7dg0eHh5wdHSsUf2HJfsOJiFEVCPZ29vDx8cHGRkZ0Ov1SoejCJVKBR8fH9jb2ysdChGRTbCzs0OTJk2QmZmJa9euKR2OIizVdzAJIaIaq06dOggMDERBQYHSoSiiVq1aTECIiCrI0dERfn5+KCwsxMOHD5UOR3aW6juYhBBRjWZvb88P4kREVCGPpyPZ0nRWa8MkhAj8vREiIiIiOSnyiN4pU6ZAo9FApVLh3Llz0vaoqCgEBARAq9VCq9Xi73//uxLhERERERFRFVJkJGTQoEGYNm1asc9wX7ZsGV5++WUFoiIiIiIiIjkoMhLStWtX+Pj4VPo8RqMRBoPBbCGi6mfHjh1o27YttFotWrRoge7du0vPaNdoNGYjqtXJb7/9Bq1Wi+bNm6N79+7IzMws9riPP/5YGkHWarVwdXXF1KlTAQBHjx6Vtrds2RLjx4+H0WiUsxhERIqoqX3HoEGD4O3tDZVKhbt375Z43LfffouwsDCpf3j//ffNfgPkiy++QGBgIJo2bYqYmBgUFhZaNE6r+8X0d999F61atcLQoUORnJxc6rGxsbFwc3OTFl9fX5miJCK5ZGVlYcKECdixYwcSEhJw4cIFLF68uNo/l10IgeHDh2Pp0qW4fPky+vTpIyUWT5sxYwYSEhKQkJCA48ePw9HREcOHDwcAhIeHQ6fTISEhAWfPnkV2djZWr14tZ1GIiGRXU/sOAJgwYQISEhLKPC46OlrqO06dOoW9e/fihx9+AACkpKRg1qxZOHz4MK5cuYKsrCx88cUXFo3TqpKQuLg4XLhwAWfOnEGXLl3KnJY1c+ZM5OTkSEt6erpMkRKRXDIzM+Hg4AB3d3dpW5s2bYrtSJYtW4bIyEhkZ2cjKysLQ4YMQYcOHRAWFoYPP/wQALB792706tULAHDnzh3Y29vjn//8J4BH3/qMGzcOwKN71KZPn44uXbqgadOmmDBhgvQ+ubm5ePPNN6VzT5gwQXrM7/z589GiRQtp9CE1NRV5eXkYOnQoQkJCEB4ejp49e5ZZ7hMnTkCtViMqKgoAMH78eHz33XdlPk74u+++g4+PD9q2bQsAcHZ2lp7ekp+fj7y8PNjZWVXTT0RkcTW17wAeJReenp5lHufi4iL1Bw8ePIDRaJTWv/nmG7z22mvw8vKCSqXChAkTsGnTpnK9f3lZVU/0eCRDpVJh8uTJSE5Oxs2bN0s8Xq1Ww9XV1WwhouolPDwczz//PPz8/PDaa69h8eLFuHr1qtkxJpMJb7/9Nn7++Wfs3bsXHh4eGD16NCZPnozjx4/j5MmTOH78OL799lt07doVx48fh9FoxMGDB9GxY0fs378fALBv3z5ER0dL501KSkJ8fDzOnTuH3bt34+jRowCAd955RzrP6dOnUVhYiOXLl+P27dtYsmQJTp48iYSEBBw5cgReXl7YtWsXbt++jfPnz+P06dPYvHmz9B5arbbYH7xKS0uDv7+/tO7i4gIXF5cSp2Q99mRn+Jher4dWq0WDBg3g6uqKmJiYctY+VUdz5hS/EFUnNbXvqKgjR44gLCwMnp6e6N69O1566SUARfsgjUaDtLS0Sr/fk6wmCSksLMT169el9e3bt8PLy8ssgyWSGztr5dnZ2WH79u04cuQIevfujV9//RUtW7bElStXpGPGjh2LBw8eYNu2bahduzbu3buHAwcOYMqUKdBqtWjXrh2uXLmCixcvonbt2tBqtfj111+xb98+zJw5EydPnoTJZMLBgwfRvXt36bzDhg2Dvb299JqkpCQAj0YbFi9eDK1Wi9atW+PQoUNITEyEq6srAgMDMWLECKxevRq3bt2Ck5MTwsPDcfHiRUycOBFbtmwxe658QkICvL29iy3709/YPTlXtzjp6ek4fPiwNBXrMY1Gg4SEBGRlZcFoNGLHjh3lq3wiIhtVk/uOiujUqRPOnDmD9PR06HQ6HDp0SNr3ZB9UVv/zLBR5OtakSZPw/fffIysrC9HR0ahTpw5Onz6Nl156SRoKatCgAXbu3KlEeERkhYKDgxEcHIzx48ejd+/e2Llzp3SPRFRUFPbu3YsbN26gYcOGMJlMUKlU0Ol0xf6QVHR0NPbt24dDhw5h4cKFaNmyJeLi4uDl5WU2hO3k5CT9297eXropTwiB7777DgEBAUXOfezYMRw5cgTx8fGIiIjApk2b0KVLF5w/fx4HDhzAvn37MG3aNCQkJKBevXolltfPzw96vV5az83NRW5uLho1alTia9atW4dXXnkF9evXL3Z/nTp1MGzYMGzcuBHDhg0r8TxERNVFTes7npWHhwdeeuklbNu2DV27di3SB6WmpsLPz8+i76nISMiKFSuQkZGBwsJCZGVl4cqVK3juuedw4sQJnD17FqdPn8b+/fsRHh6uRHhEZEWuXr2KX3/9VVq/ffs2UlJS0LRpU2nbmDFj8P777+PFF19EamoqXFxc0KVLF3z88cfSMdeuXUNGRgaARx3Jv/71L9SrVw916tRBdHQ0Zs+ebTacXppXXnkFH3/8sdSx3L59G1euXEFubi6uX7+OLl26YNasWYiMjMSpU6eQkZEBlUqFV155BUuWLIEQosx72Nq2bYsHDx4gPj4eALB69Wr079+/xF/nFULgq6++KjIVKykpSZpznJ+fjx07diAsLKxc5SQislU1te+oiEuXLklPC8vNzcWPP/4o9Q8DBw7Et99+i+vXr0MIgVWrVln8yyurmY5FZEmcRlV9FBYWYt68eWjevDm0Wi26dOmC0aNH49VXXzU7bsiQIVi8eDF69uyJy5cvY+PGjbhw4QJatWqFVq1aYeDAgdI9Zu3atUNOTo40fN6jRw+kpqaWuyNZunQpHBwcoNVqERYWhujoaOj1euTk5GDAgAFo1aoVwsLCUFBQgNGjR+Ps2bPo1KkTwsLC0KZNG4wcOVJq6Eua12tnZ4cNGzbgf/7nf9C8eXP89NNP+OSTT6T9ffv2xYkTJ6T1AwcOQAhhNiUAAOLj49G6dWuEh4ejdevW8PLywqxZs8pVTiIiW1VT+w7gUbLz+KcwgoKCpAecAOZ9x7Zt2xAaGirdPxMdHY0///nPAICAgADMnTsXnTt3RtOmTeHp6VnkS67KUomqmOSlEIPBADc3N+Tk5PAmdStR0gf/qt5ekqo+D5Gtq4ntaE0rs5LtMttOouqrom0pR0KIiIiIiEhWTEKIiIiIiEhWijwdi0gpnApAREREpDwmIURERCQL3n9HRI9xOhYREREREcmKIyFkEfy2ioiIiIjKiyMhREREREQkKyYhREREREQkKyYhRERkM4xGIyZPnozAwEC0bNkSI0aMAADcuHEDvXv3RmBgIEJDQ3H48GGFIyUiotLwnhAiIrIZM2bMgJ2dHS5fvgyVSoXMzExpe0REBHbt2gWdTodBgwYhKSkJDg7s5oiIrBFbZyIisgn37t3DunXrkJGRAZVKBQBo1KgRAGDr1q1ISUkBALRv3x5eXl44fPgwoqKiipzHaDTCaDRK6waDoeqDJyIiM5yORURENiEpKQnu7u6YP38+2rVrhy5dumD//v24efMmTCYTPDw8pGM1Gg3S0tKKPU9sbCzc3NykxdfXV64iEBHR/+JICBER2YSCggIkJycjJCQEH3/8MU6fPo3o6GicO3dOGhl5TAhR4nlmzpyJqVOnSusGg6FaJiJ8dDoRWTMmIUREZBP8/f1hZ2eH4cOHAwDCw8PRpEkTXLhwAQCQnZ0tjYakpqbCz8+v2POo1Wqo1Wp5giYiomJxOhYREdmEBg0aoHv37ti9ezeAR4lGSkoKgoKCMHjwYKxYsQIAoNPpkJWVhcjISCXDJSKiUnAkhBTBaQJE9CxWrVqFsWPHYvr06bC3t8eaNWvQqFEjLFy4ECNHjkRgYCAcHR0RFxfHJ2MREVkxttBERGQzAgICEB8fX2S7l5cX9uzZI39ARET0TDgdi4iIiIiIZMWRECIiIqowTqslospgEkIVolSnw86OiIiIqPrgdCwiIiIiIpIVkxAiIiIiIpIVkxAiIiIiIpIVkxAiIiIiIpIVb0wnIiIiq1TSQ0n4sBIi28eRECIiIiIikhWTECIiIiIikhWTECIiIiIikpUiSciUKVOg0WigUqlw7tw5afuNGzfQu3dvBAYGIjQ0FIcPH1YiPCIiIiIiqkKKJCGDBg3C4cOH4e/vb7Z9xowZiIiIQGJiItatW4fhw4ejsLBQiRCJiIiIiKiKKPJ0rK5duxa7fevWrUhJSQEAtG/fHl5eXjh8+DCioqKKPd5oNMJoNErrBoPB4rESERFZKz4liohsldXcE3Lz5k2YTCZ4eHhI2zQaDdLS0kp8TWxsLNzc3KTF19dXjlCJiIiIiKgSrCYJAQCVSmW2LoQo9fiZM2ciJydHWtLT06syPCIiIiIisgCr+bFCd3d3AEB2drY0GpKamgo/P78SX6NWq6FWq2WJj4iIiKwbf9yQyHZY1UjI4MGDsWLFCgCATqdDVlYWIiMjFY6KiIiIiIgsSZEkZNKkSfDx8UFGRgaio6PRrFkzAMDChQtx5MgRBAYGYsyYMYiLi4ODg9UM1hARERERkQUo8gl/xYoV0ojHk7y8vLBnzx4FIqKncehaHpw6QERUcWwjiWyfVU3HIiIiIiKi6o9JCBERERERyYo3XBA9A06jIiIiInp2HAkhIiKbM3fuXKhUKpw7dw4AcOPGDfTu3RuBgYEIDQ3F4cOHFY6QiIhKwySEiIhsysmTJ3Hs2DGz35GaMWMGIiIikJiYiHXr1mH48OEoLCxUMEoiIioNkxAiIrIZRqMRkyZNwsqVK6FSqaTtW7duxaRJkwAA7du3h5eXV4mjIUajEQaDwWwhIiJ5MQkhIiKb8eGHH2LEiBFo0qSJtO3mzZswmUzw8PCQtmk0GqSlpRV7jtjYWLi5uUmLr69vlcdNRETmmIQQEZFNOHr0KHQ6HSZOnFhk35OjIgAghCjxPDNnzkROTo60pKenWzxWIiIqHZ+ORURENuHnn3/GxYsXpVGQjIwM9OrVC2vXrgUAZGdnS6MhqampZveMPEmtVkOtVssTNFkFPtGQyPpwJISIiGzCjBkzcO3aNej1euj1evj4+GD37t3o06cPBg8ejBUrVgAAdDodsrKyEBkZqXDERERUEo6EEBGRzVu4cCFGjhyJwMBAODo6Ii4uDg4O7OKIiKwVW2giIrJJer1e+reXlxf27NmjXDBERFQhTEJqMM6FJSIiIiIl8J4QIiIiIiKSFZMQIiIiIiKSFZMQIiIiIiKSFe8JIbIgPoueiIiIqGxMQoiIiIhflhCRrDgdi4iIiIiIZMUkhIiIiIiIZMUkhIiIiIiIZMUkhIiIiIiIZMUkhIiIiIiIZMWnYxHJgE+dISKyLXzkOlHV4kgIERERERHJikkIERERERHJitOxiIiIrBynAFUN1iuRcjgSQkREREREsmISQkREREREsrLK6VgajQZOTk5wcnICAMycORNDhw5VOCoi+fCpLERE1ontM5FlWGUSAgDffPMNQkNDlQ6DiIiIiIgszGqTkPIwGo0wGo3SusFgUDAaIiIiIiIqD6u9J2T48OFo1aoV/vznPyM7O7vYY2JjY+Hm5iYtvr6+MkdJREREREQVZZUjIb/88gv8/PxQUFCADz74AKNHj8a///3vIsfNnDkTU6dOldYNBgMTkWJwnioRERERWROrTEL8/PwAALVq1cJf/vIXNG/evNjj1Go11Gq1nKEREREREVElWd10rHv37uHOnTvS+qZNm9C6dWvlAiIiIqvw4MED9O/fH82bN4dWq0Xv3r2h1+sBADdu3EDv3r0RGBiI0NBQHD58WNlgiYioVFY3EnL9+nUMHDgQDx8+hBACAQEB+Prrr5UOy6pwehUR1VQxMTHo06cPVCoVli9fjpiYGOzZswczZsxAREQEdu3aBZ1O4bbNsAAADyRJREFUh0GDBiEpKQkODlbXzREREawwCQkICMCpU6eUDoOIiKyMk5MT+vbtK61HRERg6dKlAICtW7ciJSUFANC+fXt4eXnh8OHDiIqKKnIePlmRiEh5VpeEEBERlceyZcvQr18/3Lx5EyaTCR4eHtI+jUaDtLS0Yl8XGxuLuXPnyhUm1RD8EUOiirG6e0KIiIjK8tFHHyExMRELFiwAAKhUKrP9QogSXztz5kzk5ORIS3p6epXGSkRERXEkhMiGKPVNG7/hI2uyZMkS7NixA/v27YOzszOcnZ0BANnZ2dJoSGpqqvSkxafxyYpERMpjEkJERDbj008/xaZNm7Bv3z7UrVtX2j548GCsWLECc+bMgU6nQ1ZWFiIjI5UL9BkxsafSrgFeH1SdMAkhIiKbkJGRgXfeeQcBAQHo1q0bgEejGr/99hsWLlyIkSNHIjAwEI6OjoiLi+OTsYiIrBhbaCIisgk+Pj4l3uvh5eWFPXv2yBwRERE9KyYhRERERDLj1Cqq6fh0LCIiIiIikhWTECIiIiIikhWnYxERERHZAD4unaoTjoQQEREREZGsOBJCREQkM35zXXPY0t+aIy0kJ46EEBERERGRrJiEEBERERGRrJiEEBERERGRrHhPCFE1wHm8REREZEs4EkJERERERLLiSAgREVElcTSSiKhiOBJCRERERESy4kgIUTVmK9/OlhaPtcVKRERElcckhIiIqIowiSYl8foja8bpWEREREREJCuOhFgxfoNBVcWWri1bmVJGRERE5cckhIiIiIgsil8gUVk4HYuIiIiIiGTFkZAqwOyfqHhy/B/g/z8iIiLrxySEiIiIyIYp9SWLJd+XXyDVPJyORUREREREsmISQkREREREsrLK6ViJiYkYPXo0/vjjD9StWxdfffUVQkJCqvx9KzoUWNEhQg4pUnVTHa7pqp4CUNXtR3X4G1iKUn0HUXUnx7QrS53nWc5vqc9/Sk5Pq+p6rQpWORIyfvx4xMTE4PLly5g2bRrGjRundEhERGTl2HcQEdkOqxsJuXHjBk6ePIk9e/YAAAYOHIjJkydDr9dDo9GYHWs0GmE0GqX1nJwcAIDBYHim937iVGZKOl1JxxNR1avo/0tLHV9Rljp/Vcf5f+d7dEIhhGVPXMWU7DsenfOZX0pEpZCj7ba2fuNZ3sNSbVBlylDh/kNYmRMnTogWLVqYbWvfvr34+eefixw7e/ZsAYALFy5cuFh4SU9Pl6vZtwj2HVy4cOFiHUt5+w+rGwkBAJVKZbYuSsioZs6cialTp0rrJpMJt27dgru7u9k5DAYDfH19kZ6eDldX16oJ+hkwrophXBVnrbExroqRMy4hBHJzc+Ht7V2l71MVLN13lJe1XjdyYh2wDmp6+QHWQUX7D6tLQnx9fZGRkYHCwkI4ODhACIH09HT4+fkVOVatVkOtVpttq1u3bonndnV1tcqLgnFVDOOqOGuNjXFVjFxxubm5Vfl7WFpV9h3lZa3XjZxYB6yDml5+oGbXQUX6D6u7Md3T0xOtW7fGhg0bAADbt2+HRqMpMqeXiIjoMfYdRES2xepGQgBg9erVGDNmDD766CO4urpi/fr1SodERERWjn0HEZHtsMokJCgoCEePHrXY+dRqNWbPnl1k+F1pjKtiGFfFWWtsjKtirDUua2PpvqO8+PdhHQCsg5pefoB1UFEqUdKde0RERERERFXA6u4JISIiIiKi6o1JCBERERERyYpJCBERERERyYpJCBERERERycrmkpDExER06tQJzZs3R4cOHXD+/Pkix+j1ekRFRcHNzQ3t2rUrsv/HH39EcHAwmjVrhoEDB+Lu3bvSvt9++w1arRbNmzdH9+7dkZmZKUtcZ8+eRdeuXREcHIxWrVohJiYGRqNR2q9SqRAWFgatVgutVotDhw7JEpder4eDg4P0vlqtFklJSdJ+pepr3759ZjF5e3ujTZs20v6qrK8DBw6gY8eOCAkJQWhoKN5//32zX2ZW6voqLS4lr6/S4lLy+iotrqq6vsob29GjR6Vzt2zZEuPHjzf7e1XFNUZFledvBQBffPEFAgMD0bRpU8TExKCwsBBA2de3LahsHQBAWloa+vXrh6CgIAQHB+Pzzz+XK3yLqGwdlNWe2AJLXAdLlixBaGgotFotIiIioNPp5ArfIixRB4sXL0ZoaChCQkLw2muv4c6dOzJFb6WEjenWrZtYt26dEEKIbdu2iYiIiCLH3Lx5Uxw6dEj8+OOPom3btmb7cnNzhaenp7hw4YIQQohJkyaJGTNmCCGEMJlMomnTpuLgwYNCCCEWL14shg0bJktcly9fFqdPnxZCCFFYWCiGDBkiFixYIO0HIHJzc8sViyXjSklJEe7u7sWeW8n6etpLL70klixZIq1XZX2dPHlSJCUlCSGEyMvLE507dxYbN24UQih7fZUWl5LXV2lxKXl9lRbX0yx1fZU3tnv37on8/HwhhBAPHz4Ur732mvjss8+EEFV3jVFR5flbJScni0aNGomsrCxhMplEv379xKpVq4QQpV/ftqKydWAymUSbNm3E1q1bpfXMzEzZ4reEytbB055uT2xBZesgISFB+Pn5Se1mXFycaN++vWzxW0Jl62DPnj0iNDRUGAwGIYQQc+bMERMnTpQtfmtkU0nI9evXhZubmygoKBBCPGrMvLy8REpKSrHHHzx4sMiH161bt4q+fftK67///rvw9/cXQghx/PhxERISIu0zGAzCyclJ+jBQlXE9bfHixWLcuHHS+rN86LFEXKV1otZSX1evXhW1a9cW169fl7bJUV+PTZo0Sfztb38TQljH9VVcXE9T4voqLi5ruL6Ki+tJlrq+njW2vLw80bt3b/H5558LIarmGqOiyvu3WrRokdkHiZ9++km88MILQgjbT0IsUQd79+4VnTt3litki7NEHTypuPbE2lmiDhISEqQP50II8fnnn4vXXntNlvgtwRJ1sHjxYvHWW29J+06cOCFcXFyqPHZrZlPTsdLT0+Ht7Q0Hh0e/sahSqeDn54e0tLRynyMtLQ3+/v7SukajwdWrV2EymYrsc3FxgYuLS5nTGSwR15Pu3buHtWvXol+/fmbbo6KiEB4ejqlTp+LevXtlnsdScRkMBrRv3x5t2rTBvHnz8PDhQwBF61Kp+lq/fj369OkDT09Ps+1y1FdWVha++eYb9O3bF4D1XF9Px/UkJa+v4uKyhuurtPqy1PVV0dj0ej20Wi0aNGgAV1dXxMTEAKiaa4yKKu/fqri/x5PHlHR92wJL1MH58+fh4eGBYcOGofX/b+9+QqJ4wziAf3+VdMguEsKyamsmom6zLHZIAvGkK1EZgi7kodqLhJeKpItC4DXEi5REXrZDiIp1EfIQFkvg34MHL4pLK/SHFNvYtjb26SD7om2uWzt/dvh9Pzdnl3ee+c7jC+84M3q9uHLlCtbW1sw7iBzp1Qcp+80n+UyPDFJzZXl5OUpKSjAwMGCr2/L0yODs2bN4+fIlPnz4ABFBMBhENBrF5uameQeSZ2y1CAF2Tvxu8g//a/H3MfQYX4+6ACCRSKCjowNNTU24fPmy2h4OhzE3N4dQKIRPnz7h7t27ptTlcDgQiUQwOzuL6elpvH79Gg8ePMh5fL3yAoCRkREEAoE928zI68uXL7h48SJ6enrSnhfQY3y96wKs7a8/1ZUP/ZUpL0Df/vqb2lwuF5aWlvD+/Xt8//4d4+Pj+47xL+PTwbLNcvf3dn/noP62g1wzSCQSmJ6eRm9vLxYXF9HS0gK/329MsQbJNYPd/jSf2EGuGYTDYTx//hyrq6uIRCK4desWrl69akyxBsk1g8bGRty5cwcXLlxAfX09HA4HAKCgoMCAau3BVouQ0tJSRCIR9ZCPiODdu3coKyvLeoyysjKsr6+rn9fX1+F0OnHo0KG0z6LRKKLRqGoUI+sCdibr9vZ2OBwODA4OptUNAMeOHcPNmzezehBWj7qOHj2qrtgUFRXhxo0bat9W5wUAMzMziMViaG5u3rPd6Lyi0Sh8Ph8uXbqE27dv79mvlf21X12Atf21X11W91emvAB9++tva0spLCyE3+/H06dP1b717jFKl+25+j3zcDisvpOpv+1AjwxOnjwJr9eL2tpaAEBnZyfm5+dt8xchPTJI2W8+yXd6ZDA6Ogq3263mouvXr2NmZuZ/1wddXV2Ym5vD27dv0dDQgJKSEhw/ftyUY8hHtlqEFBcXw+v1IhgMAgDGxsbgcrngcrmyHsPn82F2dhYrKysAgKGhIXVVpq6uDvF4HK9evQIAPHr0CK2trQeuUvWo6+fPn/D7/SgqKsLw8PCelfTW1hZisRgAIJlM4tmzZ/B6vQeOqUddHz9+RCKRAAB1NTa1byvzSnny5AmuXbuGw4cPq21G5/X161f4fD40Nzejt7d3z2dW9lemuqzsr0x1WdlfmepK0bO//qa21dVVlcuPHz8wPj4OTdMAGNNjlC7bc9XW1oaJiQl1i8XDhw/V+cjU33agRwYtLS3Y2NjAxsYGAGBqagput3vP71Q+0yODlD/NJ3agRwanTp3Cmzdv1Jv8Xrx4gerqattkoVcfpG6NjcVi6OvrQ09Pj2nHkJeMedTEOCsrK3Lu3DmprKyUuro6WV5eFhGRQCAgk5OTIiISj8fF6XTKiRMnpKCgQJxOp3p7jIjI5OSkVFVVSUVFhbS2tsr29rb6LBQKiaZpUllZKY2NjRKJREypKxgMCgDRNE08Ho94PB71cFMoFJIzZ86IpmlSU1MjnZ2d8vnzZ1PqGhsbk9raWrXv7u5uicfjluclsvPQbWFhoXrD0e6ajMyrv79fjhw5os6Tx+OR/v5+NYZV/ZWpLiv7K1NdVvbXQefRiP7KtrbHjx+n5fLt2zc1hhE9RumyOVciIsPDw1JRUSHl5eUSCATUiwAO6m87yDUDEZGpqSnxeDyiaZo0NDSoMexCjwz2m0/sItcMksmk3Lt3T6qqqkTTNDl//rwsLCxYciz/So8+cLvdUlNTI6dPn5b79+9LMpk0/TjyyX8ivGGYiIiIiIjMY6vbsYiIiIiIyP64CCEiIiIiIlNxEUJERERERKbiIoSIiIiIiEzFRQgREREREZmKixAiIiIiIjIVFyFERERERGQqLkKIiIiIiMhUXIQQEREREZGpuAghIiIiIiJT/QJRDkZwIRmdZQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output.png](attachment:output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As showns in the skewness number, some of the data is skewed and can be changed by taking the logaritme of the features. This will make the model better at generalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness after logarithm transformation:\n",
      "perimeter_mean            0.328800\n",
      "area_mean                 0.287328\n",
      "compactness_mean          1.043195\n",
      "concavity_mean            1.206982\n",
      "concave points_mean       1.083180\n",
      "fractal_dimension_mean    1.272294\n",
      "dtype: float64\n",
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0     1.097064     -2.073335        1.281628   1.130319         1.568466   \n",
      "1     1.829821     -0.353632        1.597721   1.713327        -0.826962   \n",
      "2     1.579888      0.456187        1.509470   1.511457         0.942210   \n",
      "3    -0.768909      0.253732       -0.550424  -0.843470         3.283553   \n",
      "4     1.750297     -1.151816        1.663405   1.667470         0.280372   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0          3.150675        2.567947             2.487638       2.217515   \n",
      "1         -0.481575        0.011104             0.571874       0.001392   \n",
      "2          1.076890        1.393265             2.021815       0.939685   \n",
      "3          3.256221        1.908415             1.460738       2.867383   \n",
      "4          0.569623        1.400416             1.438255      -0.009560   \n",
      "\n",
      "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0                2.251816  ...      1.886690      -1.359293         2.303601   \n",
      "1               -0.871539  ...      1.805927      -0.369203         1.535126   \n",
      "2               -0.396907  ...      1.511870      -0.023974         1.347475   \n",
      "3                4.856345  ...     -0.281464       0.133984        -0.249939   \n",
      "4               -0.562573  ...      1.298575      -1.466770         1.338539   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0    2.001237          1.307686           2.616665         2.109526   \n",
      "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
      "2    1.456285          0.527407           1.082932         0.854974   \n",
      "3   -0.550021          3.394275           3.893397         1.989588   \n",
      "4    1.220724          0.220556          -0.313395         0.613179   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0              2.296076        2.750622                 1.937015  \n",
      "1              1.087084       -0.243890                 0.281190  \n",
      "2              1.955000        1.152255                 0.201391  \n",
      "3              2.175786        6.046041                 4.935010  \n",
      "4              0.729259       -0.868353                -0.397100  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "skewed_features = ['perimeter_mean','area_mean','compactness_mean','concavity_mean', 'concave points_mean', 'fractal_dimension_mean']\n",
    "\n",
    "# Apply logarithm transformation to skewed features\n",
    "def transform_log(data) -> pd.Dataframe:\n",
    "    for feature in skewed_features:\n",
    "        data[feature] = np.log1p(data[feature])\n",
    "\n",
    "    # Check skewness after transformation\n",
    "    skewness_after_transformation = data[skewed_features].skew()\n",
    "    print(\"Skewness after logarithm transformation:\")\n",
    "    print(skewness_after_transformation)\n",
    "\n",
    "\n",
    "    # StandardScale the dataset\n",
    "    scaler = StandardScaler()\n",
    "    standardized_data = scaler.fit_transform(data)\n",
    "    return standardized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use StandarScaler to transform the entire dataset, so the bigger data numbers don't outshine the smaller ones. This way all data has almost equal influence in the training of the model. We are using StandardScaler above MinMaxScaler as it is more robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: \n",
      "    radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   fractal_dimension_mean  \n",
      "0                 0.07871  \n",
      "1                 0.05667  \n",
      "2                 0.05999  \n",
      "3                 0.09744  \n",
      "4                 0.05883   \n",
      "\n",
      "Worst: \n",
      "    radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0         25.38          17.33           184.60      2019.0            0.1622   \n",
      "1         24.99          23.41           158.80      1956.0            0.1238   \n",
      "2         23.57          25.53           152.50      1709.0            0.1444   \n",
      "3         14.91          26.50            98.87       567.7            0.2098   \n",
      "4         22.54          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \n",
      "0             0.6656           0.7119                0.2654          0.4601  \n",
      "1             0.1866           0.2416                0.1860          0.2750  \n",
      "2             0.4245           0.4504                0.2430          0.3613  \n",
      "3             0.8663           0.6869                0.2575          0.6638  \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "SE: \n",
      "    radius_se  texture_se  perimeter_se  area_se  smoothness_se  \\\n",
      "0     1.0950      0.9053         8.589   153.40       0.006399   \n",
      "1     0.5435      0.7339         3.398    74.08       0.005225   \n",
      "2     0.7456      0.7869         4.585    94.03       0.006150   \n",
      "3     0.4956      1.1560         3.445    27.23       0.009110   \n",
      "4     0.7572      0.7813         5.438    94.44       0.011490   \n",
      "\n",
      "   compactness_se  concavity_se  concave points_se  symmetry_se  \\\n",
      "0         0.04904       0.05373            0.01587      0.03003   \n",
      "1         0.01308       0.01860            0.01340      0.01389   \n",
      "2         0.04006       0.03832            0.02058      0.02250   \n",
      "3         0.07458       0.05661            0.01867      0.05963   \n",
      "4         0.02461       0.05688            0.01885      0.01756   \n",
      "\n",
      "   fractal_dimension_se  \n",
      "0              0.006193  \n",
      "1              0.003532  \n",
      "2              0.004571  \n",
      "3              0.009208  \n",
      "4              0.005115   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 3 categories: models can perform differently based on which data we feed them!\n",
    "data_breast_means = data_breast_cancer[data_breast_cancer.columns[0: 10]].copy()\n",
    "data_breast_worst = data_breast_cancer[data_breast_cancer.columns[-10: -1]].copy()\n",
    "data_breast_se = data_breast_cancer[data_breast_cancer.columns[10: -10]].copy()\n",
    "print(\"Means: \\n\", data_breast_means.head(), \"\\n\")\n",
    "print(\"Worst: \\n\", data_breast_worst.head(), \"\\n\")\n",
    "print(\"SE: \\n\", data_breast_se.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train + test set using KFold strategy. But really?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from python_src.sandbox import FullReport\n",
    "from time import time\n",
    "\n",
    "# Make a new kfold split and train/test a model\n",
    "def SplitWithKFold(fit_fun):\n",
    "    # Default splits into 5 folds\n",
    "    kf = KFold()\n",
    "    print(kf)\n",
    "    kfsplit = kf.split(data_breast_cancer)\n",
    "\n",
    "    i = 0\n",
    "    for idx_train, idx_test in kfsplit:\n",
    "        print(\"Test set: \", idx_test[0], \" to: \", idx_test[-1])\n",
    "        X_train, y_train = data_breast_cancer.iloc[idx_train], y_all[idx_train]\n",
    "        X_test, y_test = data_breast_cancer.iloc[idx_test], y_all[idx_test]\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "\n",
    "\n",
    "        # Train model\n",
    "\n",
    "# Just a container for the data\n",
    "class Data:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) -> None:\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_breast_cancer, y_all, test_size = 0.25, shuffle=True)\n",
    "data = Data(X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "def doGridSearch(data: Data, model, tuning_parameters: dict):\n",
    "\n",
    "    def trainAndReport(gridcv, data: Data):\n",
    "        start = time()\n",
    "        gridcv.fit(data.x_train, data.y_train)\n",
    "        t = time() - start\n",
    "\n",
    "        b0, m0 = FullReport(gridcv, data.x_test, data.y_test, t)\n",
    "        print('OK(grid-search)')\n",
    "        return b0, m0\n",
    "\n",
    "    grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV_layers,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "    scores = trainAndReport(grid_tuned, data)\n",
    "\n",
    "    return scores\n",
    "\n",
    "CV_layers = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test SGDClassifier using GridSearchCV just as we did in O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "SEARCH TIME: 496.00 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\tbest 'f1_micro' score=0.9109165526675786\n",
      "\tbest index=8\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(max_iter=100000, penalty='elasticnet', tol=0.0001)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.826 (+/-0.197) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[ 1]: 0.836 (+/-0.192) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[ 2]: 0.890 (+/-0.064) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[ 3]: 0.866 (+/-0.116) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[ 4]: 0.833 (+/-0.076) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[ 5]: 0.887 (+/-0.070) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[ 6]: 0.887 (+/-0.060) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[ 7]: 0.883 (+/-0.065) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[ 8]: 0.911 (+/-0.070) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[ 9]: 0.820 (+/-0.252) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[10]: 0.852 (+/-0.053) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[11]: 0.873 (+/-0.058) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[12]: 0.864 (+/-0.124) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[13]: 0.840 (+/-0.205) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[14]: 0.836 (+/-0.116) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[15]: 0.878 (+/-0.104) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[16]: 0.862 (+/-0.078) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[17]: 0.847 (+/-0.084) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[18]: 0.897 (+/-0.079) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[19]: 0.876 (+/-0.032) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[20]: 0.894 (+/-0.084) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[21]: 0.894 (+/-0.073) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[22]: 0.887 (+/-0.062) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[23]: 0.859 (+/-0.059) for {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[24]: 0.803 (+/-0.215) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[25]: 0.778 (+/-0.292) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[26]: 0.843 (+/-0.178) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[27]: 0.852 (+/-0.118) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[28]: 0.887 (+/-0.092) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[29]: 0.871 (+/-0.084) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[30]: 0.890 (+/-0.068) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[31]: 0.911 (+/-0.085) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[32]: 0.838 (+/-0.123) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[33]: 0.843 (+/-0.084) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[34]: 0.746 (+/-0.292) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[35]: 0.810 (+/-0.224) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[36]: 0.883 (+/-0.116) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[37]: 0.824 (+/-0.181) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[38]: 0.871 (+/-0.083) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[39]: 0.899 (+/-0.081) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[40]: 0.864 (+/-0.110) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[41]: 0.890 (+/-0.063) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[42]: 0.892 (+/-0.093) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[43]: 0.880 (+/-0.069) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[44]: 0.885 (+/-0.072) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[45]: 0.840 (+/-0.073) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[46]: 0.814 (+/-0.170) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[47]: 0.857 (+/-0.100) for {'alpha': 0.0001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[48]: 0.854 (+/-0.138) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[49]: 0.845 (+/-0.139) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[50]: 0.871 (+/-0.131) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[51]: 0.852 (+/-0.064) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[52]: 0.899 (+/-0.065) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[53]: 0.876 (+/-0.076) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[54]: 0.869 (+/-0.055) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[55]: 0.901 (+/-0.081) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[56]: 0.866 (+/-0.100) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[57]: 0.864 (+/-0.134) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[58]: 0.850 (+/-0.095) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[59]: 0.885 (+/-0.046) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[60]: 0.864 (+/-0.069) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[61]: 0.902 (+/-0.091) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[62]: 0.847 (+/-0.091) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[63]: 0.866 (+/-0.069) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[64]: 0.869 (+/-0.085) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[65]: 0.892 (+/-0.101) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[66]: 0.876 (+/-0.062) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[67]: 0.883 (+/-0.066) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[68]: 0.868 (+/-0.104) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[69]: 0.880 (+/-0.085) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[70]: 0.838 (+/-0.147) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[71]: 0.859 (+/-0.117) for {'alpha': 0.0001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[72]: 0.897 (+/-0.023) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[73]: 0.885 (+/-0.069) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[74]: 0.838 (+/-0.248) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[75]: 0.878 (+/-0.106) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[76]: 0.831 (+/-0.184) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[77]: 0.897 (+/-0.057) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[78]: 0.843 (+/-0.068) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[79]: 0.906 (+/-0.077) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[80]: 0.864 (+/-0.097) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[81]: 0.850 (+/-0.128) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[82]: 0.808 (+/-0.234) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[83]: 0.854 (+/-0.198) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[84]: 0.859 (+/-0.079) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[85]: 0.876 (+/-0.116) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[86]: 0.749 (+/-0.327) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[87]: 0.892 (+/-0.090) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[88]: 0.880 (+/-0.113) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[89]: 0.902 (+/-0.081) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[90]: 0.890 (+/-0.081) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[91]: 0.890 (+/-0.057) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[92]: 0.883 (+/-0.107) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[93]: 0.787 (+/-0.153) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[94]: 0.819 (+/-0.215) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[95]: 0.880 (+/-0.062) for {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[96]: 0.558 (+/-0.198) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[97]: 0.474 (+/-0.244) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[98]: 0.529 (+/-0.252) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[99]: 0.524 (+/-0.244) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[100]: 0.526 (+/-0.244) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[101]: 0.472 (+/-0.238) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[102]: 0.376 (+/-0.004) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[103]: 0.561 (+/-0.191) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[104]: 0.476 (+/-0.244) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[105]: 0.591 (+/-0.225) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[106]: 0.591 (+/-0.224) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[107]: 0.575 (+/-0.199) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[108]: 0.526 (+/-0.244) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[109]: 0.523 (+/-0.249) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[110]: 0.510 (+/-0.282) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[111]: 0.524 (+/-0.244) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[112]: 0.474 (+/-0.244) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[113]: 0.425 (+/-0.199) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[114]: 0.524 (+/-0.244) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[115]: 0.467 (+/-0.256) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[116]: 0.436 (+/-0.238) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[117]: 0.460 (+/-0.271) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[118]: 0.516 (+/-0.233) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[119]: 0.611 (+/-0.280) for {'alpha': 0.0001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[120]: 0.472 (+/-0.238) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[121]: 0.575 (+/-0.199) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[122]: 0.625 (+/-0.323) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[123]: 0.587 (+/-0.215) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[124]: 0.493 (+/-0.227) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[125]: 0.425 (+/-0.199) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[126]: 0.457 (+/-0.307) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[127]: 0.423 (+/-0.201) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[128]: 0.415 (+/-0.400) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[129]: 0.488 (+/-0.267) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[130]: 0.526 (+/-0.244) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[131]: 0.481 (+/-0.266) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[132]: 0.604 (+/-0.255) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[133]: 0.641 (+/-0.367) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[134]: 0.609 (+/-0.280) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[135]: 0.425 (+/-0.199) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[136]: 0.528 (+/-0.416) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[137]: 0.444 (+/-0.274) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[138]: 0.432 (+/-0.194) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[139]: 0.430 (+/-0.375) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[140]: 0.476 (+/-0.244) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[141]: 0.476 (+/-0.244) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[142]: 0.613 (+/-0.254) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[143]: 0.458 (+/-0.210) for {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[144]: 0.815 (+/-0.169) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[145]: 0.819 (+/-0.199) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[146]: 0.873 (+/-0.096) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[147]: 0.800 (+/-0.204) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[148]: 0.894 (+/-0.077) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[149]: 0.911 (+/-0.082) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[150]: 0.880 (+/-0.097) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[151]: 0.887 (+/-0.096) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[152]: 0.850 (+/-0.164) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[153]: 0.854 (+/-0.115) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[154]: 0.887 (+/-0.091) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[155]: 0.894 (+/-0.065) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[156]: 0.873 (+/-0.090) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[157]: 0.756 (+/-0.274) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[158]: 0.854 (+/-0.164) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[159]: 0.786 (+/-0.210) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[160]: 0.880 (+/-0.080) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[161]: 0.866 (+/-0.071) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[162]: 0.906 (+/-0.089) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[163]: 0.869 (+/-0.078) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[164]: 0.847 (+/-0.128) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[165]: 0.873 (+/-0.070) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[166]: 0.876 (+/-0.114) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[167]: 0.883 (+/-0.094) for {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[168]: 0.883 (+/-0.096) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[169]: 0.876 (+/-0.074) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[170]: 0.843 (+/-0.128) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[171]: 0.908 (+/-0.045) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[172]: 0.899 (+/-0.087) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[173]: 0.906 (+/-0.065) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[174]: 0.908 (+/-0.056) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[175]: 0.880 (+/-0.087) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[176]: 0.901 (+/-0.066) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[177]: 0.725 (+/-0.219) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[178]: 0.840 (+/-0.189) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[179]: 0.859 (+/-0.084) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[180]: 0.878 (+/-0.118) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[181]: 0.817 (+/-0.153) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[182]: 0.904 (+/-0.079) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[183]: 0.838 (+/-0.103) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[184]: 0.878 (+/-0.101) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[185]: 0.901 (+/-0.096) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[186]: 0.899 (+/-0.066) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[187]: 0.899 (+/-0.082) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[188]: 0.906 (+/-0.068) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[189]: 0.869 (+/-0.091) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[190]: 0.852 (+/-0.068) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[191]: 0.871 (+/-0.095) for {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[192]: 0.876 (+/-0.041) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[193]: 0.838 (+/-0.188) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[194]: 0.793 (+/-0.269) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[195]: 0.887 (+/-0.070) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[196]: 0.885 (+/-0.116) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[197]: 0.892 (+/-0.103) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[198]: 0.894 (+/-0.090) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[199]: 0.885 (+/-0.093) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[200]: 0.878 (+/-0.106) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[201]: 0.836 (+/-0.145) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[202]: 0.838 (+/-0.096) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[203]: 0.854 (+/-0.063) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[204]: 0.859 (+/-0.107) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[205]: 0.838 (+/-0.067) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[206]: 0.800 (+/-0.108) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[207]: 0.840 (+/-0.066) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[208]: 0.897 (+/-0.054) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[209]: 0.887 (+/-0.090) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[210]: 0.894 (+/-0.073) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[211]: 0.897 (+/-0.080) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[212]: 0.836 (+/-0.192) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[213]: 0.819 (+/-0.225) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[214]: 0.869 (+/-0.052) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[215]: 0.770 (+/-0.241) for {'alpha': 0.001, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[216]: 0.840 (+/-0.214) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[217]: 0.878 (+/-0.050) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[218]: 0.892 (+/-0.085) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[219]: 0.869 (+/-0.085) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[220]: 0.883 (+/-0.054) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[221]: 0.901 (+/-0.092) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[222]: 0.892 (+/-0.053) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[223]: 0.899 (+/-0.075) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[224]: 0.843 (+/-0.157) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[225]: 0.819 (+/-0.205) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[226]: 0.866 (+/-0.126) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[227]: 0.852 (+/-0.074) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[228]: 0.880 (+/-0.074) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[229]: 0.786 (+/-0.178) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[230]: 0.876 (+/-0.068) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[231]: 0.814 (+/-0.228) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[232]: 0.880 (+/-0.084) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[233]: 0.892 (+/-0.083) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[234]: 0.892 (+/-0.085) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[235]: 0.897 (+/-0.093) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[236]: 0.876 (+/-0.038) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[237]: 0.805 (+/-0.245) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[238]: 0.873 (+/-0.086) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[239]: 0.883 (+/-0.149) for {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[240]: 0.575 (+/-0.199) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[241]: 0.477 (+/-0.249) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[242]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[243]: 0.577 (+/-0.201) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[244]: 0.570 (+/-0.195) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[245]: 0.406 (+/-0.229) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[246]: 0.420 (+/-0.203) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[247]: 0.406 (+/-0.123) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[248]: 0.478 (+/-0.250) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[249]: 0.577 (+/-0.201) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[250]: 0.524 (+/-0.244) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[251]: 0.370 (+/-0.460) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[252]: 0.561 (+/-0.335) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[253]: 0.573 (+/-0.208) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[254]: 0.618 (+/-0.301) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[255]: 0.376 (+/-0.004) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[256]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[257]: 0.523 (+/-0.249) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[258]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[259]: 0.533 (+/-0.262) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[260]: 0.471 (+/-0.243) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[261]: 0.469 (+/-0.257) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[262]: 0.669 (+/-0.178) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[263]: 0.376 (+/-0.004) for {'alpha': 0.001, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[264]: 0.575 (+/-0.199) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[265]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[266]: 0.476 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[267]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[268]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[269]: 0.608 (+/-0.265) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[270]: 0.455 (+/-0.203) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[271]: 0.423 (+/-0.201) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[272]: 0.478 (+/-0.250) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[273]: 0.526 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[274]: 0.526 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[275]: 0.554 (+/-0.315) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[276]: 0.425 (+/-0.199) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[277]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[278]: 0.570 (+/-0.217) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[279]: 0.526 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[280]: 0.373 (+/-0.009) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[281]: 0.624 (+/-0.004) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[282]: 0.521 (+/-0.236) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[283]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[284]: 0.580 (+/-0.204) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[285]: 0.366 (+/-0.037) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[286]: 0.458 (+/-0.266) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[287]: 0.474 (+/-0.244) for {'alpha': 0.001, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[288]: 0.771 (+/-0.297) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[289]: 0.843 (+/-0.239) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[290]: 0.800 (+/-0.206) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[291]: 0.866 (+/-0.084) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[292]: 0.887 (+/-0.088) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[293]: 0.908 (+/-0.104) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[294]: 0.880 (+/-0.079) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[295]: 0.859 (+/-0.068) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[296]: 0.871 (+/-0.085) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[297]: 0.850 (+/-0.218) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[298]: 0.839 (+/-0.231) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[299]: 0.852 (+/-0.069) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[300]: 0.883 (+/-0.097) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[301]: 0.866 (+/-0.061) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[302]: 0.861 (+/-0.097) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[303]: 0.852 (+/-0.161) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[304]: 0.892 (+/-0.092) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[305]: 0.880 (+/-0.095) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[306]: 0.892 (+/-0.100) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[307]: 0.883 (+/-0.086) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[308]: 0.843 (+/-0.177) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[309]: 0.892 (+/-0.031) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[310]: 0.871 (+/-0.121) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[311]: 0.897 (+/-0.075) for {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[312]: 0.833 (+/-0.224) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[313]: 0.829 (+/-0.220) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[314]: 0.880 (+/-0.089) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[315]: 0.854 (+/-0.075) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[316]: 0.873 (+/-0.069) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[317]: 0.873 (+/-0.090) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[318]: 0.899 (+/-0.094) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[319]: 0.880 (+/-0.092) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[320]: 0.873 (+/-0.088) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[321]: 0.815 (+/-0.304) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[322]: 0.838 (+/-0.172) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[323]: 0.864 (+/-0.142) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[324]: 0.850 (+/-0.148) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[325]: 0.908 (+/-0.083) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[326]: 0.845 (+/-0.110) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[327]: 0.819 (+/-0.114) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[328]: 0.892 (+/-0.096) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[329]: 0.901 (+/-0.108) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[330]: 0.894 (+/-0.085) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[331]: 0.887 (+/-0.085) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[332]: 0.833 (+/-0.253) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[333]: 0.831 (+/-0.192) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[334]: 0.774 (+/-0.203) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[335]: 0.890 (+/-0.057) for {'alpha': 0.01, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[336]: 0.885 (+/-0.093) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[337]: 0.859 (+/-0.109) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[338]: 0.892 (+/-0.047) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[339]: 0.782 (+/-0.321) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[340]: 0.885 (+/-0.091) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[341]: 0.887 (+/-0.077) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[342]: 0.901 (+/-0.084) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[343]: 0.894 (+/-0.100) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[344]: 0.829 (+/-0.139) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[345]: 0.803 (+/-0.143) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[346]: 0.862 (+/-0.099) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[347]: 0.742 (+/-0.300) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[348]: 0.866 (+/-0.124) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[349]: 0.864 (+/-0.120) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[350]: 0.876 (+/-0.062) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[351]: 0.805 (+/-0.217) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[352]: 0.897 (+/-0.090) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[353]: 0.890 (+/-0.087) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[354]: 0.901 (+/-0.091) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[355]: 0.885 (+/-0.097) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[356]: 0.890 (+/-0.078) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[357]: 0.887 (+/-0.041) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[358]: 0.864 (+/-0.083) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[359]: 0.871 (+/-0.049) for {'alpha': 0.01, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[360]: 0.864 (+/-0.094) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[361]: 0.880 (+/-0.075) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[362]: 0.854 (+/-0.089) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[363]: 0.803 (+/-0.303) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[364]: 0.894 (+/-0.098) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[365]: 0.876 (+/-0.075) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[366]: 0.894 (+/-0.096) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[367]: 0.890 (+/-0.068) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[368]: 0.901 (+/-0.066) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[369]: 0.885 (+/-0.048) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[370]: 0.890 (+/-0.110) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[371]: 0.859 (+/-0.083) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[372]: 0.847 (+/-0.144) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[373]: 0.880 (+/-0.091) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[374]: 0.871 (+/-0.096) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[375]: 0.857 (+/-0.091) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[376]: 0.892 (+/-0.101) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[377]: 0.890 (+/-0.094) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[378]: 0.873 (+/-0.091) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[379]: 0.885 (+/-0.091) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[380]: 0.871 (+/-0.057) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[381]: 0.883 (+/-0.041) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[382]: 0.890 (+/-0.072) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[383]: 0.855 (+/-0.139) for {'alpha': 0.01, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[384]: 0.624 (+/-0.004) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[385]: 0.446 (+/-0.307) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[386]: 0.575 (+/-0.199) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[387]: 0.474 (+/-0.244) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[388]: 0.575 (+/-0.199) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[389]: 0.526 (+/-0.244) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[390]: 0.427 (+/-0.196) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[391]: 0.608 (+/-0.270) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[392]: 0.470 (+/-0.242) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[393]: 0.526 (+/-0.244) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[394]: 0.425 (+/-0.199) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[395]: 0.575 (+/-0.199) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[396]: 0.624 (+/-0.004) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[397]: 0.526 (+/-0.244) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[398]: 0.437 (+/-0.189) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[399]: 0.441 (+/-0.213) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[400]: 0.535 (+/-0.217) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[401]: 0.474 (+/-0.244) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[402]: 0.474 (+/-0.244) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[403]: 0.425 (+/-0.199) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[404]: 0.543 (+/-0.330) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[405]: 0.474 (+/-0.253) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[406]: 0.524 (+/-0.244) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[407]: 0.476 (+/-0.244) for {'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[408]: 0.333 (+/-0.169) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[409]: 0.575 (+/-0.364) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[410]: 0.545 (+/-0.289) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[411]: 0.442 (+/-0.445) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[412]: 0.526 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[413]: 0.479 (+/-0.236) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[414]: 0.456 (+/-0.206) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[415]: 0.474 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[416]: 0.476 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[417]: 0.627 (+/-0.009) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[418]: 0.476 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[419]: 0.476 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[420]: 0.573 (+/-0.201) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[421]: 0.420 (+/-0.180) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[422]: 0.524 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[423]: 0.523 (+/-0.240) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[424]: 0.474 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[425]: 0.476 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[426]: 0.486 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[427]: 0.425 (+/-0.199) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[428]: 0.481 (+/-0.256) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[429]: 0.571 (+/-0.210) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[430]: 0.526 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[431]: 0.526 (+/-0.244) for {'alpha': 0.01, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[432]: 0.876 (+/-0.120) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[433]: 0.908 (+/-0.050) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[434]: 0.826 (+/-0.231) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[435]: 0.878 (+/-0.108) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[436]: 0.871 (+/-0.097) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[437]: 0.890 (+/-0.086) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[438]: 0.868 (+/-0.077) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[439]: 0.892 (+/-0.074) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[440]: 0.887 (+/-0.108) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[441]: 0.810 (+/-0.207) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[442]: 0.866 (+/-0.081) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[443]: 0.850 (+/-0.183) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[444]: 0.890 (+/-0.088) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[445]: 0.866 (+/-0.136) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[446]: 0.887 (+/-0.107) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[447]: 0.812 (+/-0.338) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[448]: 0.890 (+/-0.080) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[449]: 0.885 (+/-0.082) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[450]: 0.885 (+/-0.114) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[451]: 0.894 (+/-0.079) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[452]: 0.838 (+/-0.199) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[453]: 0.852 (+/-0.160) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[454]: 0.847 (+/-0.109) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[455]: 0.869 (+/-0.090) for {'alpha': 0.1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[456]: 0.895 (+/-0.079) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[457]: 0.810 (+/-0.289) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[458]: 0.826 (+/-0.235) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[459]: 0.845 (+/-0.119) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[460]: 0.899 (+/-0.078) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[461]: 0.890 (+/-0.084) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[462]: 0.890 (+/-0.097) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[463]: 0.897 (+/-0.084) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[464]: 0.876 (+/-0.077) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[465]: 0.869 (+/-0.098) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[466]: 0.899 (+/-0.088) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[467]: 0.871 (+/-0.105) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[468]: 0.897 (+/-0.080) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[469]: 0.826 (+/-0.252) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[470]: 0.754 (+/-0.345) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[471]: 0.831 (+/-0.197) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[472]: 0.883 (+/-0.065) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[473]: 0.899 (+/-0.108) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[474]: 0.885 (+/-0.079) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[475]: 0.897 (+/-0.083) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[476]: 0.864 (+/-0.095) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[477]: 0.857 (+/-0.129) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[478]: 0.871 (+/-0.105) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[479]: 0.833 (+/-0.063) for {'alpha': 0.1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[480]: 0.890 (+/-0.125) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[481]: 0.852 (+/-0.182) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[482]: 0.892 (+/-0.067) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[483]: 0.866 (+/-0.044) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[484]: 0.869 (+/-0.062) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[485]: 0.892 (+/-0.072) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[486]: 0.883 (+/-0.062) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[487]: 0.883 (+/-0.084) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[488]: 0.817 (+/-0.151) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[489]: 0.897 (+/-0.068) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[490]: 0.850 (+/-0.235) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[491]: 0.878 (+/-0.036) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[492]: 0.871 (+/-0.108) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[493]: 0.862 (+/-0.095) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[494]: 0.878 (+/-0.093) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[495]: 0.892 (+/-0.088) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[496]: 0.897 (+/-0.078) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[497]: 0.878 (+/-0.106) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[498]: 0.887 (+/-0.089) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[499]: 0.890 (+/-0.097) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[500]: 0.871 (+/-0.070) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[501]: 0.899 (+/-0.032) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[502]: 0.904 (+/-0.065) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[503]: 0.906 (+/-0.064) for {'alpha': 0.1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[504]: 0.878 (+/-0.094) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[505]: 0.850 (+/-0.106) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[506]: 0.829 (+/-0.145) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[507]: 0.871 (+/-0.071) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[508]: 0.892 (+/-0.077) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[509]: 0.883 (+/-0.093) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[510]: 0.883 (+/-0.099) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[511]: 0.876 (+/-0.084) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[512]: 0.899 (+/-0.046) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[513]: 0.855 (+/-0.114) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[514]: 0.883 (+/-0.050) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[515]: 0.897 (+/-0.087) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[516]: 0.878 (+/-0.087) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[517]: 0.864 (+/-0.129) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[518]: 0.897 (+/-0.057) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[519]: 0.817 (+/-0.049) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[520]: 0.880 (+/-0.069) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[521]: 0.880 (+/-0.089) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[522]: 0.897 (+/-0.098) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[523]: 0.876 (+/-0.077) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[524]: 0.805 (+/-0.131) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[525]: 0.848 (+/-0.184) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[526]: 0.866 (+/-0.102) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[527]: 0.890 (+/-0.099) for {'alpha': 0.1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[528]: 0.303 (+/-0.227) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[529]: 0.570 (+/-0.194) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[530]: 0.446 (+/-0.315) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[531]: 0.432 (+/-0.193) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[532]: 0.425 (+/-0.199) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[533]: 0.467 (+/-0.179) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[534]: 0.540 (+/-0.244) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[535]: 0.486 (+/-0.195) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[536]: 0.512 (+/-0.297) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[537]: 0.481 (+/-0.277) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[538]: 0.463 (+/-0.218) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[539]: 0.523 (+/-0.249) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[540]: 0.615 (+/-0.284) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[541]: 0.427 (+/-0.201) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[542]: 0.371 (+/-0.328) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[543]: 0.514 (+/-0.282) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[544]: 0.486 (+/-0.241) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[545]: 0.519 (+/-0.193) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[546]: 0.427 (+/-0.196) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[547]: 0.446 (+/-0.168) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[548]: 0.530 (+/-0.252) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[549]: 0.444 (+/-0.193) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[550]: 0.474 (+/-0.244) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[551]: 0.519 (+/-0.239) for {'alpha': 0.1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[552]: 0.489 (+/-0.282) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[553]: 0.528 (+/-0.238) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[554]: 0.484 (+/-0.534) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[555]: 0.458 (+/-0.266) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[556]: 0.543 (+/-0.283) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[557]: 0.526 (+/-0.248) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[558]: 0.524 (+/-0.244) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[559]: 0.624 (+/-0.004) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[560]: 0.498 (+/-0.310) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[561]: 0.524 (+/-0.244) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[562]: 0.575 (+/-0.199) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[563]: 0.425 (+/-0.199) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[564]: 0.512 (+/-0.226) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[565]: 0.510 (+/-0.348) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[566]: 0.561 (+/-0.197) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[567]: 0.476 (+/-0.244) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[568]: 0.429 (+/-0.210) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[569]: 0.472 (+/-0.238) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[570]: 0.479 (+/-0.241) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[571]: 0.575 (+/-0.199) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[572]: 0.526 (+/-0.405) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[573]: 0.425 (+/-0.199) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[574]: 0.514 (+/-0.245) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[575]: 0.524 (+/-0.244) for {'alpha': 0.1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[576]: 0.756 (+/-0.312) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[577]: 0.866 (+/-0.143) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[578]: 0.869 (+/-0.127) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[579]: 0.817 (+/-0.204) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[580]: 0.892 (+/-0.075) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[581]: 0.908 (+/-0.046) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[582]: 0.894 (+/-0.088) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[583]: 0.883 (+/-0.099) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[584]: 0.897 (+/-0.078) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[585]: 0.876 (+/-0.057) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[586]: 0.822 (+/-0.101) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[587]: 0.852 (+/-0.049) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[588]: 0.796 (+/-0.233) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[589]: 0.881 (+/-0.136) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[590]: 0.813 (+/-0.240) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[591]: 0.796 (+/-0.188) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[592]: 0.868 (+/-0.057) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[593]: 0.866 (+/-0.109) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[594]: 0.892 (+/-0.049) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[595]: 0.875 (+/-0.112) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[596]: 0.850 (+/-0.066) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[597]: 0.873 (+/-0.101) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[598]: 0.894 (+/-0.061) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[599]: 0.847 (+/-0.116) for {'alpha': 1, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[600]: 0.862 (+/-0.099) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[601]: 0.845 (+/-0.224) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[602]: 0.824 (+/-0.192) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[603]: 0.864 (+/-0.057) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[604]: 0.875 (+/-0.089) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[605]: 0.878 (+/-0.074) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[606]: 0.890 (+/-0.120) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[607]: 0.871 (+/-0.105) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[608]: 0.885 (+/-0.077) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[609]: 0.852 (+/-0.097) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[610]: 0.904 (+/-0.083) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[611]: 0.904 (+/-0.093) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[612]: 0.817 (+/-0.128) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[613]: 0.876 (+/-0.083) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[614]: 0.843 (+/-0.049) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[615]: 0.833 (+/-0.237) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[616]: 0.890 (+/-0.102) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[617]: 0.880 (+/-0.107) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[618]: 0.883 (+/-0.055) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[619]: 0.892 (+/-0.096) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[620]: 0.840 (+/-0.024) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[621]: 0.906 (+/-0.042) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[622]: 0.845 (+/-0.117) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[623]: 0.859 (+/-0.102) for {'alpha': 1, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[624]: 0.880 (+/-0.035) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[625]: 0.897 (+/-0.085) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[626]: 0.887 (+/-0.041) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[627]: 0.831 (+/-0.097) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[628]: 0.880 (+/-0.108) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[629]: 0.878 (+/-0.096) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[630]: 0.887 (+/-0.114) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[631]: 0.883 (+/-0.081) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[632]: 0.887 (+/-0.050) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[633]: 0.866 (+/-0.032) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[634]: 0.864 (+/-0.108) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[635]: 0.854 (+/-0.085) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[636]: 0.864 (+/-0.057) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[637]: 0.871 (+/-0.096) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[638]: 0.784 (+/-0.207) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[639]: 0.832 (+/-0.233) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[640]: 0.871 (+/-0.079) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[641]: 0.871 (+/-0.098) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[642]: 0.885 (+/-0.105) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[643]: 0.883 (+/-0.080) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[644]: 0.887 (+/-0.075) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[645]: 0.869 (+/-0.104) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[646]: 0.883 (+/-0.020) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[647]: 0.871 (+/-0.107) for {'alpha': 1, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[648]: 0.796 (+/-0.214) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[649]: 0.852 (+/-0.107) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[650]: 0.866 (+/-0.090) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[651]: 0.827 (+/-0.153) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[652]: 0.878 (+/-0.090) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[653]: 0.885 (+/-0.066) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[654]: 0.885 (+/-0.079) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[655]: 0.871 (+/-0.086) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[656]: 0.899 (+/-0.084) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[657]: 0.857 (+/-0.182) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[658]: 0.880 (+/-0.035) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[659]: 0.883 (+/-0.133) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[660]: 0.894 (+/-0.074) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[661]: 0.847 (+/-0.026) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[662]: 0.864 (+/-0.115) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[663]: 0.864 (+/-0.146) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[664]: 0.890 (+/-0.095) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[665]: 0.878 (+/-0.053) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[666]: 0.873 (+/-0.046) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[667]: 0.880 (+/-0.070) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[668]: 0.862 (+/-0.177) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[669]: 0.911 (+/-0.057) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[670]: 0.908 (+/-0.037) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[671]: 0.880 (+/-0.091) for {'alpha': 1, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[672]: 0.526 (+/-0.396) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[673]: 0.474 (+/-0.244) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[674]: 0.570 (+/-0.195) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[675]: 0.507 (+/-0.289) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[676]: 0.563 (+/-0.195) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[677]: 0.507 (+/-0.208) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[678]: 0.526 (+/-0.235) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[679]: 0.489 (+/-0.207) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[680]: 0.575 (+/-0.199) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[681]: 0.414 (+/-0.361) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[682]: 0.390 (+/-0.334) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[683]: 0.535 (+/-0.222) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[684]: 0.526 (+/-0.244) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[685]: 0.481 (+/-0.380) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[686]: 0.474 (+/-0.244) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[687]: 0.373 (+/-0.009) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[688]: 0.516 (+/-0.252) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[689]: 0.495 (+/-0.206) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[690]: 0.470 (+/-0.242) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[691]: 0.456 (+/-0.176) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[692]: 0.476 (+/-0.244) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[693]: 0.521 (+/-0.255) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[694]: 0.624 (+/-0.004) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[695]: 0.629 (+/-0.022) for {'alpha': 1, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[696]: 0.570 (+/-0.325) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[697]: 0.643 (+/-0.308) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[698]: 0.612 (+/-0.278) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[699]: 0.427 (+/-0.196) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[700]: 0.524 (+/-0.244) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[701]: 0.524 (+/-0.244) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[702]: 0.624 (+/-0.004) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[703]: 0.575 (+/-0.199) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[704]: 0.526 (+/-0.244) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[705]: 0.547 (+/-0.403) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[706]: 0.477 (+/-0.249) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[707]: 0.540 (+/-0.271) for {'alpha': 1, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[708]: 0.714 (+/-0.222) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[709]: 0.648 (+/-0.049) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[710]: 0.544 (+/-0.230) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[711]: 0.629 (+/-0.328) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[712]: 0.526 (+/-0.248) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[713]: 0.596 (+/-0.234) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[714]: 0.526 (+/-0.244) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[715]: 0.575 (+/-0.199) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[716]: 0.479 (+/-0.250) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[717]: 0.596 (+/-0.234) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[718]: 0.533 (+/-0.430) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[719]: 0.427 (+/-0.201) for {'alpha': 1, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[720]: 0.894 (+/-0.085) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[721]: 0.822 (+/-0.375) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[722]: 0.871 (+/-0.100) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[723]: 0.838 (+/-0.187) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[724]: 0.474 (+/-0.244) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[725]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[726]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[727]: 0.573 (+/-0.201) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[728]: 0.427 (+/-0.201) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[729]: 0.476 (+/-0.244) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[730]: 0.616 (+/-0.294) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[731]: 0.477 (+/-0.240) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[732]: 0.859 (+/-0.119) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[733]: 0.897 (+/-0.064) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[734]: 0.864 (+/-0.077) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[735]: 0.887 (+/-0.115) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[736]: 0.376 (+/-0.004) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[737]: 0.624 (+/-0.004) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[738]: 0.474 (+/-0.244) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[739]: 0.624 (+/-0.004) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[740]: 0.528 (+/-0.247) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[741]: 0.540 (+/-0.210) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[742]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[743]: 0.474 (+/-0.244) for {'alpha': 100, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[744]: 0.887 (+/-0.093) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[745]: 0.850 (+/-0.096) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[746]: 0.861 (+/-0.076) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[747]: 0.862 (+/-0.099) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[748]: 0.474 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[749]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[750]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[751]: 0.624 (+/-0.004) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[752]: 0.490 (+/-0.227) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[753]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[754]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[755]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[756]: 0.843 (+/-0.070) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[757]: 0.890 (+/-0.073) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[758]: 0.833 (+/-0.074) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[759]: 0.897 (+/-0.062) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[760]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[761]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[762]: 0.474 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[763]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[764]: 0.634 (+/-0.328) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[765]: 0.573 (+/-0.201) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[766]: 0.425 (+/-0.199) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[767]: 0.474 (+/-0.244) for {'alpha': 100, 'loss': 'log_loss', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[768]: 0.859 (+/-0.052) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[769]: 0.836 (+/-0.207) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[770]: 0.838 (+/-0.190) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[771]: 0.848 (+/-0.081) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[772]: 0.575 (+/-0.199) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[773]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[774]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[775]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[776]: 0.716 (+/-0.377) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[777]: 0.655 (+/-0.315) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[778]: 0.525 (+/-0.342) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[779]: 0.514 (+/-0.202) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[780]: 0.880 (+/-0.051) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[781]: 0.871 (+/-0.033) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[782]: 0.878 (+/-0.061) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[783]: 0.857 (+/-0.093) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[784]: 0.575 (+/-0.199) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[785]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[786]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[787]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[788]: 0.587 (+/-0.366) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[789]: 0.575 (+/-0.359) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[790]: 0.531 (+/-0.384) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[791]: 0.427 (+/-0.196) for {'alpha': 100, 'loss': 'perceptron', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[792]: 0.885 (+/-0.117) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[793]: 0.873 (+/-0.092) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[794]: 0.873 (+/-0.072) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[795]: 0.862 (+/-0.119) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[796]: 0.376 (+/-0.004) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[797]: 0.474 (+/-0.244) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[798]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[799]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[800]: 0.655 (+/-0.290) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[801]: 0.697 (+/-0.346) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[802]: 0.742 (+/-0.498) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[803]: 0.622 (+/-0.173) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[804]: 0.887 (+/-0.075) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[805]: 0.864 (+/-0.077) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[806]: 0.878 (+/-0.079) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[807]: 0.880 (+/-0.113) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[808]: 0.573 (+/-0.201) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[809]: 0.575 (+/-0.199) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[810]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[811]: 0.425 (+/-0.199) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[812]: 0.739 (+/-0.355) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[813]: 0.573 (+/-0.376) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[814]: 0.695 (+/-0.298) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[815]: 0.638 (+/-0.339) for {'alpha': 100, 'loss': 'modified_huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[816]: 0.620 (+/-0.194) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[817]: 0.514 (+/-0.236) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[818]: 0.352 (+/-0.455) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[819]: 0.457 (+/-0.339) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[820]: 0.495 (+/-0.123) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[821]: 0.507 (+/-0.172) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[822]: 0.462 (+/-0.260) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[823]: 0.599 (+/-0.189) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[824]: 0.399 (+/-0.078) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[825]: 0.530 (+/-0.359) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[826]: 0.507 (+/-0.297) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[827]: 0.526 (+/-0.304) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[828]: 0.540 (+/-0.417) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[829]: 0.524 (+/-0.231) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[830]: 0.441 (+/-0.147) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[831]: 0.460 (+/-0.204) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[832]: 0.489 (+/-0.180) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[833]: 0.561 (+/-0.119) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[834]: 0.500 (+/-0.213) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[835]: 0.411 (+/-0.126) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[836]: 0.486 (+/-0.376) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[837]: 0.467 (+/-0.401) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[838]: 0.397 (+/-0.170) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[839]: 0.523 (+/-0.320) for {'alpha': 100, 'loss': 'squared_error', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[840]: 0.810 (+/-0.191) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[841]: 0.758 (+/-0.144) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[842]: 0.798 (+/-0.169) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[843]: 0.732 (+/-0.106) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[844]: 0.624 (+/-0.004) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[845]: 0.575 (+/-0.199) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[846]: 0.624 (+/-0.004) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[847]: 0.575 (+/-0.199) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[848]: 0.476 (+/-0.244) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[849]: 0.575 (+/-0.199) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[850]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[851]: 0.524 (+/-0.244) for {'alpha': 100, 'loss': 'huber', 'max_iter': 100000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\t[852]: 0.817 (+/-0.131) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[853]: 0.784 (+/-0.162) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[854]: 0.824 (+/-0.237) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.01}\n",
      "\t[855]: 0.781 (+/-0.179) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l2', 'tol': 0.1}\n",
      "\t[856]: 0.575 (+/-0.199) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[857]: 0.476 (+/-0.244) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[858]: 0.476 (+/-0.244) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.01}\n",
      "\t[859]: 0.573 (+/-0.201) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'l1', 'tol': 0.1}\n",
      "\t[860]: 0.573 (+/-0.201) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[861]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[862]: 0.526 (+/-0.244) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.01}\n",
      "\t[863]: 0.575 (+/-0.199) for {'alpha': 100, 'loss': 'huber', 'max_iter': 1000000, 'penalty': 'elasticnet', 'tol': 0.1}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61        91\n",
      "           1       0.50      1.00      0.67        52\n",
      "\n",
      "    accuracy                           0.64       143\n",
      "   macro avg       0.75      0.72      0.64       143\n",
      "weighted avg       0.82      0.64      0.63       143\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(max_iter=100000, penalty='elasticnet', tol=0.0001)\n",
      "\n",
      "best: dat=N/A, score=0.91092, model=SGDClassifier(alpha=0.0001,loss='hinge',max_iter=100000,penalty='elasticnet',tol=0.0001)\n",
      "\n",
      "OK(grid-search)\n",
      "(\"best: dat=N/A, score=0.91092, model=SGDClassifier(alpha=0.0001,loss='hinge',max_iter=100000,penalty='elasticnet',tol=0.0001)\", SGDClassifier(max_iter=100000, penalty='elasticnet', tol=0.0001))\n"
     ]
    }
   ],
   "source": [
    "# Use some classifiers\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from time import time\n",
    "\n",
    "scores = {}\n",
    "\n",
    "model = SGDClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'loss': ['hinge', 'log_loss', 'perceptron', 'modified_huber', 'squared_error', 'huber'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 100],\n",
    "    'tol' : [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter' : [int(1e+5), int(1e+6)]\n",
    "}\n",
    "\n",
    "scores = doGridSearch(data, model, tuning_parameters)\n",
    "print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our SGDClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 1.45 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\tbest 'f1_micro' score=0.9461012311901505\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.946 (+/-0.050) for {'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[ 1]: 0.946 (+/-0.050) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[ 2]: 0.946 (+/-0.050) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[ 3]: 0.946 (+/-0.050) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[ 4]: 0.946 (+/-0.050) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[ 5]: 0.946 (+/-0.050) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[ 6]: 0.934 (+/-0.035) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[ 7]: 0.934 (+/-0.041) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[ 8]: 0.939 (+/-0.057) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[ 9]: 0.923 (+/-0.038) for {'alpha': 0.01, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[10]: 0.923 (+/-0.038) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[11]: 0.923 (+/-0.052) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[12]: 0.941 (+/-0.033) for {'alpha': 0.1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[13]: 0.941 (+/-0.033) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[14]: 0.941 (+/-0.033) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[15]: 0.941 (+/-0.033) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[16]: 0.941 (+/-0.033) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[17]: 0.941 (+/-0.033) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[18]: 0.934 (+/-0.035) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[19]: 0.934 (+/-0.041) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[20]: 0.939 (+/-0.057) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[21]: 0.923 (+/-0.038) for {'alpha': 0.1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[22]: 0.923 (+/-0.038) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[23]: 0.923 (+/-0.052) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[24]: 0.944 (+/-0.035) for {'alpha': 1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[25]: 0.944 (+/-0.035) for {'alpha': 1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[26]: 0.944 (+/-0.035) for {'alpha': 1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[27]: 0.944 (+/-0.035) for {'alpha': 1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[28]: 0.944 (+/-0.035) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[29]: 0.944 (+/-0.035) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[30]: 0.944 (+/-0.035) for {'alpha': 1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[31]: 0.934 (+/-0.041) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[32]: 0.939 (+/-0.057) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[33]: 0.923 (+/-0.038) for {'alpha': 1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[34]: 0.923 (+/-0.038) for {'alpha': 1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[35]: 0.923 (+/-0.052) for {'alpha': 1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[36]: 0.941 (+/-0.042) for {'alpha': 2, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[37]: 0.941 (+/-0.042) for {'alpha': 2, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[38]: 0.941 (+/-0.042) for {'alpha': 2, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[39]: 0.941 (+/-0.042) for {'alpha': 2, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[40]: 0.941 (+/-0.042) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[41]: 0.941 (+/-0.042) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[42]: 0.946 (+/-0.032) for {'alpha': 2, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[43]: 0.934 (+/-0.041) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[44]: 0.939 (+/-0.057) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[45]: 0.923 (+/-0.038) for {'alpha': 2, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[46]: 0.923 (+/-0.038) for {'alpha': 2, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[47]: 0.923 (+/-0.052) for {'alpha': 2, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[48]: 0.944 (+/-0.031) for {'alpha': 10, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[49]: 0.944 (+/-0.031) for {'alpha': 10, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[50]: 0.944 (+/-0.031) for {'alpha': 10, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[51]: 0.944 (+/-0.031) for {'alpha': 10, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[52]: 0.944 (+/-0.031) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[53]: 0.944 (+/-0.031) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[54]: 0.944 (+/-0.031) for {'alpha': 10, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[55]: 0.937 (+/-0.038) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[56]: 0.939 (+/-0.057) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[57]: 0.923 (+/-0.038) for {'alpha': 10, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[58]: 0.923 (+/-0.038) for {'alpha': 10, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[59]: 0.923 (+/-0.052) for {'alpha': 10, 'solver': 'sag', 'tol': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        91\n",
      "           1       1.00      0.94      0.97        52\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.97      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "\n",
      "CTOR for best model: RidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "best: dat=N/A, score=0.94610, model=RidgeClassifier(alpha=0.01,solver='svd',tol=1e-05)\n",
      "\n",
      "OK(grid-search)\n",
      "(\"best: dat=N/A, score=0.94610, model=RidgeClassifier(alpha=0.01,solver='svd',tol=1e-05)\", RidgeClassifier(alpha=0.01, solver='svd', tol=1e-05))\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = 0\n",
    "\n",
    "# Chosen model\n",
    "sgd = SGDClassifier(max_iter=100000, penalty='elasticnet', tol=0.0001)\n",
    "\n",
    "model = RidgeClassifier()\n",
    "tuning_parameters = {\n",
    "        'alpha' : [0.01, 0.1, 1, 2, 10],\n",
    "        'tol' : [0.00001, 0.0001, 0.001],\n",
    "        'solver' : ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "    }\n",
    "\n",
    "scores = doGridSearch(data, model, tuning_parameters)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 0.70 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'max_iter_predict': 100, 'n_restarts_optimizer': 0}\n",
      "\tbest 'f1_micro' score=0.7065116279069767\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tGaussianProcessClassifier()\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.707 (+/-0.094) for {'max_iter_predict': 100, 'n_restarts_optimizer': 0}\n",
      "\t[ 1]: 0.707 (+/-0.094) for {'max_iter_predict': 100, 'n_restarts_optimizer': 2}\n",
      "\t[ 2]: 0.707 (+/-0.094) for {'max_iter_predict': 100, 'n_restarts_optimizer': 5}\n",
      "\t[ 3]: 0.707 (+/-0.094) for {'max_iter_predict': 500, 'n_restarts_optimizer': 0}\n",
      "\t[ 4]: 0.707 (+/-0.094) for {'max_iter_predict': 500, 'n_restarts_optimizer': 2}\n",
      "\t[ 5]: 0.707 (+/-0.094) for {'max_iter_predict': 500, 'n_restarts_optimizer': 5}\n",
      "\t[ 6]: 0.707 (+/-0.094) for {'max_iter_predict': 1000, 'n_restarts_optimizer': 0}\n",
      "\t[ 7]: 0.707 (+/-0.094) for {'max_iter_predict': 1000, 'n_restarts_optimizer': 2}\n",
      "\t[ 8]: 0.707 (+/-0.094) for {'max_iter_predict': 1000, 'n_restarts_optimizer': 5}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        91\n",
      "           1       0.73      0.46      0.56        52\n",
      "\n",
      "    accuracy                           0.74       143\n",
      "   macro avg       0.74      0.68      0.69       143\n",
      "weighted avg       0.74      0.74      0.72       143\n",
      "\n",
      "\n",
      "CTOR for best model: GaussianProcessClassifier()\n",
      "\n",
      "best: dat=N/A, score=0.70651, model=GaussianProcessClassifier(max_iter_predict=100,n_restarts_optimizer=0)\n",
      "\n",
      "OK(grid-search)\n",
      "('best: dat=N/A, score=0.70651, model=GaussianProcessClassifier(max_iter_predict=100,n_restarts_optimizer=0)', GaussianProcessClassifier())\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "model = GaussianProcessClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'n_restarts_optimizer' : [0, 2, 5],\n",
    "    'max_iter_predict' : [100, 500, 1000]\n",
    "}\n",
    "\n",
    "scores = doGridSearch(data, model, tuning_parameters)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian classifier is clearly very poor choice for this task with a score of 0.723, we will skip it.\n",
    "\n",
    "Next, we'll try a DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 0.98 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\tbest 'f1_micro' score=0.9366073871409029\n",
      "\tbest index=16\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tDecisionTreeClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=5)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.911 (+/-0.046) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[ 1]: 0.906 (+/-0.047) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[ 2]: 0.906 (+/-0.047) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[ 3]: 0.906 (+/-0.047) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[ 4]: 0.906 (+/-0.047) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[ 5]: 0.906 (+/-0.047) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[ 6]: 0.906 (+/-0.047) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[ 7]: 0.911 (+/-0.046) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[ 8]: 0.911 (+/-0.046) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[ 9]: 0.906 (+/-0.076) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[10]: 0.911 (+/-0.076) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[11]: 0.906 (+/-0.076) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\t[12]: 0.932 (+/-0.041) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[13]: 0.927 (+/-0.018) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[14]: 0.930 (+/-0.047) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[15]: 0.932 (+/-0.028) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[16]: 0.937 (+/-0.046) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[17]: 0.934 (+/-0.038) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[18]: 0.930 (+/-0.056) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[19]: 0.927 (+/-0.062) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[20]: 0.930 (+/-0.056) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[21]: 0.911 (+/-0.076) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[22]: 0.908 (+/-0.075) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[23]: 0.911 (+/-0.076) for {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\t[24]: 0.930 (+/-0.040) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[25]: 0.932 (+/-0.028) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[26]: 0.930 (+/-0.030) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[27]: 0.930 (+/-0.033) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[28]: 0.932 (+/-0.041) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[29]: 0.932 (+/-0.023) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[30]: 0.927 (+/-0.062) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[31]: 0.922 (+/-0.036) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[32]: 0.922 (+/-0.049) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[33]: 0.911 (+/-0.076) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[34]: 0.908 (+/-0.075) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[35]: 0.908 (+/-0.075) for {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\t[36]: 0.892 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[37]: 0.892 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[38]: 0.892 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[39]: 0.892 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[40]: 0.892 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[41]: 0.892 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[42]: 0.890 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[43]: 0.892 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[44]: 0.890 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[45]: 0.894 (+/-0.044) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[46]: 0.894 (+/-0.044) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[47]: 0.894 (+/-0.044) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\t[48]: 0.911 (+/-0.049) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[49]: 0.920 (+/-0.023) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[50]: 0.923 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[51]: 0.923 (+/-0.038) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[52]: 0.925 (+/-0.019) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[53]: 0.925 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[54]: 0.918 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[55]: 0.913 (+/-0.068) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[56]: 0.911 (+/-0.067) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[57]: 0.915 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[58]: 0.913 (+/-0.055) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[59]: 0.913 (+/-0.055) for {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\t[60]: 0.927 (+/-0.046) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[61]: 0.920 (+/-0.035) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[62]: 0.915 (+/-0.031) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[63]: 0.932 (+/-0.035) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[64]: 0.927 (+/-0.028) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[65]: 0.918 (+/-0.042) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[66]: 0.908 (+/-0.069) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[67]: 0.915 (+/-0.067) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[68]: 0.915 (+/-0.069) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[69]: 0.913 (+/-0.055) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[70]: 0.913 (+/-0.055) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[71]: 0.913 (+/-0.055) for {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\t[72]: 0.892 (+/-0.045) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[73]: 0.892 (+/-0.045) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[74]: 0.892 (+/-0.045) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[75]: 0.892 (+/-0.045) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[76]: 0.892 (+/-0.045) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[77]: 0.892 (+/-0.045) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[78]: 0.890 (+/-0.052) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[79]: 0.890 (+/-0.052) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[80]: 0.892 (+/-0.045) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[81]: 0.894 (+/-0.044) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[82]: 0.894 (+/-0.044) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[83]: 0.894 (+/-0.044) for {'criterion': 'log_loss', 'max_depth': 2, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\t[84]: 0.918 (+/-0.026) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[85]: 0.913 (+/-0.044) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[86]: 0.918 (+/-0.042) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[87]: 0.925 (+/-0.041) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[88]: 0.923 (+/-0.038) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[89]: 0.915 (+/-0.041) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[90]: 0.913 (+/-0.071) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[91]: 0.911 (+/-0.071) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[92]: 0.911 (+/-0.067) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[93]: 0.913 (+/-0.055) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[94]: 0.918 (+/-0.052) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[95]: 0.913 (+/-0.055) for {'criterion': 'log_loss', 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\t[96]: 0.918 (+/-0.040) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\t[97]: 0.913 (+/-0.024) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "\t[98]: 0.920 (+/-0.041) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\t[99]: 0.932 (+/-0.023) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "\t[100]: 0.927 (+/-0.041) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\t[101]: 0.925 (+/-0.044) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\t[102]: 0.913 (+/-0.074) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "\t[103]: 0.911 (+/-0.071) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\t[104]: 0.913 (+/-0.071) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "\t[105]: 0.913 (+/-0.055) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\t[106]: 0.913 (+/-0.055) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "\t[107]: 0.913 (+/-0.055) for {'criterion': 'log_loss', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        91\n",
      "           1       0.92      0.92      0.92        52\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.94      0.94       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n",
      "\n",
      "CTOR for best model: DecisionTreeClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=5)\n",
      "\n",
      "best: dat=N/A, score=0.93661, model=DecisionTreeClassifier(criterion='gini',max_depth=5,min_samples_leaf=2,min_samples_split=5)\n",
      "\n",
      "OK(grid-search)\n",
      "(\"best: dat=N/A, score=0.93661, model=DecisionTreeClassifier(criterion='gini',max_depth=5,min_samples_leaf=2,min_samples_split=5)\", DecisionTreeClassifier(max_depth=5, min_samples_leaf=2, min_samples_split=5))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth' : [2, 5, None],\n",
    "    'min_samples_split' : [2, 5, 10],\n",
    "    'min_samples_leaf' : [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "scores = doGridSearch(data, model, tuning_parameters)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=2,\n",
    "                       min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try dummy classifier for a more realistic comparison of score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Classifies EVERYTHING in the most frequent class (here 1 == Malignant tumor diagnosis)\n",
    "\n",
    "def CompareToDummy(data: Data, model):\n",
    "    dummy_clf = DummyClassifier()\n",
    "    dummy_clf.fit(data.x_train, data.y_train)\n",
    "    dummy_y = dummy_clf.predict(data.x_test)\n",
    "\n",
    "    model.fit(data.x_train, data.y_train)\n",
    "    model_y = model.predict(data.x_test)\n",
    "\n",
    "    a_s = accuracy_score(data.y_test, model_y)\n",
    "    c_v_s = cross_val_score(model, data.x_train, data.y_train, cv=3, scoring=\"accuracy\")\n",
    "    # Uses 'jaccard score' function, see: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "    a_s_dummy = accuracy_score(data.y_test, dummy_y)\n",
    "    c_v_s_dummy = cross_val_score(dummy_clf, data.x_train, data.y_train, cv = 3, scoring=\"accuracy\")\n",
    "    print(type(model).__name__)\n",
    "    print(\"Model accuracy: \", a_s, \" | Dummy accuracy: \", a_s_dummy)\n",
    "    print(\"Model cvs: \", \"c_v_s\", c_v_s, \" | Dummy cvs: \", c_v_s_dummy, \"\\n\")\n",
    "\n",
    "    return (a_s, c_v_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing cross val score and accuracy of model to dummy classifier scores\n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.8713450292397661  | Dummy accuracy:  0.6432748538011696\n",
      "Model cvs:  c_v_s [0.84962406 0.93984962 0.90909091]  | Dummy cvs:  [0.61654135 0.62406015 0.62121212] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9473684210526315  | Dummy accuracy:  0.6432748538011696\n",
      "Model cvs:  c_v_s [0.93233083 0.96992481 0.95454545]  | Dummy cvs:  [0.61654135 0.62406015 0.62121212] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9415204678362573  | Dummy accuracy:  0.6432748538011696\n",
      "Model cvs:  c_v_s [0.90225564 0.88721805 0.93939394]  | Dummy cvs:  [0.61654135 0.62406015 0.62121212] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.8362573099415205  | Dummy accuracy:  0.6374269005847953\n",
      "Model cvs:  c_v_s [0.90977444 0.87218045 0.87878788]  | Dummy cvs:  [0.62406015 0.62406015 0.62121212] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9649122807017544  | Dummy accuracy:  0.6374269005847953\n",
      "Model cvs:  c_v_s [0.93984962 0.95488722 0.93939394]  | Dummy cvs:  [0.62406015 0.62406015 0.62121212] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.935672514619883  | Dummy accuracy:  0.6374269005847953\n",
      "Model cvs:  c_v_s [0.87969925 0.87969925 0.90151515]  | Dummy cvs:  [0.62406015 0.62406015 0.62121212] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.847953216374269  | Dummy accuracy:  0.5789473684210527\n",
      "Model cvs:  c_v_s [0.93233083 0.90977444 0.84090909]  | Dummy cvs:  [0.64661654 0.64661654 0.65151515] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9473684210526315  | Dummy accuracy:  0.5789473684210527\n",
      "Model cvs:  c_v_s [0.98496241 0.94736842 0.93939394]  | Dummy cvs:  [0.64661654 0.64661654 0.65151515] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9239766081871345  | Dummy accuracy:  0.5789473684210527\n",
      "Model cvs:  c_v_s [0.93984962 0.92481203 0.92424242]  | Dummy cvs:  [0.64661654 0.64661654 0.65151515] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.9064327485380117  | Dummy accuracy:  0.6140350877192983\n",
      "Model cvs:  c_v_s [0.85714286 0.91729323 0.86363636]  | Dummy cvs:  [0.63157895 0.63157895 0.63636364] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9824561403508771  | Dummy accuracy:  0.6140350877192983\n",
      "Model cvs:  c_v_s [0.93233083 0.95488722 0.9469697 ]  | Dummy cvs:  [0.63157895 0.63157895 0.63636364] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9298245614035088  | Dummy accuracy:  0.6140350877192983\n",
      "Model cvs:  c_v_s [0.91729323 0.90225564 0.92424242]  | Dummy cvs:  [0.63157895 0.63157895 0.63636364] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.8947368421052632  | Dummy accuracy:  0.6081871345029239\n",
      "Model cvs:  c_v_s [0.80451128 0.93233083 0.89393939]  | Dummy cvs:  [0.63909774 0.63157895 0.63636364] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9590643274853801  | Dummy accuracy:  0.6081871345029239\n",
      "Model cvs:  c_v_s [0.95488722 0.96240602 0.91666667]  | Dummy cvs:  [0.63909774 0.63157895 0.63636364] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9473684210526315  | Dummy accuracy:  0.6081871345029239\n",
      "Model cvs:  c_v_s [0.96240602 0.93984962 0.91666667]  | Dummy cvs:  [0.63909774 0.63157895 0.63636364] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.8888888888888888  | Dummy accuracy:  0.6198830409356725\n",
      "Model cvs:  c_v_s [0.78195489 0.93233083 0.90909091]  | Dummy cvs:  [0.63157895 0.63157895 0.62878788] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.935672514619883  | Dummy accuracy:  0.6198830409356725\n",
      "Model cvs:  c_v_s [0.98496241 0.93984962 0.96212121]  | Dummy cvs:  [0.63157895 0.63157895 0.62878788] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9415204678362573  | Dummy accuracy:  0.6198830409356725\n",
      "Model cvs:  c_v_s [0.92481203 0.89473684 0.93939394]  | Dummy cvs:  [0.63157895 0.63157895 0.62878788] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.8830409356725146  | Dummy accuracy:  0.6198830409356725\n",
      "Model cvs:  c_v_s [0.86466165 0.81203008 0.71212121]  | Dummy cvs:  [0.63157895 0.63157895 0.62878788] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9473684210526315  | Dummy accuracy:  0.6198830409356725\n",
      "Model cvs:  c_v_s [0.96992481 0.92481203 0.99242424]  | Dummy cvs:  [0.63157895 0.63157895 0.62878788] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9122807017543859  | Dummy accuracy:  0.6198830409356725\n",
      "Model cvs:  c_v_s [0.91729323 0.91729323 0.93939394]  | Dummy cvs:  [0.63157895 0.63157895 0.62878788] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.9064327485380117  | Dummy accuracy:  0.6432748538011696\n",
      "Model cvs:  c_v_s [0.89473684 0.90977444 0.92424242]  | Dummy cvs:  [0.61654135 0.62406015 0.62121212] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9590643274853801  | Dummy accuracy:  0.6432748538011696\n",
      "Model cvs:  c_v_s [0.94736842 0.94736842 0.96212121]  | Dummy cvs:  [0.61654135 0.62406015 0.62121212] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9415204678362573  | Dummy accuracy:  0.6432748538011696\n",
      "Model cvs:  c_v_s [0.93984962 0.93984962 0.90909091]  | Dummy cvs:  [0.61654135 0.62406015 0.62121212] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.9298245614035088  | Dummy accuracy:  0.6081871345029239\n",
      "Model cvs:  c_v_s [0.93233083 0.52631579 0.62121212]  | Dummy cvs:  [0.63909774 0.63157895 0.63636364] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9766081871345029  | Dummy accuracy:  0.6081871345029239\n",
      "Model cvs:  c_v_s [0.96992481 0.93984962 0.93939394]  | Dummy cvs:  [0.63909774 0.63157895 0.63636364] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9298245614035088  | Dummy accuracy:  0.6081871345029239\n",
      "Model cvs:  c_v_s [0.93233083 0.90977444 0.88636364]  | Dummy cvs:  [0.63909774 0.63157895 0.63636364] \n",
      "\n",
      "SGDClassifier\n",
      "Model accuracy:  0.8947368421052632  | Dummy accuracy:  0.5964912280701754\n",
      "Model cvs:  c_v_s [0.93984962 0.92481203 0.86363636]  | Dummy cvs:  [0.63909774 0.63909774 0.64393939] \n",
      "\n",
      "RidgeClassifier\n",
      "Model accuracy:  0.9590643274853801  | Dummy accuracy:  0.5964912280701754\n",
      "Model cvs:  c_v_s [0.96240602 0.95488722 0.93939394]  | Dummy cvs:  [0.63909774 0.63909774 0.64393939] \n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model accuracy:  0.9181286549707602  | Dummy accuracy:  0.5964912280701754\n",
      "Model cvs:  c_v_s [0.93233083 0.87969925 0.96969697]  | Dummy cvs:  [0.63909774 0.63909774 0.64393939] \n",
      "\n",
      "{'sgd': 0.8859649122807018, 'ridge': 0.9578947368421054, 'dtree': 0.9321637426900583}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '0.885965'), Text(0, 0, '0.957895'), Text(0, 0, '0.932164')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "accuracies = {}\n",
    "\n",
    "iterations = 10\n",
    "\n",
    "# Take an average accuracy score from 10 iterations, since they change between fits!\n",
    "\n",
    "print(\"Comparing cross val score and accuracy of model to dummy classifier scores\\n\")\n",
    "sgd_accuracies = []\n",
    "ridge_accuracies = []\n",
    "dtree_accuracies = []\n",
    "for i in range(iterations):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_breast_cancer, y_all, test_size=0.3, shuffle=True)\n",
    "    data = Data(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    scores = CompareToDummy(data, sgd)\n",
    "    sgd_accuracies.append(scores[0])\n",
    "\n",
    "    scores = CompareToDummy(data, ridge)\n",
    "    ridge_accuracies.append(scores[0])\n",
    "\n",
    "    scores = CompareToDummy(data, dtree)\n",
    "    dtree_accuracies.append(scores[0])\n",
    "\n",
    "accuracies[\"sgd\"] = np.mean(sgd_accuracies)\n",
    "accuracies[\"ridge\"] = np.mean(ridge_accuracies)\n",
    "accuracies[\"dtree\"] = np.mean(dtree_accuracies)\n",
    "print(accuracies)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.barh(np.arange(len(accuracies)), list(accuracies.values()))\n",
    "plt.title(\"Classifier accuracy (f1)\")\n",
    "plt.yticks(range(len(accuracies)), list(accuracies.keys()))\n",
    "ax.bar_label(bars)\n",
    "#for i, v in enumerate(accuracies.values()):\n",
    "#    ax.text(i, v+25, \"%d\" %v, ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw the confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHHCAYAAAC4M/EEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8zElEQVR4nO3deZyNdf/H8fc5wyzMwogZwxhjJ6JsjcpSU8htuSm/SndDlhZLiHDfjZ3pVndEMqmQ0l4UlRIhNwnRrUKWURNmbM2MGc1izvX7w+3cHUPmzDkzxznX69njejw632v7XNPc92c+3+/3fC+LYRiGAACAz7J6OgAAAFC6SPYAAPg4kj0AAD6OZA8AgI8j2QMA4ONI9gAA+DiSPQAAPo5kDwCAjyPZAwDg40j2cJvJkyfLYrEU61iLxaLJkyeXbkBXmddee02NGjVS+fLlValSJbdf35mfv5msX79eFotF69ev93QogMeU83QAgBns3btX/fv3V5cuXTR+/HhVqFDB0yF5pTfeeEPHjx/XyJEjPR0K4FUsrI0Pdzl37pzOnTunwMDAKx5rsVg0adIk01T3ycnJeuSRR7R//37Vq1evVO7hzM/fW/3lL3/R999/r8OHDxf7HJvNpvz8fPn7+8tqpTMT5sRvPlyWk5MjSSpXrpxPJxpXHD9+XJJKpfv+An7+jnJzc2Wz2WS1WhUYGEiih6nx2w+nXBgX/vHHH3XfffepcuXKuvnmmx32/VFeXp5GjRqlqlWrKiQkRD169NCvv/56yWuvX79erVq1UmBgoOrWrasXX3zxsuPQr7/+ulq2bKmgoCCFh4frnnvuUWpqarGe4ciRIxo4cKCioqIUEBCg2NhYPfLII8rPz7cfc+jQId19990KDw9XhQoVdOONN+rjjz8uEq/FYtE777yjGTNmqGbNmgoMDNRtt92mAwcO2I+rXbu2Jk2aJEmqWrWqw3yFy81dqF27tvr372//XFBQoClTpqh+/foKDAxUlSpVdPPNN2vNmjX2Yy71szp37pymTZumunXrKiAgQLVr19bf//535eXlFbnfX/7yF23atElt2rRRYGCg6tSpo6VLl17x53n48GFZLBY988wzmj9/vurUqaMKFSrojjvuUGpqqgzD0LRp01SzZk0FBQWpZ8+eOn36tMM1PvzwQ3Xr1s3+36Ru3bqaNm2aCgsL7cd07NhRH3/8sX7++WdZLBZZLBbVrl3b4b/FW2+9pSeffFI1atRQhQoVlJWVVWTMfs+ePQoKCtIDDzzgEMOmTZvk5+encePGXfGZAW/DmD1K5O6771b9+vU1c+ZM/dlI0KBBg/T666/rvvvuU7t27bRu3Tp169atyHE7d+5Uly5dVL16dU2ZMkWFhYWaOnWqqlatWuTYGTNmKDExUX379tWgQYN04sQJzZs3T+3bt9fOnTv/tHo+evSo2rRpo4yMDA0ZMkSNGjXSkSNH9N577+ns2bPy9/dXenq62rVrp7Nnz2rEiBGqUqWKXn31VfXo0UPvvfee/vrXvzpc86mnnpLVatWYMWOUmZmpWbNmqV+/ftq6daskac6cOVq6dKmWL1+uBQsWKDg4WNddd10xf9LnTZ48WUlJSRo0aJDatGmjrKwsbd++Xd9++61uv/32y543aNAgvfrqq7rrrrv0+OOPa+vWrUpKStKePXu0fPlyh2MPHDigu+66SwMHDlRCQoIWLVqk/v37q2XLlrr22muvGOOyZcuUn5+v4cOH6/Tp05o1a5b69u2rW2+9VevXr9e4ceN04MABzZs3T2PGjNGiRYvs5y5ZskTBwcEaPXq0goODtW7dOk2cOFFZWVl6+umnJUn/+Mc/lJmZqV9//VWzZ8+WJAUHBzvEMG3aNPn7+2vMmDHKy8uTv79/kTgbN26sadOmaezYsbrrrrvUo0cP5eTkqH///mrUqJGmTp16xWcFvI4BOGHSpEmGJOPee++97L4Ldu3aZUgyHn30UYfj7rvvPkOSMWnSJHtb9+7djQoVKhhHjhyxt+3fv98oV66cwzUPHz5s+Pn5GTNmzHC45u7du41y5coVab/YAw88YFitVmPbtm1F9tlsNsMwDGPkyJGGJOOrr76y7ztz5owRGxtr1K5d2ygsLDQMwzC+/PJLQ5LRuHFjIy8vz37sc889Z0gydu/eXeRnc+LECYd7XvxzuCAmJsZISEiwf27evLnRrVu3P322y/38Bw0a5HDcmDFjDEnGunXrHO4nydi4caO97fjx40ZAQIDx+OOP/+l9U1JSDElG1apVjYyMDHv7hAkTDElG8+bNjYKCAnv7vffea/j7+xu5ubn2trNnzxa57kMPPWRUqFDB4bhu3boZMTExRY698N+iTp06Ra51Yd+XX35pbyssLDRuvvlmIyIiwjh58qQxdOhQo1y5cpf8vQB8Ad34KJGHH374isd88sknkqQRI0Y4tF88k7qwsFBffPGFevXqpaioKHt7vXr11LVrV4djP/jgA9lsNvXt21cnT560b5GRkapfv76+/PLLy8Zjs9m0YsUKde/eXa1atSqy/0IX+CeffKI2bdrYhyek8xXkkCFDdPjwYf34448O5w0YMMChgrzlllsknR8KcJdKlSrphx9+0P79+4t9zoWf/+jRox3aH3/8cUkqMizRpEkTe+zS+SGHhg0bFvs57r77boWFhdk/t23bVpJ0//33q1y5cg7t+fn5OnLkiL0tKCjI/u9nzpzRyZMndcstt+js2bPau3dvse4vSQkJCQ7Xuhyr1aolS5YoOztbXbt21QsvvKAJEyZc8vcC8AUke5RIbGzsFY/5+eefZbVaVbduXYf2hg0bOnw+fvy4fv/990vOUr+4bf/+/TIMQ/Xr11fVqlUdtj179tgnwl3KiRMnlJWVpaZNm14x7otjlM53/17Y/0e1atVy+Fy5cmVJ0m+//fan93HG1KlTlZGRoQYNGqhZs2YaO3as/vOf//zpORd+/hf/DCMjI1WpUqUrPod0/lmK+xwXn38h8UdHR1+y/Y/X/eGHH/TXv/5VYWFhCg0NVdWqVXX//fdLkjIzM4t1f6l4v5cX1K1bV5MnT9a2bdt07bXXKjExsdjnAt6GMXuUSHGqp9Jgs9lksVj06aefys/Pr8j+i8dwy8Kl4pD0p3MZruSPE9MkqX379jp48KA+/PBDff7553r55Zc1e/ZsJScna9CgQX96reIutOPqc1zu/CtdNyMjQx06dFBoaKimTp2qunXrKjAwUN9++63GjRsnm81WrPtLzv9efv7555LOz+U4deqUIiMjnTof8BYke5SamJgY2Ww2HTx40KFS3rdvn8Nx1apVU2BgoMMM9gsubqtbt64Mw1BsbKwaNGjgVDxVq1ZVaGiovv/++yvGfXGMkuzdyTExMU7d989UrlxZGRkZDm35+fk6duxYkWPDw8M1YMAADRgwQNnZ2Wrfvr0mT5582WR/4ee/f/9+e6+EJKWnpysjI8Otz+GK9evX69SpU/rggw/Uvn17e3tKSkqRY925QmBycrLWrFmjGTNmKCkpSQ899JA+/PBDt10fuJrQjY9Sc2G8fe7cuQ7tc+bMcfjs5+en+Ph4rVixQkePHrW3HzhwQJ9++qnDsb1795afn5+mTJlSpOI0DEOnTp26bDxWq1W9evXSypUrtX379iL7L1zvzjvv1DfffKMtW7bY9+Xk5GjhwoWqXbu2mjRp8idP7Zy6detq48aNDm0LFy4sUtlf/FzBwcGqV69eka/Q/dGdd94pqejP+9lnn5WkS34rwhMuVP5//O+Zn5+vF154ocixFStWdKpb/3JSUlI0duxY9enTR3//+9/1zDPP6KOPPirWVw0Bb0Rlj1LTokUL3XvvvXrhhReUmZmpdu3aae3atZes4CdPnqzPP/9cN910kx555BEVFhbq+eefV9OmTbVr1y77cXXr1tX06dM1YcIEHT58WL169VJISIhSUlK0fPlyDRkyRGPGjLlsTDNnztTnn3+uDh06aMiQIWrcuLGOHTumd999V5s2bVKlSpU0fvx4vfnmm+ratatGjBih8PBwvfrqq0pJSdH777/v1sVZBg0apIcfflh9+vTR7bffru+++06fffaZrrnmGofjmjRpoo4dO6ply5YKDw/X9u3b9d5772nYsGGXvXbz5s2VkJCghQsX2rvKv/nmG7366qvq1auXOnXq5LbncEW7du1UuXJlJSQkaMSIEbJYLHrttdcuOXzQsmVLvf322xo9erRat26t4OBgde/e3an7GYahBx98UEFBQVqwYIEk6aGHHtL777+vxx57TPHx8Q4TRQFfQLJHqVq0aJGqVq2qZcuWacWKFbr11lv18ccfF5m01bJlS3366acaM2aMEhMTFR0dralTp2rPnj1FZmOPHz9eDRo00OzZszVlyhRJ5yeB3XHHHerRo8efxlOjRg1t3bpViYmJWrZsmbKyslSjRg117drVvl59RESENm/erHHjxmnevHnKzc3Vddddp5UrV7q9Gh48eLBSUlL0yiuvaPXq1brlllu0Zs0a3XbbbQ7HjRgxQh999JE+//xz5eXlKSYmRtOnT9fYsWP/9Povv/yy6tSpoyVLlmj58uWKjIzUhAkT7Iv8XA2qVKmiVatW6fHHH9eTTz6pypUr6/7779dtt92mzp07Oxz76KOPateuXVq8eLFmz56tmJgYp5P9vHnztH79er3//vsO6zi88soratq0qQYPHlzkmwqAt2NtfFzVevXq5fRXzgAAjhizx1Xj999/d/i8f/9+ffLJJ+rYsaNnAgIAH0Flj6tG9erV1b9/f9WpU0c///yzFixYoLy8PO3cuVP169f3dHgA4LUYs8dVo0uXLnrzzTeVlpamgIAAxcXFaebMmSR6AHARlT0AAD6OMXsAAHwcyR4AAB/n1WP2NptNR48eVUhIiFuX0QQAlA3DMHTmzBlFRUW5dcGqi+Xm5io/P9/l6/j7+yswMNANEZUtr072R48eLbI4CwDA+6SmpqpmzZqlcu3c3FwFhVSRzp11+VqRkZFKSUnxuoTv1ck+JCREkuTfJEEWP/8rHA14p1/WP+PpEIBScyYrS/Vio+3/f14a8vPzpXNnFdAkQXIlVxTmK+3HV5Wfn0+yL0sXuu4tfv4ke/is0NBQT4cAlLoyGYotF+hSrjAs3jvNzXsjBwDAGRZJFosLm3O327hxo7p3766oqChZLBatWLHCYb9hGJo4caKqV6+uoKAgxcfHF1ka/PTp0+rXr59CQ0NVqVIlDRw4UNnZ2U4/OskeAGAOFqvrmxNycnLUvHlzzZ8//5L7Z82apblz5yo5OVlbt25VxYoV1blzZ+Xm5tqP6devn3744QetWbNGq1at0saNGzVkyBCnH92ru/EBALhade3aVV27dr3kPsMwNGfOHD355JPq2bOnJGnp0qWKiIjQihUrdM8992jPnj1avXq1tm3bplatWkk6/9bGO++8U88884xTr2KmsgcAmINLXfj/3SRlZWU5bHl5eU6HkpKSorS0NMXHx9vbwsLC1LZtW23ZskWStGXLFlWqVMme6CUpPj5eVqtVW7dudep+JHsAgDm4qRs/OjpaYWFh9i0pKcnpUNLS0iRJERERDu0RERH2fWlpaapWrZrD/nLlyik8PNx+THHRjQ8AgBNSU1MdviUTEBDgwWiKh8oeAGAOburGDw0NddhKkuwjIyMlSenp6Q7t6enp9n2RkZE6fvy4w/5z587p9OnT9mOKi2QPADAJV7vw3ZcyY2NjFRkZqbVr19rbsrKytHXrVsXFxUmS4uLilJGRoR07dtiPWbdunWw2m9q2bevU/ejGBwCgFGRnZ+vAgQP2zykpKdq1a5fCw8NVq1YtjRw5UtOnT1f9+vUVGxurxMRERUVFqVevXpKkxo0bq0uXLho8eLCSk5NVUFCgYcOG6Z577nFqJr5EsgcAmMUfuuJLfL4Ttm/frk6dOtk/jx49WpKUkJCgJUuW6IknnlBOTo6GDBmijIwM3XzzzVq9erXDUrzLli3TsGHDdNttt8lqtapPnz6aO3eu86EbhmE4fdZVIisrS2FhYQpoNpjlcuGzftv2vKdDAEpNVlaWIqqEKTMzs9SWhrbnitajZSlX8sl0xrk85W17tlRjLS2M2QMA4OPoxgcAmEMZd+NfTUj2AABzKMH69kXO91IkewCAOZi4svfeP1MAAECxUNkDAMyBbnwAAHycxeJisqcbHwAAXKWo7AEA5mC1nN9cOd9LkewBAOZg4jF7740cAAAUC5U9AMAcTPw9e5I9AMAc6MYHAAC+isoeAGAOdOMDAODjTNyNT7IHAJiDiSt77/0zBQAAFAuVPQDAHOjGBwDAx9GNDwAAfBWVPQDAJFzsxvfi+phkDwAwB7rxAQCAr6KyBwCYg8Xi4mx8763sSfYAAHMw8VfvvDdyAABQLFT2AABzMPEEPZI9AMAcTNyNT7IHAJiDiSt77/0zBQAAFAuVPQDAHOjGBwDAx9GNDwAAfBWVPQDAFCwWiywmrexJ9gAAUzBzsqcbHwAAH0dlDwAwB8t/N1fO91IkewCAKdCNDwAAfBaVPQDAFMxc2ZPsAQCmQLIHAMDHmTnZM2YPAICPo7IHAJgDX70DAMC30Y0PAAB8FpU9AMAUzr/h1pXK3n2xlDWSPQDAFCxysRvfi7M93fgAAPg4KnsAgCmYeYIeyR4AYA4m/uod3fgAAPg4KnsAgDm42I1v0I0PAMDVzdUxe9dm8nsWyR4AYApmTvaM2QMA4OOo7AEA5mDi2fgkewCAKdCNDwAAfBaVPQDAFMxc2ZPsAQCmYOZkTzc+AACloLCwUImJiYqNjVVQUJDq1q2radOmyTAM+zGGYWjixImqXr26goKCFB8fr/3797s9FpI9AMAULlT2rmzO+Oc//6kFCxbo+eef1549e/TPf/5Ts2bN0rx58+zHzJo1S3PnzlVycrK2bt2qihUrqnPnzsrNzXXrs9ONDwAwhzL+6t3mzZvVs2dPdevWTZJUu3Ztvfnmm/rmm28kna/q58yZoyeffFI9e/aUJC1dulQRERFasWKF7rnnHheCdURlDwCAE7Kyshy2vLy8Sx7Xrl07rV27Vj/99JMk6bvvvtOmTZvUtWtXSVJKSorS0tIUHx9vPycsLExt27bVli1b3BozlT0AwBTcNUEvOjraoX3SpEmaPHlykePHjx+vrKwsNWrUSH5+fiosLNSMGTPUr18/SVJaWpokKSIiwuG8iIgI+z53IdkDAEzBXck+NTVVoaGh9vaAgIBLHv/OO+9o2bJleuONN3Tttddq165dGjlypKKiopSQkFDiOEqCZA8AMAV3JfvQ0FCHZH85Y8eO1fjx4+1j782aNdPPP/+spKQkJSQkKDIyUpKUnp6u6tWr289LT09XixYtShznpTBmDwBAKTh79qysVsc06+fnJ5vNJkmKjY1VZGSk1q5da9+flZWlrVu3Ki4uzq2xUNkDAMyhjGfjd+/eXTNmzFCtWrV07bXXaufOnXr22Wf14IMPnr+cxaKRI0dq+vTpql+/vmJjY5WYmKioqCj16tXLhUCLItkDAEyhrFfQmzdvnhITE/Xoo4/q+PHjioqK0kMPPaSJEyfaj3niiSeUk5OjIUOGKCMjQzfffLNWr16twMDAEsd5ydiNPy7l42WysrIUFhamgGaDZfHz93Q4QKn4bdvzng4BKDVZWVmKqBKmzMzMYo2Dl/QeYWFhqjHkTVn9K5T4Orb8szqy8N5SjbW0UNlD7a6vq+F/i1fzRrVUvWqY+o1ZqE82/MfhmAkPddMDvdopLDhIW/9zSI8/9bYOpZ6QJEVXD9fYgV3UvlUDVasSqrSTmXrn023616LPVHCu0BOPBJTIS+9s0LzX1+r4qSw1rV9D/xx7t1peW9vTYcFNWBvfw+bPn6/atWsrMDBQbdu2ta8uhLJRIShA3/90RGNnvX3J/Y89EK+H/q+DRie9pdsHPKOzv+fr/XlDFeB//m/FBrUjZLVaNSrpLcXdM0P/mP2BBvS+WYlDe5TlYwAu+eDzHXpyznKNG9RV618bp6b1a6jP8Pk6cfqMp0ODm1jk4nK5Lg34e5bHk/3bb7+t0aNHa9KkSfr222/VvHlzde7cWcePH/d0aKbxxeYfNSN5lT5e/59L7n/43k56ZtFn+nTjbv1w4KgembRUkdeEqVuH5pKktVv2aNjU1/Xl1r36+cgpfbpxt55/fa26d2pelo8BuOSFN9bpgV7t1K9HnBrVqa5nJ9yjCoH+ev0j965kBniCx5P9s88+q8GDB2vAgAFq0qSJkpOTVaFCBS1atMjToUFSTI0qirwmTOu/2Wtvy8rJ1Y4fDqv1dbUve15ocJB+yzxbBhECrssvOKdde1PVsU1De5vValWHNg21bXeKByODO5X1i3CuJh5N9vn5+dqxY4fDusBWq1Xx8fFuXxcYJRNR5fwklBOnHLsyj586o2pVLj1BJbbmNRryfx20ZPmmUo8PcIdTGdkqLLSpaniIQ3vV8FAdP5XloajgdhY3bF7KoxP0Tp48qcLCwkuuC7x3794ix+fl5Tm8cCAri/8RXm2qVw3Te3OHasUXO7V0xWZPhwMA0FXQje+MpKQkhYWF2beLX0YA90v/b1VTtYpjxVOtSkiRiifymjB9tOAxffOfQxo5880yixFwVZVKwfLzsxaZjHfidNZle7DgfejG95BrrrlGfn5+Sk9Pd2hPT0+3rxn8RxMmTFBmZqZ9S01NLatQTevnI6eUdjJTHVr/bywzpGKgWl5bW9v+c9jeVr1qmFYmP6bv9v6ioVNflxcv3wAT8i9fTi0aRWvDtn32NpvNpo3bflLrZrEejAzuZOZk79FufH9/f7Vs2VJr1661Lw1os9m0du1aDRs2rMjxAQEBl327EEquYpC/YqOr2j/HRFVR0wY1lJF5Vr+m/6bkN7/UmAe76FDqCf185JT+/nA3pZ3M1McbvpP0v0SfmnZaic8t1zWVg+3XOn6Kry3BOzx63616dMprur5xLd1wbW0tePNL5fyep37db/R0aHATi+X85sr53srji+qMHj1aCQkJatWqldq0aaM5c+YoJydHAwYM8HRoptGicYxWvfiY/fPM0X0kSW+s+lpDp7yu55Z+oQpBAZr993sVFhykr787qLtGvKC8/HOSpI5tG6lurWqqW6uafvxkhsO1K7cu+kcbcDXqfUdLnczI1swXP9bxU2fUrEENvTd3KN348AlXxXK5zz//vJ5++mmlpaWpRYsWmjt3rtq2bXvF81guF2bAcrnwZWW5XG6d4e/JGlCxxNex5eXo0Ly7WC63pIYNG3bJbnsAANzGxW58b/7qnVfNxgcAAM67Kip7AABKm5lfhEOyBwCYgpln49ONDwCAj6OyBwCYgtVqkdVa8vLccOFcTyPZAwBMgW58AADgs6jsAQCmwGx8AAB8nJm78Un2AABTMHNlz5g9AAA+jsoeAGAKZq7sSfYAAFMw85g93fgAAPg4KnsAgClY5GI3vhe/45ZkDwAwBbrxAQCAz6KyBwCYArPxAQDwcXTjAwAAn0VlDwAwBbrxAQDwcWbuxifZAwBMwcyVPWP2AAD4OCp7AIA5uNiN78UL6JHsAQDmQDc+AADwWVT2AABTYDY+AAA+jm58AADgs6jsAQCmQDc+AAA+jm58AADgs6jsAQCmYObKnmQPADAFxuwBAPBxZq7sGbMHAMDHUdkDAEyBbnwAAHwc3fgAAMBnUdkDAEzBIhe78d0WSdkj2QMATMFqscjqQrZ35VxPoxsfAAAfR2UPADAFZuMDAODjzDwbn2QPADAFq+X85sr53ooxewAAfByVPQDAHCwudsV7cWVPsgcAmIKZJ+jRjQ8AQCk5cuSI7r//flWpUkVBQUFq1qyZtm/fbt9vGIYmTpyo6tWrKygoSPHx8dq/f7/b4yDZAwBMweKGf5zx22+/6aabblL58uX16aef6scff9S//vUvVa5c2X7MrFmzNHfuXCUnJ2vr1q2qWLGiOnfurNzcXLc+O934AABTKOvZ+P/85z8VHR2txYsX29tiY2Pt/24YhubMmaMnn3xSPXv2lCQtXbpUERERWrFihe65556SB3sRKnsAAJyQlZXlsOXl5V3yuI8++kitWrXS3XffrWrVqun666/XSy+9ZN+fkpKitLQ0xcfH29vCwsLUtm1bbdmyxa0xk+wBAKZwYVEdVzZJio6OVlhYmH1LSkq65P0OHTqkBQsWqH79+vrss8/0yCOPaMSIEXr11VclSWlpaZKkiIgIh/MiIiLs+9ylWN34H330UbEv2KNHjxIHAwBAaXHXbPzU1FSFhoba2wMCAi55vM1mU6tWrTRz5kxJ0vXXX6/vv/9eycnJSkhIKHkgJVCsZN+rV69iXcxisaiwsNCVeAAAuKqFhoY6JPvLqV69upo0aeLQ1rhxY73//vuSpMjISElSenq6qlevbj8mPT1dLVq0cF/AKmY3vs1mK9ZGogcAXK0uvOLWlc0ZN910k/bt2+fQ9tNPPykmJkbS+cl6kZGRWrt2rX1/VlaWtm7dqri4ONcf+A9cmo2fm5urwMBAd8UCAECpKetFdUaNGqV27dpp5syZ6tu3r7755hstXLhQCxcu/O/1LBo5cqSmT5+u+vXrKzY2VomJiYqKiip2j3pxOT1Br7CwUNOmTVONGjUUHBysQ4cOSZISExP1yiuvuDU4AADcxV0T9IqrdevWWr58ud588001bdpU06ZN05w5c9SvXz/7MU888YSGDx+uIUOGqHXr1srOztbq1avdXkg7nexnzJihJUuWaNasWfL397e3N23aVC+//LJbgwMAwJv95S9/0e7du5Wbm6s9e/Zo8ODBDvstFoumTp2qtLQ05ebm6osvvlCDBg3cHofTyX7p0qVauHCh+vXrJz8/P3t78+bNtXfvXrcGBwCAu1zoxndl81ZOj9kfOXJE9erVK9Jus9lUUFDglqAAAHC3kkyyu/h8b+V0Zd+kSRN99dVXRdrfe+89XX/99W4JCgAAuI/Tlf3EiROVkJCgI0eOyGaz6YMPPtC+ffu0dOlSrVq1qjRiBADAZRa59kp6763rS1DZ9+zZUytXrtQXX3yhihUrauLEidqzZ49Wrlyp22+/vTRiBADAZWU9G/9qUqLv2d9yyy1as2aNu2MBAACloMSL6mzfvl179uyRdH4cv2XLlm4LCgAAdyvrV9xeTZxO9r/++qvuvfde/fvf/1alSpUkSRkZGWrXrp3eeust1axZ090xAgDgMle74r25G9/pMftBgwapoKBAe/bs0enTp3X69Gnt2bNHNptNgwYNKo0YAQCAC5yu7Dds2KDNmzerYcOG9raGDRtq3rx5uuWWW9waHAAA7uTFxblLnE720dHRl1w8p7CwUFFRUW4JCgAAd6Mb3wlPP/20hg8fru3bt9vbtm/frscee0zPPPOMW4MDAMBdLkzQc2XzVsWq7CtXruzwF01OTo7atm2rcuXOn37u3DmVK1dODz74oNtfywcAAFxTrGQ/Z86cUg4DAIDSZeZu/GIl+4SEhNKOAwCAUmXm5XJLvKiOJOXm5io/P9+hLTQ01KWAAACAezmd7HNycjRu3Di98847OnXqVJH9hYWFbgkMAAB34hW3TnjiiSe0bt06LViwQAEBAXr55Zc1ZcoURUVFaenSpaURIwAALrNYXN+8ldOV/cqVK7V06VJ17NhRAwYM0C233KJ69eopJiZGy5YtU79+/UojTgAAUEJOV/anT59WnTp1JJ0fnz99+rQk6eabb9bGjRvdGx0AAG5i5lfcOp3s69Spo5SUFElSo0aN9M4770g6X/FfeDEOAABXGzN34zud7AcMGKDvvvtOkjR+/HjNnz9fgYGBGjVqlMaOHev2AAEAgGucHrMfNWqU/d/j4+O1d+9e7dixQ/Xq1dN1113n1uAAAHAXM8/Gd+l79pIUExOjmJgYd8QCAECpcbUr3otzffGS/dy5c4t9wREjRpQ4GAAASgvL5V7B7Nmzi3Uxi8VCsgcA4CpTrGR/Yfb91eqHT5MUwjK98FG9Fm71dAhAqTn3e06Z3cuqEsxKv+h8b+XymD0AAN7AzN343vyHCgAAKAYqewCAKVgskpXZ+AAA+C6ri8nelXM9jW58AAB8XImS/VdffaX7779fcXFxOnLkiCTptdde06ZNm9waHAAA7sKLcJzw/vvvq3PnzgoKCtLOnTuVl5cnScrMzNTMmTPdHiAAAO5woRvflc1bOZ3sp0+fruTkZL300ksqX768vf2mm27St99+69bgAACA65yeoLdv3z61b9++SHtYWJgyMjLcERMAAG5n5rXxna7sIyMjdeDAgSLtmzZtUp06ddwSFAAA7nbhrXeubN7K6WQ/ePBgPfbYY9q6dassFouOHj2qZcuWacyYMXrkkUdKI0YAAFxmdcPmrZzuxh8/frxsNptuu+02nT17Vu3bt1dAQIDGjBmj4cOHl0aMAADABU4ne4vFon/84x8aO3asDhw4oOzsbDVp0kTBwcGlER8AAG5h5jH7Eq+g5+/vryZNmrgzFgAASo1Vro27W+W92d7pZN+pU6c/XVhg3bp1LgUEAADcy+lk36JFC4fPBQUF2rVrl77//nslJCS4Ky4AANyKbnwnzJ49+5LtkydPVnZ2tssBAQBQGngRjhvcf//9WrRokbsuBwAA3MRtr7jdsmWLAgMD3XU5AADc6vz77EtenpuqG793794Onw3D0LFjx7R9+3YlJia6LTAAANyJMXsnhIWFOXy2Wq1q2LChpk6dqjvuuMNtgQEAAPdwKtkXFhZqwIABatasmSpXrlxaMQEA4HZM0CsmPz8/3XHHHbzdDgDgdSxu+MdbOT0bv2nTpjp06FBpxAIAQKm5UNm7snkrp5P99OnTNWbMGK1atUrHjh1TVlaWwwYAAK4uxR6znzp1qh5//HHdeeedkqQePXo4LJtrGIYsFosKCwvdHyUAAC4y85h9sZP9lClT9PDDD+vLL78szXgAACgVFovlT9/tUpzzvVWxk71hGJKkDh06lFowAADA/Zz66p03/1UDADA3uvGLqUGDBldM+KdPn3YpIAAASgMr6BXTlClTiqygBwAArm5OJft77rlH1apVK61YAAAoNVaLxaUX4bhyrqcVO9kzXg8A8GZmHrMv9qI6F2bjAwAA71LsZG+z2ejCBwB4L8v/JumVZHNlafynnnpKFotFI0eOtLfl5uZq6NChqlKlioKDg9WnTx+lp6e7/JiX4vRyuQAAeCOrLC5vJbFt2za9+OKLuu666xzaR40apZUrV+rdd9/Vhg0bdPToUfXu3dsdj1oEyR4AYAquVPUl/dpedna2+vXrp5deesnh1fCZmZl65ZVX9Oyzz+rWW29Vy5YttXjxYm3evFlff/21G5/6PJI9AAClZOjQoerWrZvi4+Md2nfs2KGCggKH9kaNGqlWrVrasmWL2+Nw6qt3AAB4K3fNxr/4Da8BAQEKCAgocvxbb72lb7/9Vtu2bSuyLy0tTf7+/qpUqZJDe0REhNLS0koe5GVQ2QMATOHC9+xd2SQpOjpaYWFh9i0pKanIvVJTU/XYY49p2bJlCgwMLOtHLYLKHgAAJ6Smpio0NNT++VJV/Y4dO3T8+HHdcMMN9rbCwkJt3LhRzz//vD777DPl5+crIyPDobpPT09XZGSk22Mm2QMATMFda+OHhoY6JPtLue2227R7926HtgEDBqhRo0YaN26coqOjVb58ea1du1Z9+vSRJO3bt0+//PKL4uLiSh7kZZDsAQCmYJWLy+U68dW7kJAQNW3a1KGtYsWKqlKlir194MCBGj16tMLDwxUaGqrhw4crLi5ON954Y4ljvBySPQAAHjB79mxZrVb16dNHeXl56ty5s1544YVSuRfJHgBgCp5+xe369esdPgcGBmr+/PmaP3++axcuBpI9AMAUrHLtK2je/PU1b44dAAAUA5U9AMAULBaLS69r9+ZXvZPsAQCm4OKL61w619NI9gAAU/jjKnglPd9bMWYPAICPo7IHAJiG99bmriHZAwBMwdPfs/ckuvEBAPBxVPYAAFPgq3cAAPg4VtADAAA+i8oeAGAKdOMDAODjzLyCHt34AAD4OCp7AIAp0I0PAICPM/NsfJI9AMAUzFzZe/MfKgAAoBio7AEApmDm2fgkewCAKfAiHAAA4LOo7AEApmCVRVYXOuNdOdfTSPYAAFOgGx8AAPgsKnsAgClY/vuPK+d7K5I9AMAU6MYHAAA+i8oeAGAKFhdn49ONDwDAVc7M3fgkewCAKZg52TNmDwCAj6OyBwCYAl+9AwDAx1kt5zdXzvdWdOMDAODjqOwBAKZANz4AAD6O2fgAAMBnUdkDAEzBIte64r24sCfZAwDMgdn4AADAZ1HZ44pu6jtVv6b9VqT9b71u0vTRd3kgIsB14RXK64G2tXRDdJgCyvkpLStXc9cf0sGTOfKzWNSvdU21rFVJESEBOptfqO+OZGrpN6n67WyBp0NHCTEb30M2btyop59+Wjt27NCxY8e0fPly9erVy5Mh4RI+WjhahYU2++efUo6p3+hkdevUwnNBAS6o6O+np3peq91HszTt033KzD2nqNBA5eSdkyQFlLOqzjUV9c63R5Ry6qyCA8ppULsY/aNzA41Z/oOHo0dJmXk2vkeTfU5Ojpo3b64HH3xQvXv39mQo+BNVKgU7fF6wbK1ialyjG1vU9VBEgGt6t4jSyew8zdtwyN52/Eye/d/PFhRq8id7Hc5Z+O/DeuavTXVNRX+dzMkvs1jhPha5NsnOi3O9Z5N9165d1bVrV0+GACflF5zT8jU7NKhvB1m8+c9cmFqbmMra+WuGxsbX07XVQ3U6J1+f/piuNXtPXPacCv5+shmGcvILyzBSwD28asw+Ly9PeXn/++s7KyvLg9GY0+df7VZW9u+6u2sbT4cClFhESIC6NI7QR7uP6b2dR1W/akUNaldb5woNfbn/ZJHjy/tZlNCmlr46cEq/F5DsvZVVFlldKFKsXlzbe9Vs/KSkJIWFhdm36OhoT4dkOm9/vFUd2zZSxDVhng4FKDGLRTp0Mkevb/tVKafO6vO9J7Rm73F1blKtyLF+FovGxteXLFLypsNlHyzcxuKGzVt5VbKfMGGCMjMz7VtqaqqnQzKVX9NOa9OOn3RPtxs9HQrgkt/OFig143eHtl9/+11VgwMc2s4n+nqqGuyvyR/vpaqH1/KqbvyAgAAFBARc+UCUinc/+UZVKgXr1rgmng4FcMne9DOqERbo0BZVKVAn/jBJ70Kirx4WqMRVe3TmvzP14cVMPEPPqyp7eI7NZtO7n36ju7q0Vrlyfp4OB3DJR7vT1CAiWHe1iFJkaIDa162iOxpV0yc/pks6n+ifuL2+6lWtqNnrDspqsahSUHlVCiqvct68jJrJWdzwj7fyaGWfnZ2tAwcO2D+npKRo165dCg8PV61atTwYGS62aftPOpL+m/p2a+vpUACXHTiRo6c+36+/tYlW3xtqKP1Mnl7Z8rM2HjglSapSsbza1q4sSZpzVzOHc59c+aO+P3amzGMGXOHRZL99+3Z16tTJ/nn06NGSpISEBC1ZssRDUeFS2rdppJ83zvZ0GIDbbP8lQ9t/ybjkvuPZ+eq1cGvZBoTS5+KiOl5c2Hs22Xfs2FGGYXgyBACASZh4yJ4xewAAfJ1XzcYHAKDETFzak+wBAKbAW+8AAPBxZn7rHWP2AAD4OCp7AIApmHjInmQPADAJE2d7uvEBAPBxVPYAAFMw82x8KnsAgClcmI3vyuaMpKQktW7dWiEhIapWrZp69eqlffv2ORyTm5uroUOHqkqVKgoODlafPn2Unp7uxqc+j2QPAEAp2LBhg4YOHaqvv/5aa9asUUFBge644w7l5OTYjxk1apRWrlypd999Vxs2bNDRo0fVu3dvt8dCNz4AwBTKen7e6tWrHT4vWbJE1apV044dO9S+fXtlZmbqlVde0RtvvKFbb71VkrR48WI1btxYX3/9tW688UYXonVEZQ8AMAeLGzZJWVlZDlteXl6xbp+ZmSlJCg8PlyTt2LFDBQUFio+Ptx/TqFEj1apVS1u2bHHtWS9CsgcAwAnR0dEKCwuzb0lJSVc8x2azaeTIkbrpppvUtGlTSVJaWpr8/f1VqVIlh2MjIiKUlpbm1pjpxgcAmIK7ZuOnpqYqNDTU3h4QEHDFc4cOHarvv/9emzZtKvH9XUGyBwCYgrvWxg8NDXVI9lcybNgwrVq1Shs3blTNmjXt7ZGRkcrPz1dGRoZDdZ+enq7IyMiSB3oJdOMDAEzBTUP2xWYYhoYNG6bly5dr3bp1io2NddjfsmVLlS9fXmvXrrW37du3T7/88ovi4uJK8ISXR2UPAEApGDp0qN544w19+OGHCgkJsY/Dh4WFKSgoSGFhYRo4cKBGjx6t8PBwhYaGavjw4YqLi3PrTHyJZA8AMIsy/u7dggULJEkdO3Z0aF+8eLH69+8vSZo9e7asVqv69OmjvLw8de7cWS+88IILQV4ayR4AYAplvVyuYRhXPCYwMFDz58/X/PnzSxpWsTBmDwCAj6OyBwCYgrtm43sjkj0AwBRM/Dp7uvEBAPB1VPYAAHMwcWlPsgcAmEJZz8a/mtCNDwCAj6OyBwCYArPxAQDwcSYesifZAwBMwsTZnjF7AAB8HJU9AMAUzDwbn2QPADAHFyfoeXGupxsfAABfR2UPADAFE8/PI9kDAEzCxNmebnwAAHwclT0AwBSYjQ8AgI8z83K5dOMDAODjqOwBAKZg4vl5JHsAgEmYONuT7AEApmDmCXqM2QMA4OOo7AEApmCRi7Px3RZJ2SPZAwBMwcRD9nTjAwDg66jsAQCmYOZFdUj2AACTMG9HPt34AAD4OCp7AIAp0I0PAICPM28nPt34AAD4PCp7AIAp0I0PAICPM/Pa+CR7AIA5mHjQnjF7AAB8HJU9AMAUTFzYk+wBAOZg5gl6dOMDAODjqOwBAKbAbHwAAHydiQft6cYHAMDHUdkDAEzBxIU9yR4AYA7MxgcAAD6Lyh4AYBKuzcb35o58kj0AwBToxgcAAD6LZA8AgI+jGx8AYApm7sYn2QMATMHMy+XSjQ8AgI+jsgcAmALd+AAA+DgzL5dLNz4AAD6Oyh4AYA4mLu1J9gAAU2A2PgAA8FlU9gAAU2A2PgAAPs7EQ/Z04wMATMLihq0E5s+fr9q1ayswMFBt27bVN99849pzlADJHgCAUvL2229r9OjRmjRpkr799ls1b95cnTt31vHjx8s0DpI9AMAULG74x1nPPvusBg8erAEDBqhJkyZKTk5WhQoVtGjRolJ4wssj2QMATOHCBD1XNmfk5+drx44dio+Pt7dZrVbFx8dry5Ytbn66P+fVE/QMw5AknTlzxsORAKXn3O85ng4BKDXncs//fl/4//PSlJWV5ZbzL75OQECAAgICihx/8uRJFRYWKiIiwqE9IiJCe/fudSkWZ3l1sr+Q5K9vHOvhSAAArjhz5ozCwsJK5dr+/v6KjIxU/dhol68VHBys6GjH60yaNEmTJ092+dqlyauTfVRUlFJTUxUSEiKLN38B0otkZWUpOjpaqampCg0N9XQ4gFvx+132DMPQmTNnFBUVVWr3CAwMVEpKivLz812+lmEYRfLNpap6Sbrmmmvk5+en9PR0h/b09HRFRka6HIszvDrZW61W1axZ09NhmFJoaCj/Zwifxe932Sqtiv6PAgMDFRgYWOr3+SN/f3+1bNlSa9euVa9evSRJNptNa9eu1bBhw8o0Fq9O9gAAXM1Gjx6thIQEtWrVSm3atNGcOXOUk5OjAQMGlGkcJHsAAErJ//3f/+nEiROaOHGi0tLS1KJFC61evbrIpL3SRrKHUwICAjRp0qTLjlEB3ozfb5SGYcOGlXm3/cUsRll83wEAAHgMi+oAAODjSPYAAPg4kj0AAD6OZA8AgI8j2aPYroZ3MgOlYePGjerevbuioqJksVi0YsUKT4cEuBXJHsVytbyTGSgNOTk5at68uebPn+/pUIBSwVfvUCxt27ZV69at9fzzz0s6v+RjdHS0hg8frvHjx3s4OsB9LBaLli9fbl/eFPAFVPa4oqvpncwAAOeR7HFFf/ZO5rS0NA9FBQAoLpI9AAA+jmSPK7qa3skMAHAeyR5X9Md3Ml9w4Z3McXFxHowMAFAcvPUOxXK1vJMZKA3Z2dk6cOCA/XNKSop27dql8PBw1apVy4ORAe7BV+9QbM8//7yefvpp+zuZ586dq7Zt23o6LMBl69evV6dOnYq0JyQkaMmSJWUfEOBmJHsAAHwcY/YAAPg4kj0AAD6OZA8AgI8j2QMA4ONI9gAA+DiSPQAAPo5kDwCAjyPZAy7q37+/w7vPO3bsqJEjR5Z5HOvXr5fFYlFGRsZlj7FYLFqxYkWxrzl58mS1aNHCpbgOHz4si8WiXbt2uXQdACVHsodP6t+/vywWiywWi/z9/VWvXj1NnTpV586dK/V7f/DBB5o2bVqxji1OggYAV7E2PnxWly5dtHjxYuXl5emTTz7R0KFDVb58eU2YMKHIsfn5+fL393fLfcPDw91yHQBwFyp7+KyAgABFRkYqJiZGjzzyiOLj4/XRRx9J+l/X+4wZMxQVFaWGDRtKklJTU9W3b19VqlRJ4eHh6tmzpw4fPmy/ZmFhoUaPHq1KlSqpSpUqeuKJJ3TxitMXd+Pn5eVp3Lhxio6OVkBAgOrVq6dXXnlFhw8ftq/HXrlyZVksFvXv31/S+bcKJiUlKTY2VkFBQWrevLnee+89h/t88sknatCggYKCgtSpUyeHOItr3LhxatCggSpUqKA6deooMTFRBQUFRY578cUXFR0drQoVKqhv377KzMx02P/yyy+rcePGCgwMVKNGjfTCCy84HQuA0kOyh2kEBQUpPz/f/nnt2rXat2+f1qxZo1WrVqmgoECdO3dWSEiIvvrqK/373/9WcHCwunTpYj/vX//6l5YsWaJFixZp06ZNOn36tJYvX/6n933ggQf05ptvau7cudqzZ49efPFFBQcHKzo6Wu+//74kad++fTp27Jiee+45SVJSUpKWLl2q5ORk/fDDDxo1apTuv/9+bdiwQdL5P0p69+6t7t27a9euXRo0aJDGjx/v9M8kJCRES5Ys0Y8//qjnnntOL730kmbPnu1wzIEDB/TOO+9o5cqVWr16tXbu3KlHH33Uvn/ZsmWaOHGiZsyYoT179mjmzJlKTEzUq6++6nQ8AEqJAfighIQEo2fPnoZhGIbNZjPWrFljBAQEGGPGjLHvj4iIMPLy8uznvPbaa0bDhg0Nm81mb8vLyzOCgoKMzz77zDAMw6hevboxa9Ys+/6CggKjZs2a9nsZhmF06NDBeOyxxwzDMIx9+/YZkow1a9ZcMs4vv/zSkGT89ttv9rbc3FyjQoUKxubNmx2OHThwoHHvvfcahmEYEyZMMJo0aeKwf9y4cUWudTFJxvLlyy+7/+mnnzZatmxp/zxp0iTDz8/P+PXXX+1tn376qWG1Wo1jx44ZhmEYdevWNd544w2H60ybNs2Ii4szDMMwUlJSDEnGzp07L3tfAKWLMXv4rFWrVik4OFgFBQWy2Wy67777NHnyZPv+Zs2aOYzTf/fddzpw4IBCQkIcrpObm6uDBw8qMzNTx44dc3itb7ly5dSqVasiXfkX7Nq1S35+furQoUOx4z5w4IDOnj2r22+/3aE9Pz9f119/vSRpz549RV4vHBcXV+x7XPD2229r7ty5OnjwoLKzs3Xu3DmFhoY6HFOrVi3VqFHD4T42m0379u1TSEiIDh48qIEDB2rw4MH2Y86dO6ewsDCn4wFQOkj28FmdOnXSggUL5O/vr6ioKJUr5/jrXrFiRYfP2dnZatmypZYtW1bkWlWrVi1RDEFBQU6fk52dLUn6+OOPHZKsdH4egrts2bJF/fr105QpU9S5c2eFhYXprbfe0r/+9S+nY33ppZeK/PHh5+fntlgBuIZkD59VsWJF1atXr9jH33DDDXr77bdVrVq1ItXtBdWrV9fWrVvVvn17Secr2B07duiGG2645PHNmjWTzWbThg0bFB8fX2T/hZ6FwsJCe1uTJk0UEBCgX3755bI9Ao0bN7ZPNrzg66+/vvJD/sHmzZsVExOjf/zjH/a2n3/+uchxv/zyi44ePaqoqCj7faxWqxo2bKiIiAhFRUXp0KFD6tevn1P3B1B2mKAH/Fe/fv10zTXXqGfPnvrqq6+UkpKi9evXa8SIEfr1118lSY899pieeuoprVixQnv37tWjjz76p9+Rr127thISEvTggw9qxYoV9mu+8847kqSYmBhZLBatWrVKJ06cUHZ2tkJCQjRmzBiNGjVKr776qg4ePKhvv/1W8+bNs096e/jhh7V//36NHTtW+/bt0xtvvKElS5Y49bz169fXL7/8orfeeksHDx7U3LlzLznZMDAwUAkJCfruu+/01VdfacSIEerbt68iIyMlSVOmTFFSUpLmzp2rn376Sbt379bixYv17LPPOhUPgNJDsgf+q0KFCtq4caNq1aql3r17q3Hjxho4cKByc3Ptlf7jjz+uv/3tb0pISFBcXJxCQkL017/+9U+vu2DBAt1111169NFH1ahRIw0ePFg5OTmSpBo1amjKlCkaP368IiIiNGzYMEnStGnTlJiYqKSkJDVu3FhdunTRxx9/rNjYWEnnx9Hff/99rVixQs2bN1dycrJmzpzp1PP26NFDo0aN0rBhw9SiRQtt3rxZiYmJRY6rV6+eevfurTvvvFN33HGHrrvuOoev1g0aNEgvv/yyFi9erGbNmqlDhw5asmSJPVYAnmcxLjezCAAA+AQqewAAfBzJHgAAH0eyBwDAx5HsAQDwcSR7AAB8HMkeAAAfR7IHAMDHkewBAPBxJHsAAHwcyR4AAB9HsgcAwMeR7AEA8HH/DyL17SiUWJJqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "display = ConfusionMatrixDisplay.from_estimator(sgd, data.x_test, data.y_test, cmap=plt.cm.Blues)\n",
    "display.ax_.set_title(\"sgd confusion matrix\")\n",
    "plt.savefig(\"images/results/sgd_conf.png\")\n",
    "display_2 = ConfusionMatrixDisplay.from_estimator(ridge, data.x_test, data.y_test, cmap=plt.cm.Blues)\n",
    "display_2.ax_.set_title(\"ridge confusion matrix\")\n",
    "plt.savefig(\"images/results/ridge_conf.png\")\n",
    "display_3 = ConfusionMatrixDisplay.from_estimator(dtree, data.x_test, data.y_test, cmap=plt.cm.Blues)\n",
    "display_3.ax_.set_title(\"decision tree confusion matrix\")\n",
    "plt.savefig(\"images/results/dtree_conf.png\")\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "import matplotlib.image as img\n",
    "img_sgd = img.imread(\"images/results/sgd_conf.png\")\n",
    "img_ridge = img.imread(\"images/results/ridge_conf.png\")\n",
    "img_dtree = img.imread(\"images/results/dtree_conf.png\")\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_sgd)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_ridge)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_dtree)\n",
    "plt.savefig(\"images/results/all_conf.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run the algorithm on means and worst separately to see if we can get a better result with different data. For example, can we get better results from only considering the means or the worst features from the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "SEARCH TIME: 4.35 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\tbest 'f1_micro' score=0.9530232558139534\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.953 (+/-0.073) for {'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[ 1]: 0.953 (+/-0.073) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[ 2]: 0.953 (+/-0.073) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[ 3]: 0.953 (+/-0.073) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[ 4]: 0.953 (+/-0.073) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[ 5]: 0.953 (+/-0.073) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[ 6]: 0.951 (+/-0.050) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[ 7]: 0.923 (+/-0.050) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[ 8]: 0.937 (+/-0.049) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[ 9]: 0.925 (+/-0.028) for {'alpha': 0.01, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[10]: 0.925 (+/-0.028) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[11]: 0.911 (+/-0.023) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[12]: 0.946 (+/-0.068) for {'alpha': 0.1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[13]: 0.946 (+/-0.068) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[14]: 0.946 (+/-0.068) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[15]: 0.946 (+/-0.068) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[16]: 0.946 (+/-0.068) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[17]: 0.946 (+/-0.068) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[18]: 0.951 (+/-0.050) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[19]: 0.923 (+/-0.050) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[20]: 0.937 (+/-0.049) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[21]: 0.925 (+/-0.028) for {'alpha': 0.1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[22]: 0.925 (+/-0.028) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[23]: 0.911 (+/-0.023) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[24]: 0.946 (+/-0.068) for {'alpha': 1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[25]: 0.946 (+/-0.068) for {'alpha': 1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[26]: 0.946 (+/-0.068) for {'alpha': 1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[27]: 0.946 (+/-0.068) for {'alpha': 1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[28]: 0.946 (+/-0.068) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[29]: 0.946 (+/-0.068) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[30]: 0.948 (+/-0.059) for {'alpha': 1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[31]: 0.923 (+/-0.050) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[32]: 0.937 (+/-0.049) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[33]: 0.925 (+/-0.028) for {'alpha': 1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[34]: 0.925 (+/-0.028) for {'alpha': 1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[35]: 0.911 (+/-0.023) for {'alpha': 1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[36]: 0.946 (+/-0.068) for {'alpha': 2, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[37]: 0.946 (+/-0.068) for {'alpha': 2, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[38]: 0.946 (+/-0.068) for {'alpha': 2, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[39]: 0.946 (+/-0.068) for {'alpha': 2, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[40]: 0.946 (+/-0.068) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[41]: 0.946 (+/-0.068) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[42]: 0.946 (+/-0.068) for {'alpha': 2, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[43]: 0.925 (+/-0.053) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[44]: 0.937 (+/-0.049) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[45]: 0.925 (+/-0.028) for {'alpha': 2, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[46]: 0.925 (+/-0.028) for {'alpha': 2, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[47]: 0.911 (+/-0.023) for {'alpha': 2, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[48]: 0.946 (+/-0.057) for {'alpha': 10, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[49]: 0.946 (+/-0.057) for {'alpha': 10, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[50]: 0.946 (+/-0.057) for {'alpha': 10, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[51]: 0.946 (+/-0.057) for {'alpha': 10, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[52]: 0.946 (+/-0.057) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[53]: 0.946 (+/-0.057) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[54]: 0.946 (+/-0.057) for {'alpha': 10, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[55]: 0.930 (+/-0.039) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[56]: 0.937 (+/-0.049) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[57]: 0.925 (+/-0.028) for {'alpha': 10, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[58]: 0.925 (+/-0.028) for {'alpha': 10, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[59]: 0.911 (+/-0.023) for {'alpha': 10, 'solver': 'sag', 'tol': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        82\n",
      "           1       0.98      0.89      0.93        61\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.95      0.94      0.94       143\n",
      "weighted avg       0.95      0.94      0.94       143\n",
      "\n",
      "\n",
      "CTOR for best model: RidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "best: dat=N/A, score=0.95302, model=RidgeClassifier(alpha=0.01,solver='svd',tol=1e-05)\n",
      "\n",
      "OK(grid-search)\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "SEARCH TIME: 0.84 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\tbest 'f1_micro' score=0.9436662106703148\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.944 (+/-0.018) for {'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[ 1]: 0.944 (+/-0.018) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[ 2]: 0.944 (+/-0.018) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[ 3]: 0.944 (+/-0.018) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[ 4]: 0.944 (+/-0.018) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[ 5]: 0.944 (+/-0.018) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[ 6]: 0.934 (+/-0.023) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[ 7]: 0.913 (+/-0.045) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[ 8]: 0.906 (+/-0.053) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[ 9]: 0.909 (+/-0.040) for {'alpha': 0.01, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[10]: 0.909 (+/-0.040) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[11]: 0.911 (+/-0.031) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[12]: 0.937 (+/-0.028) for {'alpha': 0.1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[13]: 0.937 (+/-0.028) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[14]: 0.937 (+/-0.028) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[15]: 0.937 (+/-0.028) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[16]: 0.937 (+/-0.028) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[17]: 0.937 (+/-0.028) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[18]: 0.937 (+/-0.028) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[19]: 0.913 (+/-0.045) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[20]: 0.906 (+/-0.053) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[21]: 0.909 (+/-0.040) for {'alpha': 0.1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[22]: 0.909 (+/-0.040) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[23]: 0.911 (+/-0.031) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[24]: 0.923 (+/-0.043) for {'alpha': 1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[25]: 0.923 (+/-0.043) for {'alpha': 1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[26]: 0.923 (+/-0.043) for {'alpha': 1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[27]: 0.923 (+/-0.043) for {'alpha': 1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[28]: 0.923 (+/-0.043) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[29]: 0.923 (+/-0.043) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[30]: 0.923 (+/-0.043) for {'alpha': 1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[31]: 0.918 (+/-0.048) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[32]: 0.906 (+/-0.053) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[33]: 0.909 (+/-0.040) for {'alpha': 1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[34]: 0.909 (+/-0.040) for {'alpha': 1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[35]: 0.911 (+/-0.031) for {'alpha': 1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[36]: 0.918 (+/-0.048) for {'alpha': 2, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[37]: 0.918 (+/-0.048) for {'alpha': 2, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[38]: 0.918 (+/-0.048) for {'alpha': 2, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[39]: 0.918 (+/-0.048) for {'alpha': 2, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[40]: 0.918 (+/-0.048) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[41]: 0.918 (+/-0.048) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[42]: 0.918 (+/-0.048) for {'alpha': 2, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[43]: 0.918 (+/-0.048) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[44]: 0.906 (+/-0.053) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[45]: 0.909 (+/-0.040) for {'alpha': 2, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[46]: 0.909 (+/-0.040) for {'alpha': 2, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[47]: 0.911 (+/-0.031) for {'alpha': 2, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[48]: 0.918 (+/-0.053) for {'alpha': 10, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[49]: 0.918 (+/-0.053) for {'alpha': 10, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[50]: 0.918 (+/-0.053) for {'alpha': 10, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[51]: 0.918 (+/-0.053) for {'alpha': 10, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[52]: 0.918 (+/-0.053) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[53]: 0.918 (+/-0.053) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[54]: 0.918 (+/-0.053) for {'alpha': 10, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[55]: 0.918 (+/-0.053) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[56]: 0.906 (+/-0.053) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[57]: 0.909 (+/-0.040) for {'alpha': 10, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[58]: 0.909 (+/-0.040) for {'alpha': 10, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[59]: 0.911 (+/-0.031) for {'alpha': 10, 'solver': 'sag', 'tol': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        83\n",
      "           1       0.96      0.83      0.89        60\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.93      0.90      0.91       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n",
      "\n",
      "CTOR for best model: RidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "best: dat=N/A, score=0.94367, model=RidgeClassifier(alpha=0.01,solver='svd',tol=1e-05)\n",
      "\n",
      "OK(grid-search)\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "SEARCH TIME: 0.75 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\tbest 'f1_micro' score=0.9671409028727771\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.967 (+/-0.052) for {'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[ 1]: 0.967 (+/-0.052) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[ 2]: 0.967 (+/-0.052) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[ 3]: 0.967 (+/-0.052) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[ 4]: 0.967 (+/-0.052) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[ 5]: 0.967 (+/-0.052) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[ 6]: 0.955 (+/-0.064) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[ 7]: 0.937 (+/-0.043) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[ 8]: 0.927 (+/-0.034) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[ 9]: 0.930 (+/-0.038) for {'alpha': 0.01, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[10]: 0.930 (+/-0.038) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[11]: 0.918 (+/-0.051) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[12]: 0.965 (+/-0.061) for {'alpha': 0.1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[13]: 0.965 (+/-0.061) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[14]: 0.965 (+/-0.061) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[15]: 0.965 (+/-0.061) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[16]: 0.965 (+/-0.061) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[17]: 0.965 (+/-0.061) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[18]: 0.948 (+/-0.066) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[19]: 0.937 (+/-0.043) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[20]: 0.927 (+/-0.034) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[21]: 0.930 (+/-0.038) for {'alpha': 0.1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[22]: 0.930 (+/-0.038) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[23]: 0.918 (+/-0.051) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[24]: 0.951 (+/-0.045) for {'alpha': 1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[25]: 0.951 (+/-0.045) for {'alpha': 1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[26]: 0.951 (+/-0.045) for {'alpha': 1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[27]: 0.951 (+/-0.045) for {'alpha': 1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[28]: 0.951 (+/-0.045) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[29]: 0.951 (+/-0.045) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[30]: 0.948 (+/-0.043) for {'alpha': 1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[31]: 0.937 (+/-0.043) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[32]: 0.927 (+/-0.034) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[33]: 0.930 (+/-0.038) for {'alpha': 1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[34]: 0.930 (+/-0.038) for {'alpha': 1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[35]: 0.918 (+/-0.051) for {'alpha': 1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[36]: 0.948 (+/-0.043) for {'alpha': 2, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[37]: 0.948 (+/-0.043) for {'alpha': 2, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[38]: 0.948 (+/-0.043) for {'alpha': 2, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[39]: 0.948 (+/-0.043) for {'alpha': 2, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[40]: 0.948 (+/-0.043) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[41]: 0.948 (+/-0.043) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[42]: 0.948 (+/-0.043) for {'alpha': 2, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[43]: 0.937 (+/-0.043) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[44]: 0.927 (+/-0.034) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[45]: 0.930 (+/-0.038) for {'alpha': 2, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[46]: 0.930 (+/-0.038) for {'alpha': 2, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[47]: 0.918 (+/-0.051) for {'alpha': 2, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[48]: 0.946 (+/-0.060) for {'alpha': 10, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[49]: 0.946 (+/-0.060) for {'alpha': 10, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[50]: 0.946 (+/-0.060) for {'alpha': 10, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[51]: 0.946 (+/-0.060) for {'alpha': 10, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[52]: 0.946 (+/-0.060) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[53]: 0.946 (+/-0.060) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[54]: 0.946 (+/-0.060) for {'alpha': 10, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[55]: 0.937 (+/-0.043) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[56]: 0.927 (+/-0.034) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[57]: 0.930 (+/-0.038) for {'alpha': 10, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[58]: 0.930 (+/-0.038) for {'alpha': 10, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[59]: 0.918 (+/-0.051) for {'alpha': 10, 'solver': 'sag', 'tol': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        90\n",
      "           1       0.98      0.96      0.97        53\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "\n",
      "CTOR for best model: RidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "best: dat=N/A, score=0.96714, model=RidgeClassifier(alpha=0.01,solver='svd',tol=1e-05)\n",
      "\n",
      "OK(grid-search)\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "SEARCH TIME: 0.90 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\tbest 'f1_micro' score=0.7910807113543091\n",
      "\tbest index=0\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tRidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.791 (+/-0.052) for {'alpha': 0.01, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[ 1]: 0.791 (+/-0.052) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[ 2]: 0.791 (+/-0.052) for {'alpha': 0.01, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[ 3]: 0.791 (+/-0.052) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[ 4]: 0.791 (+/-0.052) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[ 5]: 0.791 (+/-0.052) for {'alpha': 0.01, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[ 6]: 0.789 (+/-0.045) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[ 7]: 0.784 (+/-0.049) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[ 8]: 0.784 (+/-0.063) for {'alpha': 0.01, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[ 9]: 0.784 (+/-0.059) for {'alpha': 0.01, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[10]: 0.784 (+/-0.059) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[11]: 0.784 (+/-0.059) for {'alpha': 0.01, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[12]: 0.782 (+/-0.061) for {'alpha': 0.1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[13]: 0.782 (+/-0.061) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[14]: 0.782 (+/-0.061) for {'alpha': 0.1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[15]: 0.782 (+/-0.061) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[16]: 0.782 (+/-0.061) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[17]: 0.782 (+/-0.061) for {'alpha': 0.1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[18]: 0.782 (+/-0.061) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[19]: 0.782 (+/-0.053) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[20]: 0.784 (+/-0.063) for {'alpha': 0.1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[21]: 0.784 (+/-0.059) for {'alpha': 0.1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[22]: 0.784 (+/-0.059) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[23]: 0.784 (+/-0.059) for {'alpha': 0.1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[24]: 0.782 (+/-0.054) for {'alpha': 1, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[25]: 0.782 (+/-0.054) for {'alpha': 1, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[26]: 0.782 (+/-0.054) for {'alpha': 1, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[27]: 0.782 (+/-0.054) for {'alpha': 1, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[28]: 0.782 (+/-0.054) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[29]: 0.782 (+/-0.054) for {'alpha': 1, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[30]: 0.782 (+/-0.054) for {'alpha': 1, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[31]: 0.782 (+/-0.054) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[32]: 0.784 (+/-0.063) for {'alpha': 1, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[33]: 0.784 (+/-0.059) for {'alpha': 1, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[34]: 0.784 (+/-0.059) for {'alpha': 1, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[35]: 0.784 (+/-0.059) for {'alpha': 1, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[36]: 0.784 (+/-0.052) for {'alpha': 2, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[37]: 0.784 (+/-0.052) for {'alpha': 2, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[38]: 0.784 (+/-0.052) for {'alpha': 2, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[39]: 0.784 (+/-0.052) for {'alpha': 2, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[40]: 0.784 (+/-0.052) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[41]: 0.784 (+/-0.052) for {'alpha': 2, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[42]: 0.782 (+/-0.043) for {'alpha': 2, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[43]: 0.782 (+/-0.043) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[44]: 0.784 (+/-0.069) for {'alpha': 2, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[45]: 0.784 (+/-0.059) for {'alpha': 2, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[46]: 0.784 (+/-0.059) for {'alpha': 2, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[47]: 0.784 (+/-0.059) for {'alpha': 2, 'solver': 'sag', 'tol': 0.001}\n",
      "\t[48]: 0.782 (+/-0.063) for {'alpha': 10, 'solver': 'svd', 'tol': 1e-05}\n",
      "\t[49]: 0.782 (+/-0.063) for {'alpha': 10, 'solver': 'svd', 'tol': 0.0001}\n",
      "\t[50]: 0.782 (+/-0.063) for {'alpha': 10, 'solver': 'svd', 'tol': 0.001}\n",
      "\t[51]: 0.782 (+/-0.063) for {'alpha': 10, 'solver': 'cholesky', 'tol': 1e-05}\n",
      "\t[52]: 0.782 (+/-0.063) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.0001}\n",
      "\t[53]: 0.782 (+/-0.063) for {'alpha': 10, 'solver': 'cholesky', 'tol': 0.001}\n",
      "\t[54]: 0.782 (+/-0.063) for {'alpha': 10, 'solver': 'lsqr', 'tol': 1e-05}\n",
      "\t[55]: 0.782 (+/-0.063) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.0001}\n",
      "\t[56]: 0.782 (+/-0.059) for {'alpha': 10, 'solver': 'lsqr', 'tol': 0.001}\n",
      "\t[57]: 0.784 (+/-0.059) for {'alpha': 10, 'solver': 'sag', 'tol': 1e-05}\n",
      "\t[58]: 0.784 (+/-0.059) for {'alpha': 10, 'solver': 'sag', 'tol': 0.0001}\n",
      "\t[59]: 0.784 (+/-0.059) for {'alpha': 10, 'solver': 'sag', 'tol': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        97\n",
      "           1       0.86      0.70      0.77        46\n",
      "\n",
      "    accuracy                           0.87       143\n",
      "   macro avg       0.87      0.82      0.84       143\n",
      "weighted avg       0.87      0.87      0.86       143\n",
      "\n",
      "\n",
      "CTOR for best model: RidgeClassifier(alpha=0.01, solver='svd', tol=1e-05)\n",
      "\n",
      "best: dat=N/A, score=0.79108, model=RidgeClassifier(alpha=0.01,solver='svd',tol=1e-05)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    }
   ],
   "source": [
    "X_train_means, X_test_means, Y_train_means, Y_test_means = train_test_split(data_breast_means, y_all, test_size = 0.25, shuffle=True)\n",
    "X_train_worst, X_test_worst, Y_train_worst, Y_test_worst = train_test_split(data_breast_worst, y_all, test_size = 0.25, shuffle=True)\n",
    "X_train_se, X_test_se, Y_train_se, Y_test_se = train_test_split(data_breast_se, y_all, test_size = 0.25, shuffle=True)\n",
    "\n",
    "data_means = Data(X_train_means, Y_train_means, X_test_means, Y_test_means)\n",
    "data_worst = Data(X_train_worst, Y_train_worst, X_test_worst, Y_test_worst)\n",
    "data_se = Data(X_train_se, Y_train_se, X_test_se, Y_test_se)\n",
    "\n",
    "grid_tuned = gridSearchRidge(data)\n",
    "b, m = trainAndReport(grid_tuned, data)\n",
    "grid_tuned = gridSearchRidge(data_means)\n",
    "b, m = trainAndReport(grid_tuned, data_means)\n",
    "grid_tuned = gridSearchRidge(data_worst)\n",
    "b, m = trainAndReport(grid_tuned, data_worst)\n",
    "grid_tuned = gridSearchRidge(data_se)\n",
    "b, m = trainAndReport(grid_tuned, data_se)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swmal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
